{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Callable, List, NamedTuple\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from scipy.special import erf\n",
    "from domain_model import DocumentManagement, StateVariable\n",
    "from simulation import ACC, idm_approaching_pars, IDMPlus, acc_approaching_pars, \\\n",
    "    SimulationApproaching, ACCHDM, acc_idm_approaching_pars, HDM, hdm_approaching_pars, \\\n",
    "    acc_lead_braking_pars, acc_hdm_lead_braking_pars, idm_lead_braking_pars, SimulationLeadBraking, \\\n",
    "    SimulationString, SimulationCutIn, idm_cutin_pars, acc_cutin_pars, acc_idm_cutin_pars\n",
    "from stats import KDE, kde_from_file\n",
    "from case_study_approaching import check_validity_approaching\n",
    "from case_study_lead_braking import check_validity_lead_braking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERWRITE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show number of scenarios found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaddec = DocumentManagement(os.path.join(\"data\", \"5_scenarios\", \"lead_braking2.json\"))\n",
    "print(\"Number of lead vehicle decelerating scenarios: {:d}\"\n",
    "      .format(len(leaddec.collections[\"scenario\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approaching = DocumentManagement(os.path.join(\"data\", \"5_scenarios\", \"approaching_vehicle2.json\"))\n",
    "print(\"Number of approaching slower vehicle scenarios: {:d}\"\n",
    "      .format(len(approaching.collections[\"scenario\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutins = DocumentManagement(os.path.join(\"data\", \"5_scenarios\", \"cut_in_scenarios2.json\"))\n",
    "print(\"Number of cut-in scenarios: {:d}\".format(len(cutins.collections[\"scenario\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulations\n",
    "\n",
    "#### Approaching stopped vehicle (false positive) with 2 vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = SimulationApproaching([ACC(), IDMPlus()], [acc_approaching_pars, idm_approaching_pars],\n",
    "                          min_simulation_time=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.simulation(dict(vego=20, ratio_vtar_vego=0, amin=-6, init_position=20, reactiontime=13),\n",
    "             plot=True, ignore_stop=[True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating risk for false positives\n",
    "\n",
    "A vehicle is detected at distance X\n",
    "Ego is at speed V\n",
    "Vehicle behind with same speed (modelled using IDM+, with delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_lognormal = np.log(.92**2/np.sqrt(.92**2+.28**2))\n",
    "sigma_lognormal = np.sqrt(np.log(1+.28**2/.92**2))\n",
    "def pdf(x):\n",
    "    return (np.exp(-(np.log(x) - mu_lognormal)**2 / (2*sigma_lognormal**2)) / \n",
    "            (x*sigma_lognormal*np.sqrt(2*np.pi)))\n",
    "def cdf(x):\n",
    "    return 0.5*(1 + erf((np.log(x) - mu_lognormal) / (sigma_lognormal*np.sqrt(2))))\n",
    "def sample_reactiontime():\n",
    "    return np.random.lognormal(np.log(.92**2/np.sqrt(.92**2+.28**2)),\n",
    "                               np.sqrt(np.log(1+.28**2/.92**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation = SimulationApproaching([ACC(), IDMPlus()], \n",
    "                                   [acc_approaching_pars, idm_approaching_pars],\n",
    "                                   min_simulation_time=5)\n",
    "def fp_simulation(speed, distance, reactiontime, thw):\n",
    "     return simulation.simulation(dict(vego=speed, ratio_vtar_vego=0, thw=thw,\n",
    "                                       amin=-6, init_position=distance, reactiontime=reactiontime),\n",
    "                                  ignore_stop=[True, False])\n",
    "\n",
    "def is_collision(speed, distance, reactiontime, thw):\n",
    "    result = fp_simulation(speed, distance, reactiontime, thw)\n",
    "    if result[1] < 0.0:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_of_collision(speed, distance, thw):\n",
    "    minimum = 0.3\n",
    "    maximum = 4\n",
    "    if is_collision(speed, distance, minimum, thw):\n",
    "        return 1.0\n",
    "    if not is_collision(speed, distance, maximum, thw):\n",
    "        return 0.0\n",
    "    while cdf(maximum) - cdf(minimum) > 0.00001:\n",
    "        if is_collision(speed, distance, (maximum + minimum) / 2, thw):\n",
    "            maximum = (maximum + minimum) / 2\n",
    "        else:\n",
    "            minimum = (maximum + minimum) / 2\n",
    "    return 1 - cdf((maximum + minimum) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_heatplot_fp(dmin, dmax, vmin, vmax, thw=1.0, overwrite=False):\n",
    "    name = \"fp_prob_{:d}_{:d}_{:d}_{:d}_{:02.0f}\".format(dmin, dmax, vmin, vmax, 10*thw)\n",
    "    filename = os.path.join(\"data\", \"7_simulation_results\", \"{:s}.p\".format(name))\n",
    "    \n",
    "    distances = np.linspace(dmin, dmax, 50)\n",
    "    speeds = np.linspace(vmin, vmax, 50)\n",
    "        \n",
    "    if not overwrite and os.path.exists(filename):\n",
    "        with open(filename, \"rb\") as file:\n",
    "            prob_collision = pickle.load(file)\n",
    "    else:\n",
    "        prob_collision = np.zeros((len(distances), len(speeds)))\n",
    "        for i, distance in enumerate(tqdm(distances)):\n",
    "            for j, speed in enumerate(speeds):\n",
    "                prob_collision[i, j] = prob_of_collision(speed, distance, thw)\n",
    "        with open(filename, \"wb\") as file:\n",
    "            pickle.dump(prob_collision, file)\n",
    "    \n",
    "    f, ax = plt.subplots(1, 1)\n",
    "    heatmap = plt.contourf(speeds, distances, prob_collision, cmap='hot')\n",
    "    cbar = f.colorbar(heatmap)\n",
    "    plt.title(\"THW of follower is {:3.1f} s\".format(thw))\n",
    "    plt.xlabel(\"Speed [m/s]\")\n",
    "    plt.ylabel(\"Initial distance of false positive [m]\")\n",
    "    cbar.ax.set_ylabel(\"Probability of collision rear vehicle\")\n",
    "    \n",
    "    f.savefig(os.path.join(\"figs\", \"{:s}.png\".format(name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False P (resulting from triggering condition)\n",
    " - Obtain impact speed heatmap\n",
    "False N (resulting from triggering condition)  (3 -> 2 (ego) -> 1 (stationary, not detection))\n",
    " - Focus on this one\n",
    "\n",
    "Low-mu (triggering condition) -> lead vehicle braking, approaching, cut-in, cut-out (scenario)\n",
    "Slope (triggering condition) -> lead vehicle braking, approaching, cut-in, cut-out (scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gap(t) = inital_gap(thw=1.1s) - 0.5*a*t^2\n",
    "Make heatmap of impact speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_heatplot_fp(10, 100, 5, 40, 1.0, overwrite=OVERWRITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_heatplot_fp(10, 100, 5, 40, 0.6, overwrite=OVERWRITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_heatplot_fp(10, 100, 5, 40, 0.3, overwrite=OVERWRITE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap for impact speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_reaction_time_collision(speed, distance, thw):\n",
    "    minimum = 0.1\n",
    "    maximum = 10\n",
    "    if not is_collision(speed, distance, maximum, thw):\n",
    "        return -1\n",
    "    if is_collision(speed, distance, minimum, thw):\n",
    "        return minimum\n",
    "    while (maximum - minimum) >= 0.01:\n",
    "        if is_collision(speed, distance, (maximum+minimum)/2, thw):\n",
    "            maximum = (maximum + minimum) / 2\n",
    "        else:\n",
    "            minimum = (maximum + minimum) / 2\n",
    "    return maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_cdf(xmin, xmax=5):\n",
    "    x = np.linspace(xmin, xmax, 100)\n",
    "    y = np.array([cdf(xx) for xx in x])\n",
    "    y -= y[0]\n",
    "    y /= y[-1]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_heatplot_fp_vimpact(dmin, dmax, vmin, vmax, thw=1.0, overwrite=False):\n",
    "    name = \"fp_vimpact_{:d}_{:d}_{:d}_{:d}_{:02.0f}\".format(dmin, dmax, vmin, vmax, 10*thw)\n",
    "    filename = os.path.join(\"data\", \"7_simulation_results\", \"{:s}.p\".format(name))\n",
    "    \n",
    "    distances = np.linspace(dmin, dmax, 50)\n",
    "    speeds = np.linspace(vmin, vmax, 50)\n",
    "    n_simulations = 20\n",
    "        \n",
    "    if not overwrite and os.path.exists(filename):\n",
    "        with open(filename, \"rb\") as file:\n",
    "            vimpact = pickle.load(file)\n",
    "    else:\n",
    "        vimpact = np.zeros((len(distances), len(speeds), n_simulations))\n",
    "        for i, distance in enumerate(tqdm(distances)):\n",
    "            for j, speed in enumerate(speeds):\n",
    "                min_reaction_time = find_reaction_time_collision(speed, distance, thw)\n",
    "                if min_reaction_time < 0:\n",
    "                    continue\n",
    "                cdfx, cdfy = get_new_cdf(min_reaction_time)\n",
    "                cdf_q = np.linspace(.5/n_simulations, 1-.5/n_simulations, n_simulations)\n",
    "                for k in range(n_simulations):\n",
    "                    reaction_time = np.interp(cdf_q[k], cdfy, cdfx)\n",
    "                    result = fp_simulation(speed, distance, reaction_time, thw)[1]\n",
    "                    if result < 0:  # Only use result if there is an impact.\n",
    "                        vimpact[i, j, k] = -result\n",
    "        with open(filename, \"wb\") as file:\n",
    "            pickle.dump(vimpact, file)\n",
    "    \n",
    "    f, ax = plt.subplots(1, 1)\n",
    "    heatmap = plt.contourf(speeds, distances, np.mean(vimpact, axis=2), cmap='hot')\n",
    "    cbar = f.colorbar(heatmap)\n",
    "    plt.title(\"THW of follower is {:3.1f} s\".format(thw))\n",
    "    plt.xlabel(\"Speed [m/s]\")\n",
    "    plt.ylabel(\"Initial distance ego vehicle to ghost object [m]\")\n",
    "    cbar.ax.set_ylabel(\"Expected impact speed with collision [m/s]\")\n",
    "    \n",
    "    f.savefig(os.path.join(\"figs\", \"{:s}.png\".format(name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_heatplot_fp_vimpact(10, 100, 5, 40, 1.0, overwrite=OVERWRITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_heatplot_fp_vimpact(10, 100, 5, 40, 0.6, overwrite=OVERWRITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "make_heatplot_fp_vimpact(10, 100, 5, 40, 0.3, overwrite=OVERWRITE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating risk for false negatives\n",
    "\n",
    "#### Single simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_fn = SimulationApproaching([IDMPlus()], [idm_approaching_pars], min_simulation_time=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_fn.simulation(dict(vego=10, init_position=25.1, amin=-6, reactiontime=1.57,\n",
    "                     ratio_vtar_vego=0), plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_fn = SimulationApproaching([ACCHDM()], [acc_idm_approaching_pars], min_simulation_time=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_fn.simulation(dict(vego=10, ratio_vtar_vego=0, amin=-6, reactiontime=1.59, k1_acc=0, k2_acc=0),\n",
    "             plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute collision probability over varying speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_breakpoint(func, minimum=.2, maximum=5, tol=1e-5, **kwargs):\n",
    "    \"\"\" Find the point where the function switches from positive to negative.\n",
    "    \n",
    "    :param func: The function for which to find the change point.\n",
    "    :param minimum: The minimum x-value to search for.\n",
    "    :param maximum: The maximum x-value to search for.\n",
    "    :param tol: Search until (cdf(maximum)-cdf(minimum)) is within this tolerance.\n",
    "    :param kwargs: Parameters to be passed to func.\n",
    "    :return: (x of change point, probability that sample is larger than x,\n",
    "              latest simulation result)\n",
    "    \"\"\"\n",
    "    result = func(maximum, **kwargs)[0]\n",
    "    if result > 0:\n",
    "        return maximum, 0.0, result\n",
    "    result = func(minimum, **kwargs)[0]\n",
    "    if result < 0:\n",
    "        minimum, 1.0, result\n",
    "    while cdf(maximum) - cdf(minimum) > tol:\n",
    "        result = func((maximum+minimum)/2, **kwargs)[0]\n",
    "        if result > 0:\n",
    "            minimum = (maximum+minimum)/2\n",
    "        else:\n",
    "            maximum = (maximum+minimum)/2\n",
    "    return (maximum+minimum)/2, 1-cdf((maximum+minimum)/2), result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_fn(reactiontime, speed, ttcwarning):\n",
    "    return s_fn.simulation(dict(vego=speed, ratio_vtar_vego=0, amin=-6, \n",
    "                                init_position=ttcwarning*speed, reactiontime=reactiontime))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_heatplot_fn(vmin, vmax, ttcmin, ttcmax, overwrite=False):\n",
    "    name = \"fn_prob_v{:d}_{:d}_ttc{:d}_{:d}\".format(vmin, vmax, ttcmin, ttcmax)\n",
    "    filename = os.path.join(\"data\", \"7_simulation_results\", \"{:s}.p\".format(name))\n",
    "    \n",
    "    speeds = np.linspace(vmin, vmax, 50)\n",
    "    ttcs = np.linspace(ttcmin, ttcmax, 50)\n",
    "    \n",
    "    if not overwrite and os.path.exists(filename):\n",
    "        with open(filename, \"rb\") as file:\n",
    "            prob_collision = pickle.load(file)\n",
    "    else:\n",
    "        prob_collision = np.zeros((len(ttcs), len(speeds)))\n",
    "        for i, ttc in enumerate(tqdm(ttcs)):\n",
    "            for j, speed in enumerate(speeds):\n",
    "                prob_collision[i, j] = find_breakpoint(func_fn, speed=speed, ttcwarning=ttc)[1]\n",
    "        with open(filename, \"wb\") as file:\n",
    "            pickle.dump(prob_collision, file)\n",
    "    \n",
    "    f, ax = plt.subplots(1, 1)\n",
    "    heatmap = plt.contourf(speeds, ttcs, prob_collision, cmap='hot', levels=np.linspace(0, 1, 6))\n",
    "    cbar = f.colorbar(heatmap)\n",
    "    plt.title(\"Probability of collision\")\n",
    "    plt.xlabel(\"Initial speed of ego vehicle [m/s]\")\n",
    "    plt.ylabel(\"TTC at which warning is given [s]\")\n",
    "    cbar.ax.set_ylabel(\"Probability of collision with front vehicle\")\n",
    "    \n",
    "    f.savefig(os.path.join(\"figs\", \"{:s}.png\".format(name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_heatplot_fn(5, 30, 1, 4, overwrite=OVERWRITE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute expected impact speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_heatplot_fn_vimpact(vmin, vmax, ttcmin, ttcmax, overwrite=False):\n",
    "    name = \"fn_vimpact_v{:d}_{:d}_ttc{:d}_{:d}\".format(vmin, vmax, ttcmin, ttcmax)\n",
    "    filename = os.path.join(\"data\", \"7_simulation_results\", \"{:s}.p\".format(name))\n",
    "    \n",
    "    speeds = np.linspace(vmin, vmax, 50)\n",
    "    ttcs = np.linspace(ttcmin, ttcmax, 50)\n",
    "    n_simulations = 20\n",
    "    \n",
    "    if not overwrite and os.path.exists(filename):\n",
    "        with open(filename, \"rb\") as file:\n",
    "            vimpact = pickle.load(file)\n",
    "    else:\n",
    "        vimpact = np.zeros((len(ttcs), len(speeds), n_simulations))\n",
    "        for i, ttc in enumerate(tqdm(ttcs)):\n",
    "            for j, speed in enumerate(speeds):\n",
    "                min_reaction_time = find_breakpoint(func_fn, speed=speed, ttcwarning=ttc)[0]\n",
    "                if min_reaction_time < 0:\n",
    "                    continue\n",
    "                cdfx, cdfy = get_new_cdf(min_reaction_time)\n",
    "                cdf_q = np.linspace(.5/n_simulations, 1-.5/n_simulations, n_simulations)\n",
    "                for k in range(n_simulations):\n",
    "                    reaction_time = np.interp(cdf_q[k], cdfy, cdfx)\n",
    "                    result = func_fn(reaction_time, speed, ttc)\n",
    "                    if result < 0:  # Only use result if there is an impact.\n",
    "                        vimpact[i, j, k] = -result\n",
    "        with open(filename, \"wb\") as file:\n",
    "            pickle.dump(vimpact, file)\n",
    "    \n",
    "    f, ax = plt.subplots(1, 1)\n",
    "    heatmap = plt.contourf(speeds, ttcs, np.mean(vimpact, axis=2), cmap='hot')\n",
    "    cbar = f.colorbar(heatmap)\n",
    "    plt.title(\"Expected impact speed in case of collision\")\n",
    "    plt.xlabel(\"Initial speed of ego vehicle [m/s]\")\n",
    "    plt.ylabel(\"TTC at which warning is given [s]\")\n",
    "    cbar.ax.set_ylabel(\"Expected impact speed with collision [m/s]\")\n",
    "    \n",
    "    f.savefig(os.path.join(\"figs\", \"{:s}.png\".format(name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_heatplot_fn_vimpact(5, 30, 1, 4, overwrite=OVERWRITE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the KDEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lead vehicle braking\n",
    "\n",
    "Three parameters:\n",
    "\n",
    "- Initial speed ego vehicle (and lead vehicle);\n",
    "- Mean deceleration of lead vehicle;\n",
    "- Speed difference of lead vehicle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(\"data\", \"6_kde\", \"scenario_lead_braking.p\")\n",
    "if os.path.exists(filename) and not OVERWRITE:\n",
    "    kde_lead_braking = kde_from_file(filename)\n",
    "else:\n",
    "    pars = []\n",
    "    for key in leaddec.collections[\"scenario\"]:\n",
    "        scenario = leaddec.get_item(\"scenario\", key)\n",
    "        \n",
    "        vstart, vdiff, amean = 0, 0, 0\n",
    "        for activity in scenario.activities:\n",
    "            if activity.name == \"deceleration target\":\n",
    "                vstart, vend = activity.get_state(time=[activity.get_tstart(), \n",
    "                                                        activity.get_tend()])[0]\n",
    "                vdiff = vstart-vend\n",
    "                amean = vdiff/(activity.get_tend()-activity.get_tstart())\n",
    "                break\n",
    "\n",
    "        if vstart > 0 and vdiff > 0 and amean > 0:\n",
    "            pars.append([vstart, amean, vdiff])\n",
    "\n",
    "    kde_lead_braking = KDE(np.array(pars))\n",
    "    kde_lead_braking.compute_bandwidth()\n",
    "    kde_lead_braking.pickle(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approaching slower vehicle\n",
    "\n",
    "Two parameters:\n",
    "\n",
    "- Initial speed ego vehicle;\n",
    "- Ratio speed ego vehicle over speed target vehicle [0, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(\"data\", \"6_kde\", \"scenario_approaching.p\")\n",
    "if os.path.exists(filename) and not OVERWRITE:\n",
    "    kde_approaching = kde_from_file(filename)\n",
    "else:\n",
    "    pars = []\n",
    "    for key in approaching.collections[\"scenario\"]:\n",
    "        scenario = approaching.get_item(\"scenario\", key)\n",
    "        vego = scenario.get_state(scenario.get_actor_by_name(\"ego vehicle\"), StateVariable.SPEED,\n",
    "                                  scenario.get_tstart())\n",
    "        vtarget = scenario.get_state(scenario.get_actor_by_name(\"target vehicle\"),\n",
    "                                     StateVariable.LON_TARGET, scenario.get_tstart())[0]\n",
    "        if vego > vtarget:\n",
    "            pars.append([vego, vtarget/vego])\n",
    "\n",
    "    kde_approaching = KDE(np.array(pars))\n",
    "    kde_approaching.compute_bandwidth()\n",
    "    kde_approaching.pickle(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cut-in\n",
    "\n",
    "Three parameters\n",
    "\n",
    "- Distance at cut-in\n",
    "- Speed lead vehicle\n",
    "- Speed ego vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(\"data\", \"6_kde\", \"scenario_cutin.p\")\n",
    "if os.path.exists(filename) and not OVERWRITE:\n",
    "    kde_cutin = kde_from_file(filename)\n",
    "else:\n",
    "    pars = []\n",
    "    for key in cutins.collections[\"scenario\"]:\n",
    "        scenario = cutins.get_item(\"scenario\", key)\n",
    "        t_center = (scenario.get_tstart() + scenario.get_tend())/2\n",
    "        vtarget, distance = scenario.get_state(scenario.get_actor_by_name(\"target vehicle\"), \n",
    "                                               StateVariable.LON_TARGET, t_center)\n",
    "        vego = scenario.get_state(scenario.get_actor_by_name(\"ego vehicle\"), StateVariable.SPEED,\n",
    "                                  t_center)\n",
    "        if distance > 0:\n",
    "            pars.append([distance, vtarget, vego])\n",
    "\n",
    "    kde_cutin = KDE(np.array(pars))\n",
    "    kde_cutin.compute_bandwidth()\n",
    "    kde_cutin.pickle(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk in 'normal' situation\n",
    "\n",
    "To calculate the risk, we need to apply importance sampling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case study options list\n",
    "CaseStudy = NamedTuple(\"CaseStudy\", [(\"name\", str),\n",
    "                                     (\"n\", int),\n",
    "                                     (\"parameters\", List[str]),\n",
    "                                     (\"default_parameters\", dict),\n",
    "                                     (\"percentile\", int),\n",
    "                                     (\"simulator\", SimulationString),\n",
    "                                     (\"kde\", KDE),\n",
    "                                     (\"func_validity_check\", Callable),\n",
    "                                     (\"func_get_result\", Callable),\n",
    "                                     (\"func_process_result\", Callable)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_parms(options, par_func):\n",
    "    np.random.seed(0)\n",
    "    pars = np.zeros((options.n, len(options.parameters)))\n",
    "    tries = np.zeros(options.n)\n",
    "    i = 0\n",
    "    while i < options.n:\n",
    "        pars[i, :] = par_func()[0]\n",
    "        tries[i] += 1\n",
    "        if options.func_validity_check(pars[i, :]):\n",
    "            i += 1\n",
    "    df = pd.DataFrame(data=pars, columns=options.parameters)\n",
    "    df[\"tries\"] = tries\n",
    "    return df, pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_simulations(df, pars, options):\n",
    "    result = np.zeros(options.n)\n",
    "    kpi = np.zeros(options.n)\n",
    "    for i, par in enumerate(tqdm(pars)):\n",
    "        par_dict = dict(zip(options.parameters, par))\n",
    "        par_dict.update(options.default_parameters)\n",
    "        result[i] = options.func_get_result(options, par_dict)\n",
    "        kpi[i] = options.func_process_result(result[i])\n",
    "    df[\"result\"] = result\n",
    "    df[\"kpi\"] = kpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo(options, overwrite=False):\n",
    "    filename_df = os.path.join(\"data\", \"7_simulation_results\",\n",
    "                               \"{:s}_mc.csv\".format(options.name))\n",
    "    if os.path.exists(filename_df) and not overwrite:\n",
    "        return pd.read_csv(filename_df, index_col=0)\n",
    "    \n",
    "    df, pars = generate_parms(options, options.kde.sample)\n",
    "    do_simulations(df, pars, options)\n",
    "    df.to_csv(filename_df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_result(df_mc):\n",
    "    prob = np.mean(df_mc[\"kpi\"])\n",
    "    sigma = np.sqrt(np.sum((df_mc[\"kpi\"] - prob)**2)) / len(df_mc)\n",
    "    print(\"Monte Carlo:         Probability of collision: {:.3e} %\".format(prob), end=\"\")\n",
    "    print(\" +/- {:.3e} %\".format(sigma), end=\"\")\n",
    "    print(\" ({:d} simulations)\".format(len(df_mc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_is(df_mc, options, overwrite=False):\n",
    "    filename = os.path.join(\"data\", \"6_kde\", \"{:s}_is.p\".format(options.name))\n",
    "    if os.path.exists(filename) and not overwrite:\n",
    "        return kde_from_file(filename)\n",
    "    \n",
    "    df_sorted = df_mc.sort_values(\"result\")\n",
    "    df_is = df_sorted.iloc[:options.n*options.percentile//100]\n",
    "    data = df_is[options.parameters].values\n",
    "    kde = KDE(data)\n",
    "    kde.compute_bandwidth()\n",
    "    kde.pickle(filename)\n",
    "    return kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importance_sampling(kde, options, overwrite=False):\n",
    "    filename_df = os.path.join(\"data\", \"7_simulation_results\",\n",
    "                               \"{:s}_is.csv\".format(options.name))\n",
    "    if os.path.exists(filename_df) and not overwrite:\n",
    "        return pd.read_csv(filename_df, index_col=0)\n",
    "    \n",
    "    # Generate the parameters.\n",
    "    df, pars = generate_parms(options, kde.sample)\n",
    "    df[\"density_orig\"] = options.kde.score_samples(pars)\n",
    "    df[\"density_is\"] = kde.score_samples(pars)\n",
    "    do_simulations(df, pars, options)\n",
    "    \n",
    "    # Write to file\n",
    "    df.to_csv(filename_df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_result(df_is, df_mc):\n",
    "    values = df_is[\"kpi\"] * df_is[\"density_orig\"] / df_is[\"density_is\"]\n",
    "    values *= np.sum(df_mc[\"tries\"]) / len(df_mc)\n",
    "    values /= np.sum(df_is[\"tries\"]) / len(df_is)\n",
    "    prob = np.mean(values)\n",
    "    sigma = np.sqrt(np.sum((values - prob)**2)) / len(values)\n",
    "    print(\"Importance sampling: Probability of collision: {:.3e} %\".format(prob), end=\"\")\n",
    "    print(\" +/- {:.3e} %\".format(sigma), end=\"\")\n",
    "    print(\" ({:d} simulations)\".format(len(values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_study(options, overwrite=False):\n",
    "    df_mc = monte_carlo(options, overwrite=overwrite)\n",
    "    mc_result(df_mc)\n",
    "    kde_is = create_is(df_mc, options, overwrite=overwrite)\n",
    "    df_is = importance_sampling(kde_is, options, overwrite=overwrite)\n",
    "    is_result(df_is, df_mc)\n",
    "    return df_mc, df_is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lead vehicle braking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kpi_idm(result):\n",
    "    return max(1-result, 0)\n",
    "def get_kpi_acc(result):\n",
    "    if result < 0:\n",
    "        return 1\n",
    "    return 0\n",
    "def check_lb_pars(pars):\n",
    "    if pars[2] <= 0 or pars[2] > pars[0] or pars[1] <= 0:  # dv<0, vend>=0, amean>0\n",
    "        return False\n",
    "    return True\n",
    "def func_for_breakpoint(reactiontime, options, **kwargs):\n",
    "    pars = dict(reactiontime=reactiontime, **kwargs)\n",
    "    return options.simulator.simulation(pars)\n",
    "def func_idm(options, par_dict):\n",
    "    _, prob, result = find_breakpoint(func_for_breakpoint, options=options, **par_dict)\n",
    "    if prob > 0:\n",
    "        return 1 - prob\n",
    "    else:\n",
    "        return 1 + result\n",
    "def func_acc(options, par_dict):\n",
    "    return options.simulator.simulation(par_dict)\n",
    "    \n",
    "s_lb_idm = SimulationLeadBraking(follower=IDMPlus(), follower_parameters=idm_lead_braking_pars)\n",
    "s_lb_acc = SimulationLeadBraking(follower=ACC(), follower_parameters=acc_lead_braking_pars)\n",
    "s_lb_accidm = SimulationLeadBraking(follower=ACCHDM(), follower_parameters=acc_hdm_lead_braking_pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_parameters = dict(n=2000,\n",
    "                          default_parameters=dict(amin=-6),\n",
    "                          parameters=[\"v0\", \"amean\", \"dv\"],\n",
    "                          percentile=10,\n",
    "                          kde=kde_lead_braking,\n",
    "                          func_validity_check=check_lb_pars)\n",
    "parameters = dict(name=\"lead_braking_idm\",\n",
    "                  simulator=s_lb_idm,\n",
    "                  func_get_result=func_idm,\n",
    "                  func_process_result=get_kpi_idm)\n",
    "parameters.update(default_parameters)\n",
    "df_mc, df_is = case_study(CaseStudy(**parameters), overwrite=OVERWRITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict(name=\"lead_braking_acc\",\n",
    "                  simulator=s_lb_acc,\n",
    "                  func_get_result=func_acc,\n",
    "                  func_process_result=get_kpi_acc)\n",
    "parameters.update(default_parameters)\n",
    "df_mc, df_is = case_study(CaseStudy(**parameters), overwrite=OVERWRITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_mc[\"dv\"], df_mc[\"v0\"], '.', label=\"Normal sampling\")\n",
    "plt.plot(df_is[\"dv\"], df_is[\"v0\"], '.', label=\"Importance sampling\")\n",
    "plt.xlabel(\"Speed difference [m/s]\")\n",
    "plt.ylabel(\"Initial speed [m/s]\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict(name=\"lead_braking_accidm\",\n",
    "                  simulator=s_lb_accidm,\n",
    "                  func_get_result=func_idm,\n",
    "                  func_process_result=get_kpi_idm)\n",
    "parameters.update(default_parameters)\n",
    "_ = case_study(CaseStudy(**parameters), overwrite=OVERWRITE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approaching slower vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_as_pars(pars):\n",
    "    if pars[0] <= 0 or pars[1] < 0 or pars[1] >= 1:  # vego>0, 0<=ratio_vtar_vego<1\n",
    "        return False\n",
    "    return True\n",
    "    \n",
    "s_as_idm = SimulationApproaching([IDMPlus()], [idm_approaching_pars], min_simulation_time=5)\n",
    "s_as_acc = SimulationApproaching([ACC()], [acc_approaching_pars], min_simulation_time=5)\n",
    "s_as_accidm = SimulationApproaching([ACCHDM()], [acc_idm_approaching_pars], min_simulation_time=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_parameters = dict(n=2000,\n",
    "                          default_parameters=dict(amin=-6),\n",
    "                          parameters=[\"vego\", \"ratio_vtar_vego\"],\n",
    "                          percentile=10,\n",
    "                          kde=kde_approaching,\n",
    "                          func_validity_check=check_as_pars)\n",
    "parameters = dict(name=\"approaching_slower_idm\",\n",
    "                  simulator=s_as_idm,\n",
    "                  func_get_result=func_idm,\n",
    "                  func_process_result=get_kpi_idm)\n",
    "parameters.update(default_parameters)\n",
    "_ = case_study(CaseStudy(**parameters), overwrite=OVERWRITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict(name=\"approaching_slower_acc\",\n",
    "                  simulator=s_as_acc,\n",
    "                  func_get_result=func_acc,\n",
    "                  func_process_result=get_kpi_acc)\n",
    "parameters.update(default_parameters)\n",
    "_ = case_study(CaseStudy(**parameters), overwrite=OVERWRITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict(name=\"approaching_slower_accidm\",\n",
    "                  simulator=s_as_accidm,\n",
    "                  func_get_result=func_idm,\n",
    "                  func_process_result=get_kpi_idm)\n",
    "parameters.update(default_parameters)\n",
    "df_mc, df_is = case_study(CaseStudy(**parameters), overwrite=OVERWRITE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cut-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ci_pars(pars):\n",
    "    if pars[0] <= 0 or pars[1] < 0 or pars[2] <= 0:  # vego>0, 0<=ratio_vtar_vego<1\n",
    "        return False\n",
    "    return True\n",
    "    \n",
    "s_ci_idm = SimulationCutIn(IDMPlus(), idm_cutin_pars, min_simulation_time=5)\n",
    "s_ci_acc = SimulationCutIn(ACC(), acc_cutin_pars, min_simulation_time=5)\n",
    "s_ci_accidm = SimulationCutIn(ACCHDM(), acc_idm_cutin_pars, min_simulation_time=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_parameters = dict(n=2000,\n",
    "                          default_parameters=dict(amin=-6),\n",
    "                          parameters=[\"dinit\", \"vlead\", \"vego\"],\n",
    "                          percentile=10,\n",
    "                          kde=kde_cutin,\n",
    "                          func_validity_check=check_ci_pars)\n",
    "parameters = dict(name=\"cutin_idm\",\n",
    "                  simulator=s_ci_idm,\n",
    "                  func_get_result=func_idm,\n",
    "                  func_process_result=get_kpi_idm)\n",
    "parameters.update(default_parameters)\n",
    "_ = case_study(CaseStudy(**parameters), overwrite=OVERWRITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict(name=\"cutin_acc\",\n",
    "                  simulator=s_ci_acc,\n",
    "                  func_get_result=func_acc,\n",
    "                  func_process_result=get_kpi_acc)\n",
    "parameters.update(default_parameters)\n",
    "df_mc, df_is = case_study(CaseStudy(**parameters), overwrite=OVERWRITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_mc[\"dinit\"], df_mc[\"vego\"]-df_mc[\"vlead\"], '.', label=\"Normal sampling\")\n",
    "plt.plot(df_is[\"dinit\"], df_is[\"vego\"]-df_mc[\"vlead\"], '.', label=\"Importance sampling\")\n",
    "plt.xlabel(\"Distance at cut-in [m]\")\n",
    "plt.ylabel(\"Speed ego vehicle [m/s]\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict(name=\"cutin_slower_accidm\",\n",
    "                  simulator=s_ci_accidm,\n",
    "                  func_get_result=func_idm,\n",
    "                  func_process_result=get_kpi_idm)\n",
    "parameters.update(default_parameters)\n",
    "df_mc, df_is = case_study(CaseStudy(**parameters), overwrite=OVERWRITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk(overwrite=False):\n",
    "    nmc = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk_lead_braking(follower, follower_parms, name_follower, amin=-3, overwrite=False):\n",
    "    nmc = 10000\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    name = \"risk_lowmu_leadbraking_{:s}_amin{:.0f}\".format(name_follower, int(-amin))\n",
    "    filename = os.path.join(\"data\", \"7_simulation_results\", \"{:s}.p\".format(name))\n",
    "    if os.path.exists(filename) and not overwrite:\n",
    "        with open(filename, \"rb\") as file:\n",
    "            result = pickle.load(file)\n",
    "    else:\n",
    "        simulator = SimulationLeadBraking(follower=follower, follower_parameters=follower_parms)\n",
    "        result = np.zeros(nmc)\n",
    "        for i in tqdm(range(nmc)):\n",
    "            pars = kde_lead_braking.sample()[0]\n",
    "            while not check_validity_lead_braking(pars):\n",
    "                pars = kde_lead_braking.sample()[0]\n",
    "            result[i] = simulator.simulation(dict(v0=pars[0], amean=pars[1], dv=pars[2], amin=amin))\n",
    "        \n",
    "        with open(filename, \"wb\") as file:\n",
    "            pickle.dump(result, file)\n",
    "    \n",
    "    print(\"Probability of collision: {:.4f}\".format(np.mean(result < 0)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risks with low-$\\mu$\n",
    "\n",
    "#### Lead vehicle decelerating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk_lowmu_lead_braking(follower, follower_parms, name_follower, amin=-3, overwrite=False):\n",
    "    nmc = 10000\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    name = \"risk_lowmu_leadbraking_{:s}_amin{:.0f}\".format(name_follower, int(-amin))\n",
    "    filename = os.path.join(\"data\", \"7_simulation_results\", \"{:s}.p\".format(name))\n",
    "    if os.path.exists(filename) and not overwrite:\n",
    "        with open(filename, \"rb\") as file:\n",
    "            result = pickle.load(file)\n",
    "    else:\n",
    "        simulator = SimulationLeadBraking(follower=follower, follower_parameters=follower_parms)\n",
    "        result = np.zeros(nmc)\n",
    "        for i in tqdm(range(nmc)):\n",
    "            pars = kde_lead_braking.sample()[0]\n",
    "            while not check_validity_lead_braking(pars):\n",
    "                pars = kde_lead_braking.sample()[0]\n",
    "            result[i] = simulator.simulation(dict(v0=pars[0], amean=pars[1], dv=pars[2], amin=amin))\n",
    "        \n",
    "        with open(filename, \"wb\") as file:\n",
    "            pickle.dump(result, file)\n",
    "    \n",
    "    print(\"Probability of collision: {:.4f}\".format(np.mean(result < 0)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_idm = risk_lowmu_lead_braking(IDMPlus(), idm_lead_braking_pars, \"idmplus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_acc = risk_lowmu_lead_braking(ACC(), acc_lead_braking_pars, \"acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_accidm = risk_lowmu_lead_braking(ACCHDM(), acc_hdm_lead_braking_pars, \"accidm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approaching slower vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk_lowmu_approaching(follower, follower_parms, name_follower, amin=-3, overwrite=False):\n",
    "    nmc = 10000\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    name = \"risk_lowmu_approaching_{:s}_amin{:.0f}\".format(name_follower, int(-amin))\n",
    "    filename = os.path.join(\"data\", \"7_simulation_results\", \"{:s}.p\".format(name))\n",
    "    if os.path.exists(filename) and not overwrite:\n",
    "        with open(filename, \"rb\") as file:\n",
    "            result = pickle.load(file)\n",
    "    else:\n",
    "        simulator = SimulationApproaching([follower], [follower_parms], min_simulation_time=5)\n",
    "        result = np.zeros(nmc)\n",
    "        for i in tqdm(range(nmc)):\n",
    "            pars = kde_approaching.sample()[0]\n",
    "            while not check_validity_approaching(pars):\n",
    "                pars = kde_approaching.sample()[0]\n",
    "            result[i] = simulator.simulation(dict(vego=pars[0], ratio_vtar_vego=pars[1], amin=amin))\n",
    "        \n",
    "        with open(filename, \"wb\") as file:\n",
    "            pickle.dump(result, file)\n",
    "    \n",
    "    print(\"Probability of collision: {:.4f}\".format(np.mean(result < 0)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_idm = risk_lowmu_approaching(IDMPlus(), idm_approaching_pars, \"idmplus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_acc = risk_lowmu_approaching(ACC(), acc_approaching_pars, \"acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_accidm = risk_lowmu_approaching(ACCHDM(), acc_idm_approaching_pars, \"accidm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cut-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_validity_cutin(pars):\n",
    "    # Speeds should be strictly positive\n",
    "    if pars[1] <= 0 or pars[2] <= 0:\n",
    "        return False\n",
    "    \n",
    "    # Initial distance should be strictly positive\n",
    "    if pars[0] <= 0:\n",
    "        return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk_lowmu_cutin(follower, follower_parms, name_follower, amin=-3, overwrite=False):\n",
    "    nmc = 10000\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    name = \"risk_lowmu_cutin_{:s}_amin{:.0f}\".format(name_follower, int(-amin))\n",
    "    filename = os.path.join(\"data\", \"7_simulation_results\", \"{:s}.p\".format(name))\n",
    "    if os.path.exists(filename) and not overwrite:\n",
    "        with open(filename, \"rb\") as file:\n",
    "            result = pickle.load(file)\n",
    "    else:\n",
    "        simulator = SimulationApproaching([follower], [follower_parms], min_simulation_time=5)\n",
    "        result = np.zeros(nmc)\n",
    "        for i in tqdm(range(nmc)):\n",
    "            pars = kde_cutin.sample()[0]\n",
    "            while not check_validity_cutin(pars):\n",
    "                pars = kde_cutin.sample()[0]\n",
    "                \n",
    "            # If speed target is faster, no need to simulate\n",
    "            if pars[1] >= pars[2]:\n",
    "                result[i] = pars[0]\n",
    "                continue\n",
    "                \n",
    "            result[i] = simulator.simulation(dict(vego=pars[2], ratio_vtar_vego=pars[1]/pars[2], \n",
    "                                                  amin=amin, init_position=pars[0]))\n",
    "        \n",
    "        with open(filename, \"wb\") as file:\n",
    "            pickle.dump(result, file)\n",
    "    \n",
    "    print(\"Probability of collision: {:.4f}\".format(np.mean(result < 0)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_idm = risk_lowmu_cutin(IDMPlus(), idm_approaching_pars, \"idmplus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_acc = risk_lowmu_cutin(ACC(), acc_approaching_pars, \"acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_accidm = risk_lowmu_cutin(ACCHDM(), acc_idm_approaching_pars, \"accidm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk of late notice\n",
    "\n",
    "#### Lead vehicle decelerating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk_latenotice_lead_braking(follower, follower_parms, name_follower, distance_notice=60, \n",
    "                                 overwrite=False):\n",
    "    nmc = 10000\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    name = \"risk_latenotice_leadbraking_{:s}_d{:d}\".format(name_follower, int(distance_notice))\n",
    "    filename = os.path.join(\"data\", \"7_simulation_results\", \"{:s}.p\".format(name))\n",
    "    if os.path.exists(filename) and not overwrite:\n",
    "        with open(filename, \"rb\") as file:\n",
    "            result = pickle.load(file)\n",
    "    else:\n",
    "        simulator = SimulationLeadBraking(follower=follower, follower_parameters=follower_parms)\n",
    "        result = np.zeros(nmc)\n",
    "        for i in tqdm(range(nmc)):\n",
    "            pars = kde_lead_braking.sample()[0]\n",
    "            while not check_validity_lead_braking(pars):\n",
    "                pars = kde_lead_braking.sample()[0]\n",
    "                \n",
    "            parms = dict(v0=pars[0], amean=pars[1], dv=pars[2], amin=-6)\n",
    "            if name_follower in [\"idmplus\", \"accidm\"]:\n",
    "                parms[\"max_view\"] = distance_notice\n",
    "            if name_follower in [\"acc\", \"accidm\"]:\n",
    "                parms[\"sensor_range\"] = distance_notice\n",
    "            result[i] = simulator.simulation(parms)\n",
    "        \n",
    "        with open(filename, \"wb\") as file:\n",
    "            pickle.dump(result, file)\n",
    "    \n",
    "    print(\"Probability of collision: {:.4f}\".format(np.mean(result < 0)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_idm = risk_latenotice_lead_braking(IDMPlus(), idm_lead_braking_pars, \"idmplus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_acc = risk_latenotice_lead_braking(ACC(), acc_lead_braking_pars, \"acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_accidm = risk_latenotice_lead_braking(ACCHDM(), acc_hdm_lead_braking_pars, \"accidm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approaching slower vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk_latenotice_approaching(follower, follower_parms, name_follower, , \n",
    "                                overwrite=False):\n",
    "    nmc = 10000\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    name = \"risk_latenotice_approaching_{:s}_d{:.0f}\".format(name_follower, int(distance_notice))\n",
    "    filename = os.path.join(\"data\", \"7_simulation_results\", \"{:s}.p\".format(name))\n",
    "    if os.path.exists(filename) and not overwrite:\n",
    "        with open(filename, \"rb\") as file:\n",
    "            result = pickle.load(file)\n",
    "    else:\n",
    "        simulator = SimulationApproaching([follower], [follower_parms], min_simulation_time=5)\n",
    "        result = np.zeros(nmc)\n",
    "        for i in tqdm(range(nmc)):\n",
    "            pars = kde_approaching.sample()[0]\n",
    "            while not check_validity_approaching(pars):\n",
    "                pars = kde_approaching.sample()[0]\n",
    "            parms = dict(vego=pars[0], ratio_vtar_vego=pars[1], amin=-6)\n",
    "            if name_follower in [\"idmplus\", \"accidm\"]:\n",
    "                parms[\"max_view\"] = distance_notice\n",
    "            if name_follower in [\"acc\", \"accidm\"]:\n",
    "                parms[\"sensor_range\"] = distance_notice\n",
    "            result[i] = simulator.simulation(parms)\n",
    "        \n",
    "        with open(filename, \"wb\") as file:\n",
    "            pickle.dump(result, file)\n",
    "    \n",
    "    print(\"Probability of collision: {:.4f}\".format(np.mean(result < 0)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_idm = risk_latenotice_approaching(IDMPlus(), idm_approaching_pars, \"idmplus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_acc = risk_latenotice_approaching(ACC(), acc_approaching_pars, \"acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_accidm = risk_latenotice_approaching(ACCHDM(), acc_idm_approaching_pars, \"accidm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cut-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk_lowmu_cutin(follower, follower_parms, name_follower, amin=-3, overwrite=False):\n",
    "    nmc = 10000\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    name = \"risk_lowmu_cutin_{:s}_amin{:.0f}\".format(name_follower, int(-amin))\n",
    "    filename = os.path.join(\"data\", \"7_simulation_results\", \"{:s}.p\".format(name))\n",
    "    if os.path.exists(filename) and not overwrite:\n",
    "        with open(filename, \"rb\") as file:\n",
    "            result = pickle.load(file)\n",
    "    else:\n",
    "        simulator = SimulationApproaching([follower], [follower_parms], min_simulation_time=5)\n",
    "        result = np.zeros(nmc)\n",
    "        for i in tqdm(range(nmc)):\n",
    "            pars = kde_cutin.sample()[0]\n",
    "            while not check_validity_cutin(pars):\n",
    "                pars = kde_cutin.sample()[0]\n",
    "                \n",
    "            # If speed target is faster, no need to simulate\n",
    "            if pars[1] >= pars[2]:\n",
    "                result[i] = pars[0]\n",
    "                continue\n",
    "                \n",
    "            result[i] = simulator.simulation(dict(vego=pars[2], ratio_vtar_vego=pars[1]/pars[2], \n",
    "                                                  amin=amin, init_position=pars[0]))\n",
    "        \n",
    "        with open(filename, \"wb\") as file:\n",
    "            pickle.dump(result, file)\n",
    "    \n",
    "    print(\"Probability of collision: {:.4f}\".format(np.mean(result < 0)))\n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
