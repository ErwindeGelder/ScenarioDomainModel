{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments for paper on surrogate metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy.signal\n",
    "import scipy.spatial.distance as dist\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from simulation import WangStamatiadis, WSDriver, SimulationApproaching, ws_approaching_pars, \\\n",
    "    LeaderInteraction, IDMPlus, SimulationLongitudinal, IDMParameters, LeaderInteractionParameters\n",
    "from stats import KDE, kde_from_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERWRITE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show that our metric is a generalisation of W&S' metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_MONTE_CARLO_WS = 500\n",
    "WS_TTCS = np.linspace(.5, 4, 36)\n",
    "WS_SPEED_DIFFS = [10, 20, 30]\n",
    "WS_LINESTYLES = ['-', '--', ':']\n",
    "WS_COLORS = [(0, 0, 0), (.5, .5, .5)]\n",
    "WS_LINEWIDTHS = [3, 3]\n",
    "WS_FILENAME = os.path.join(\"data\", \"7_simulation_results\", \"ws_comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = WSDriver()\n",
    "ws = WangStamatiadis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ws_comparison(tolerance=0.2):\n",
    "    simulation = SimulationApproaching([driver], [ws_approaching_pars], tolerance=tolerance,\n",
    "                                   max_simulation=500)\n",
    "    simulation.min_simulations = 20\n",
    "    def ws_with_our_method(ttc: float, speed_diff: float):\n",
    "        return simulation.get_probability(dict(vego=speed_diff, ratio_vtar_vego=0, \n",
    "                                               init_position=ttc*speed_diff))\n",
    "\n",
    "    \n",
    "    FILENAME = WS_FILENAME + \"_tol{:.0f}.p\".format(100*tolerance)\n",
    "    if os.path.exists(FILENAME):\n",
    "        with open(FILENAME, \"rb\") as file:\n",
    "            result = pickle.load(file)\n",
    "    if not os.path.exists(FILENAME) or OVERWRITE or \\\n",
    "            not result.shape == (len(WS_TTCS), len(WS_SPEED_DIFFS), 2):\n",
    "        result = np.zeros((len(WS_TTCS), len(WS_SPEED_DIFFS), 2))\n",
    "        np.random.seed(0)\n",
    "        for i, ttc in enumerate(WS_TTCS):\n",
    "            for j, speed_diff in enumerate(WS_SPEED_DIFFS):\n",
    "                result[i, j, 0] = ws.prob_collision(ttc, speed_diff)\n",
    "                result[i, j, 1] = ws_with_our_method(ttc, speed_diff)\n",
    "        with open(FILENAME, \"wb\") as file:\n",
    "            pickle.dump(result, file)\n",
    "    \n",
    "    for i, speed_diff in enumerate(WS_SPEED_DIFFS):\n",
    "        plt.plot(WS_TTCS, result[:, i, 0], ls=WS_LINESTYLES[i], color=WS_COLORS[0], \n",
    "                 lw=WS_LINEWIDTHS[0])\n",
    "        plt.plot(WS_TTCS, result[:, i, 1], ls=WS_LINESTYLES[i], color=WS_COLORS[1],\n",
    "                 lw=WS_LINEWIDTHS[1])\n",
    "    plt.xlabel(\"TTC [s]\")\n",
    "    plt.ylabel(\"$P(C|x)$ according to the WS metric\")\n",
    "    plt.xlim(WS_TTCS[0], WS_TTCS[-1])\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_comparison(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_comparison(0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply method on NGSIM data set to create a risk metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NGSIM_DATA = os.path.join(\"data\", \"8_interactions_v3\", \n",
    "                          \"dNGSIM_iLongitudinal_mFull_Reconstruction_e100_wi1_w1_hs32_bs2\",\n",
    "                          \"interactions.pkl\")\n",
    "NGSIM_KDE = os.path.join(\"data\", \"6_kde\", \"NGSIM2.p\")\n",
    "NGSIM_PROB_COLLISION = os.path.join(\"data\", \"7_simulation_results\", \n",
    "                                    \"prob_collision_NGSIM2.csv\")\n",
    "SCALING_GRID = [2, .5, 2, .25]\n",
    "\n",
    "DELTA_T = 0.1\n",
    "NHORIZON = 50\n",
    "D_SVD = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data.\n",
    "with open(NGSIM_DATA, 'rb') as file:\n",
    "    all_interactions = pickle.load(file)\n",
    "locations = sorted(all_interactions.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for speed and acceleration\n",
    "def filter_signal(signal):\n",
    "    return scipy.signal.savgol_filter(signal, 15, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pars(vel_acc):\n",
    "    if len(vel_acc) < 15:\n",
    "        return np.zeros((0, NHORIZON+2))\n",
    "    if np.max(np.abs(np.diff(vel_acc['Velocity_X']))) > 1.5:\n",
    "        return np.zeros((0, NHORIZON+2))\n",
    "    \n",
    "    data = vel_acc.copy()\n",
    "    data['ax_savgol'] = filter_signal(data[\"Acceleration_X\"])\n",
    "    data['vx_savgol'] = filter_signal(data[\"Velocity_X\"])\n",
    "    is_possible = np.logical_and(data.index < data.index[-1] - DELTA_T*NHORIZON,\n",
    "                                 np.mod(np.arange(len(data)), 10) == 0)\n",
    "    if not np.any(is_possible):\n",
    "        return np.zeros((0, NHORIZON+2))\n",
    "    delta_ts = np.array([np.arange(NHORIZON+1)*DELTA_T]*np.sum(is_possible))\n",
    "    times = np.array([data.loc[is_possible].index]*(NHORIZON+1)).T\n",
    "    speeds = np.interp(times+delta_ts, data.index, data['vx_savgol'])\n",
    "    accelerations = data.loc[is_possible, \"ax_savgol\"]\n",
    "    return np.concatenate((np.atleast_2d(accelerations).T, speeds), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = []\n",
    "for location in locations:\n",
    "    parameters += [get_pars(interaction['leader']) for interaction in \n",
    "                   all_interactions[location].values()]\n",
    "pars = np.concatenate(parameters).T\n",
    "mean_pars = np.mean(pars, axis=1)\n",
    "\n",
    "u, s, vt = np.linalg.svd((pars.T-mean_pars).T, full_matrices=False)\n",
    "v1t = vt[:D_SVD]\n",
    "s1 = s[:D_SVD]\n",
    "u1 = u[:, :D_SVD]\n",
    "u11 = u[:2, :D_SVD]\n",
    "\n",
    "kde = KDE(v1t.T, scaling=True)\n",
    "kde.set_bandwidth(kde.silverman())\n",
    "kde.constrained_sample(matrix=u11*s1, vector=[0.0, 10.0])\n",
    "kde.pickle(NGSIM_KDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_speed_profiles(init_acc, init_vel, n_plots=50):\n",
    "    np.random.seed(0)\n",
    "    samples = kde.constrained_sample(n_samples=n_plots, \n",
    "                                     vector=[init_acc-mean_pars[0], init_vel-mean_pars[1]])\n",
    "    vprofiles = np.dot(samples*s1, u1.T)[:, 1:] + mean_pars[1:]\n",
    "    for vprofile in vprofiles:\n",
    "        plt.plot(np.arange(NHORIZON+1)*DELTA_T, vprofile, c=(.4, .4, .4))\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(\"Speed [m/s]\")\n",
    "    plt.title(\"Initial acceleration: {:.0f} m/s$^2$, initial speed: {:.0f} m/s\"\n",
    "              .format(init_acc, init_vel))\n",
    "plot_speed_profiles(1.0, 15.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_speed_profiles(-1, 15.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leader_parameters(**kwargs):\n",
    "    return LeaderInteractionParameters(init_position=kwargs[\"gap\"],\n",
    "                                       init_speed=kwargs[\"v0_lead\"],\n",
    "                                       velocities=kwargs[\"velocities\"],\n",
    "                                       times=kwargs[\"times\"])\n",
    "\n",
    "def follower_parameters(**kwargs):\n",
    "    return IDMParameters(amin=kwargs[\"amin\"],\n",
    "                         speed=kwargs[\"v0_host\"],\n",
    "                         n_reaction=int(kwargs[\"tr\"]*100),\n",
    "                         init_speed=kwargs[\"v0_host\"],\n",
    "                         init_position=0)\n",
    "\n",
    "def get_other_pars(**kwargs):\n",
    "    # Get the speed difference and the mean acceleration from the KDE.\n",
    "    sample = kde.constrained_sample(n_samples=1, \n",
    "                                    vector=[kwargs[\"a0_lead\"]-mean_pars[0], \n",
    "                                            kwargs[\"v0_lead\"]-mean_pars[1]])\n",
    "    kwargs[\"velocities\"] = (np.dot(sample*s1, u1.T)[:, 1:] + mean_pars[1:])[0]\n",
    "    kwargs[\"times\"] = np.arange(NHORIZON+1)*DELTA_T    \n",
    "    \n",
    "    # Get reaction time from a lognormal distribution with mean=.92, std=0.28\n",
    "    if \"tr\" not in kwargs:\n",
    "        kwargs[\"tr\"] = np.random.lognormal(np.log(.92**2 / np.sqrt(.92**2 + .28**2)), \n",
    "                                           np.sqrt(np.log(1 + .28**2/.92**2)))\n",
    "    \n",
    "    # Get the braking capacity from a truncated normal distribution\n",
    "    if \"amin\" not in kwargs:\n",
    "        while True:\n",
    "            kwargs[\"amin\"] = np.random.normal(-8.45, 1.4)\n",
    "            if -12.68 < kwargs[\"amin\"] < -4.23:\n",
    "                break\n",
    "    \n",
    "    return kwargs\n",
    "\n",
    "simulation = SimulationLongitudinal(LeaderInteraction(), leader_parameters,\n",
    "                                    IDMPlus(), follower_parameters)\n",
    "simulation.min_simulation_time = 5\n",
    "\n",
    "def get_probability(plot=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Parameters to provide:\n",
    "    - v0_lead\n",
    "    - a0_lead\n",
    "    - v0_host\n",
    "    - gap\n",
    "    \"\"\"\n",
    "    # If the host speed is zero, always return 0.0\n",
    "    if \"v0_host\" in kwargs:\n",
    "        if kwargs[\"v0_host\"] <= 0.0:\n",
    "            return 0.0\n",
    "    \n",
    "    min_sim = 10\n",
    "    max_sim = 100\n",
    "    results = np.zeros(max_sim)\n",
    "    for i in range(max_sim):\n",
    "        parameters = get_other_pars(**kwargs)\n",
    "        results[i] = simulation.simulation(parameters)\n",
    "        \n",
    "        if i+1 >= min_sim:\n",
    "            # If results are all the same, return either 0.0 or 1.0\n",
    "            if np.std(results[:i+1]) < 1e-8:\n",
    "                if results[0] > 0.0:\n",
    "                    return 0.0\n",
    "                return 1.0\n",
    "            \n",
    "            kde_result = KDE(results[:i+1], scaling=True)\n",
    "            kde_result.compute_bandwidth()\n",
    "            cdf_zero = kde_result.cdf(np.array([0.0]))[0]\n",
    "            if np.sqrt(cdf_zero*(1-cdf_zero)/(i+1)) < 0.1:\n",
    "                break\n",
    "    \n",
    "    if np.isnan(cdf_zero):\n",
    "        asfdasdffd\n",
    "        \n",
    "    \n",
    "\n",
    "    if plot:\n",
    "        _, axes = plt.subplots(1, 1)\n",
    "        minx = min(np.min(results[:i+1]), 0) - 2*kde_result.get_bandwidth()\n",
    "        maxx = max(np.max(results[:i+1]), 0) + 2*kde_result.get_bandwidth()\n",
    "        x_cdf = np.linspace(minx, maxx)\n",
    "        y_cdf = kde_result.cdf(x_cdf)\n",
    "        axes.plot(x_cdf, y_cdf)\n",
    "        axes.set_xlim(minx, maxx)\n",
    "        axes.plot(results[:i+1], np.zeros(i+1), '|')\n",
    "        axes.set_title(\"N={:d}, F(0)={:.3f} +/- {:.3f}\".format(i, cdf_zero,\n",
    "                                                               np.sqrt(cdf_zero*(1-cdf_zero)/(i+1))))\n",
    "        \n",
    "    return cdf_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show result of single simulation.\n",
    "np.random.seed(0)\n",
    "simulation.simulation(get_other_pars(v0_lead=15, a0_lead=-1, v0_host=20, gap=10), plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = -2\n",
    "prob_ngsim(v_lead[i], a_lead[i], v_host[i], distance[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show result of calculating probability.\n",
    "np.random.seed(1)\n",
    "get_probability(v0_lead=10, a0_lead=-1, \n",
    "                v0_host=12, gap=np.exp(-3.5), plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid\n",
    "def grid_pars(interaction):\n",
    "    if len(interaction['leader']) < 15:\n",
    "        return np.zeros((0, 4))\n",
    "    interaction['leader']['ax_savgol'] = filter_signal(interaction['leader'][\"Acceleration_X\"])\n",
    "    interaction['leader']['vx_savgol'] = filter_signal(interaction['leader'][\"Velocity_X\"])\n",
    "    pars = pd.DataFrame(interaction[\"leader\"][[\"vx_savgol\", \"ax_savgol\"]].values,\n",
    "                        columns=[\"v0_lead\", \"a0_lead\"], index=interaction[\"leader\"].index)\n",
    "    interaction['follower']['vx_savgol'] = filter_signal(interaction['follower'][\"Velocity_X\"])\n",
    "    pars[\"v0_host\"] = interaction[\"follower\"][\"vx_savgol\"]\n",
    "    gap = (interaction[\"leader\"][\"Position_X\"] - interaction[\"follower\"][\"Position_X\"] - \n",
    "           interaction[\"leader\"][\"Length\"]/2 - interaction[\"follower\"][\"Length\"]/2)\n",
    "    gap[gap < 0] = np.exp(-5)  # Lower limit\n",
    "    pars[\"loggap\"] = np.log(gap)\n",
    "    return pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if OVERWRITE or not os.path.exists(NGSIM_PROB_COLLISION):\n",
    "    parameters = []\n",
    "    for location in locations:\n",
    "        parameters += [grid_pars(interaction) for interaction in \n",
    "                       all_interactions[location].values()]\n",
    "    parameters = np.concatenate(parameters)\n",
    "    \n",
    "    grid = parameters.copy()\n",
    "    grid[:, 0] = np.clip(grid[:, 0], 0, 100)\n",
    "    # grid[:, 1] = np.clip(grid[:, 1], -5, 5)\n",
    "    grid[:, 2] = np.clip(grid[:, 2], 0, 100)\n",
    "    grid[:, 3] = np.clip(grid[:, 3], -5, 5)\n",
    "    grid = np.round(grid / SCALING_GRID)\n",
    "    grid = np.unique(grid, axis=0)\n",
    "    grid = grid * SCALING_GRID\n",
    "else:\n",
    "    df = pd.read_csv(NGSIM_PROB_COLLISION, index_col=0)\n",
    "    grid = df[[\"v0_lead\", \"a0_lead\", \"v0_host\", \"loggap\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the collision probability for the grid\n",
    "def get_probability_grid_pars(row):\n",
    "    return get_probability(v0_lead=row[0], a0_lead=row[1],\n",
    "                           v0_host=row[2], gap=np.exp(row[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if OVERWRITE or not os.path.exists(NGSIM_PROB_COLLISION):\n",
    "    prob_collision = [get_probability_grid_pars(row) for row in tqdm(grid)]\n",
    "    df = pd.DataFrame(grid, columns=(\"v0_lead\", \"a0_lead\", \"v0_host\", \"loggap\"))\n",
    "    df[\"prob_collision\"] = prob_collision\n",
    "    df.to_csv(NGSIM_PROB_COLLISION)\n",
    "else:\n",
    "    prob_collision = df[\"prob_collision\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(prob_collision, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for the interpolation\n",
    "scaling = np.std(grid, axis=0)\n",
    "bandwidth = 0.30  # Very close to the Silverman's rule of thumb\n",
    "grid_scaled = grid / scaling\n",
    "def prob_ngsim(v0_lead, a0_lead, v0_host, gap):\n",
    "    tmp = np.array([[v0_lead, a0_lead, v0_host, np.log(gap)]]) / scaling\n",
    "    sq_distance = dist.cdist(grid_scaled, tmp, metric='sqeuclidean')\n",
    "    weights = np.exp(-sq_distance / 2 / (bandwidth**2))  # Bandwidth of .3\n",
    "    probability = np.dot(prob_collision, weights) / np.sum(weights, axis=0)\n",
    "    #if probability > 0.3:\n",
    "    #    print(tmp * scaling)\n",
    "    #    print(grid_scaled[np.argmax(weights)] * scaling)\n",
    "    #    aasffa\n",
    "    return probability\n",
    "print(\"Bandwidth matrix has at diagonal:\")\n",
    "print((bandwidth / scaling)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method for adding data to grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_data_to_grid(pars):\n",
    "    \"\"\" \n",
    "    Use this function in the following manner:\n",
    "    \n",
    "    add_data_to_grid(<parameters>)\n",
    "    \"\"\"\n",
    "    global grid, scaling, grid_scaled, prob_collision, df\n",
    "    pars = np.round(pars / SCALING_GRID)\n",
    "    pars = np.unique(pars, axis=0)\n",
    "    pars = pars * SCALING_GRID\n",
    "    new = [not np.any((grid == pars[i, :]).all(axis=1)) for i in range(len(pars))]\n",
    "    if not np.any(new):\n",
    "        return grid, prob_collision\n",
    "    print(\"{:d}/{:d} values added\".format(np.sum(new), len(new)))\n",
    "    pars = pars[new, :]\n",
    "    df_new = pd.DataFrame(pars, columns=(\"v0_lead\", \"a0_lead\", \"v0_host\", \"loggap\"))\n",
    "    pcol = [get_probability_grid_pars(row) for row in pars]\n",
    "    df_new[\"prob_collision\"] = pcol\n",
    "    df = pd.concat((df, df_new), ignore_index=True)\n",
    "    df.to_csv(NGSIM_PROB_COLLISION)\n",
    "    grid = df[[\"v0_lead\", \"a0_lead\", \"v0_host\", \"loggap\"]].values\n",
    "    scaling = np.std(grid, axis=0)\n",
    "    grid_scaled = grid / scaling\n",
    "    prob_collision = df[\"prob_collision\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try method for scenario 1: No risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots(time, v_lead, a_lead, v_host, distance):    \n",
    "    # Calculate WS prob\n",
    "    prob_ws = np.zeros_like(time)\n",
    "    for i, (vh, vl, gap) in enumerate(zip(v_host, v_lead, distance)):\n",
    "        if vh > vl:\n",
    "            ttc = gap / (vh - vl)\n",
    "            prob_ws[i] = ws.prob_collision(ttc, vh-vl)\n",
    "            \n",
    "    # Calculate prob with new method\n",
    "    add_data_to_grid(np.array([v_lead, a_lead, v_host, np.log(distance)]).T)\n",
    "    prob_new = np.zeros_like(time)\n",
    "    for i, (vh, vl, al, gap) in enumerate(zip(v_host, v_lead, a_lead, distance)):\n",
    "        prob_new[i] = prob_ngsim(vl, al, vh, gap)\n",
    "        \n",
    "    _, ax1 = plt.subplots()\n",
    "    ax1.plot(time, v_host, c=WS_COLORS[0], lw=WS_LINEWIDTHS[0], ls=WS_LINESTYLES[0])\n",
    "    ax1.plot(time, v_lead, c=WS_COLORS[0], lw=WS_LINEWIDTHS[0], ls=WS_LINESTYLES[1])\n",
    "    ax1.set_xlabel(\"Time [s]\")\n",
    "    ax1.set_ylabel(\"Speed [m/s]\", color=WS_COLORS[0])\n",
    "    ax1.grid()\n",
    "    ax1.set_xlim(time[0], time[-1])\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(time, distance, c=WS_COLORS[1], lw=WS_LINEWIDTHS[0], ls=WS_LINESTYLES[2])\n",
    "    ax2.set_ylabel(\"Distance[m]\", color=WS_COLORS[1])\n",
    "    \n",
    "    ax1_ticks = ax1.get_yticks()[1:-1]\n",
    "    nticks = len(ax1_ticks)\n",
    "    n = 1\n",
    "    while int(np.max(distance)/n)+1 - int(np.min(distance/n)) >= nticks:\n",
    "        n += 1\n",
    "    ax2_ticks = (np.arange(nticks)+int(np.min(distance)/n))*n\n",
    "    ax2.set_yticks(ax2_ticks)\n",
    "    ax1_ylim = ax1.get_ylim()\n",
    "    aspect_ratio = (ax2_ticks[-1] - ax2_ticks[0]) / (ax1_ticks[-1] - ax1_ticks[0])\n",
    "    ax2.set_ylim(ax2_ticks[0] - aspect_ratio * (ax1_ticks[0] - ax1_ylim[0]),\n",
    "                 ax2_ticks[-1] + aspect_ratio * (ax1_ylim[1] - ax1_ticks[-1]))\n",
    "    \n",
    "    plt.subplots()\n",
    "    plt.plot(time, prob_ws, c=WS_COLORS[0], lw=WS_LINEWIDTHS[0])\n",
    "    plt.plot(time, prob_new, c=WS_COLORS[1], lw=WS_LINEWIDTHS[1])\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlim(time[0], time[-1])\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(\"Probability of collision\")\n",
    "    plt.grid()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parms = dict(v0_leader=20, dv_leader=10, a_leader=3, t_leader=3,\n",
    "             v0_host=24, dv1_host=16, dv2_host=2, a1_host=4, a2_host=0.5, t_host=2,\n",
    "             d_init=40, tmax=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(v0_leader, dv_leader, a_leader, t_leader,\n",
    "                v0_host, dv1_host, dv2_host, a1_host, a2_host, t_host,\n",
    "                d_init, tmax):\n",
    "    time = np.arange(0, tmax+0.01, 0.01)\n",
    "\n",
    "    v_lead = v0_leader * np.ones_like(time)\n",
    "    a_lead = np.zeros_like(time)\n",
    "    v_lead[time > dv_leader/a_leader+t_leader] = v0_leader - dv_leader\n",
    "    i = np.logical_and(time > t_leader, time <= dv_leader/a_leader+t_leader)\n",
    "    v_lead[i] = dv_leader/2*(np.cos(np.pi*(time[i]-t_leader)*a_leader/dv_leader)-1)+v0_leader\n",
    "    a_lead[i] = (-dv_leader/2*np.sin(np.pi*(time[i]-t_leader)*a_leader/dv_leader) * \n",
    "                 np.pi*a_leader/dv_leader)\n",
    "\n",
    "    v_host = v0_host * np.ones_like(time)\n",
    "    a_host = np.zeros_like(time)\n",
    "    t1 = dv1_host / a1_host + t_host\n",
    "    i = np.logical_and(time > t_host, time <= t1)\n",
    "    v_host[i] = dv1_host/2*(np.cos(np.pi*(time[i]-t_host)*a1_host/dv1_host)-1)+v0_host\n",
    "    a_host[i] = -dv1_host/2*np.sin(np.pi*(time[i]-t_host)*a1_host/dv1_host)*np.pi*a1_host/dv1_host\n",
    "    t2 = t1 + dv2_host / a2_host\n",
    "    i = np.logical_and(time > t1, time <= t2)\n",
    "    v_host[i] = -dv2_host/2*(np.cos(np.pi*(time[i]-t1)*a2_host/dv2_host)-1)+v0_host-dv1_host\n",
    "    a_host[i] = dv2_host/2*np.sin(np.pi*(time[i]-t1)*a2_host/dv2_host)*np.pi*a2_host/dv2_host\n",
    "    v_host[time > t2] = v0_host - dv1_host + dv2_host\n",
    "    distance = d_init + np.cumsum(v_lead - v_host)*0.01\n",
    "    \n",
    "    return time, v_lead, a_lead, v_host, distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plots(*create_data(**parms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try method for scenario 2: Risky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parms[\"t_host\"] = 4\n",
    "make_plots(*create_data(**parms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try method for scenario 3: Collision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parms[\"v0_host\"] = 25\n",
    "parms[\"a1_host\"] = 5\n",
    "parms[\"d_init\"] = 34.933\n",
    "parms[\"tmax\"] = 6\n",
    "make_plots(*create_data(**parms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plots(time, v_lead, a_lead, v_host, distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate partial derivatives of our method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOLERANCE = 0.02\n",
    "MIN_SIMULATIONS = 100\n",
    "MAX_SIMULATIONS = 500\n",
    "FIXED_PARAMETERS = dict(a0_lead=0)\n",
    "VARIABLE_PARAMETERS = dict(v0_lead=(9.8, 10, 10.2),\n",
    "                           v0_host=(19.8, 20, 20.2),\n",
    "                           gap=(19.5, 20, 20.5),\n",
    "                           amin=(-4.8, -5, -5.2),\n",
    "                           tr=(.90, .95, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation.tolerance = TOLERANCE\n",
    "simulation.min_simulations = MIN_SIMULATIONS\n",
    "simulation.max_simulations = MAX_SIMULATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "parameters = FIXED_PARAMETERS.copy()\n",
    "for key, values in VARIABLE_PARAMETERS.items():\n",
    "    parameters[key] = values[1]\n",
    "print(\"Default simulation result: {:.3f}\".format(get_probability(**parameters)))\n",
    "for key, values in VARIABLE_PARAMETERS.items():\n",
    "    print()\n",
    "    results = [0, 0]\n",
    "    for i, value in enumerate([values[0], values[2]]):\n",
    "        parameters[key] = value\n",
    "        results[i] = get_probability(**parameters)\n",
    "        print(\"Change '{:s}' to {}, result: {:.3f}\".format(key, value, results[i]))\n",
    "    parameters[key] = values[1]  # Change back to default value\n",
    "    \n",
    "    print(\"Partial derivative for {:s}: {:.3f}\"\n",
    "          .format(key, (results[1]-results[0])/(values[2]-values[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
