{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments for paper on surrogate metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy.signal\n",
    "import scipy.spatial.distance as dist\n",
    "from simulation import WangStamatiadis, WSDriver, SimulationApproaching, ws_approaching_pars, \\\n",
    "    LeaderInteraction, IDMPlus, SimulationLongitudinal, IDMParameters, LeaderInteractionParameters\n",
    "from stats import KDE, kde_from_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERWRITE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show that our metric is a generalisation of W&S' metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_MONTE_CARLO_WS = 500\n",
    "WS_TTCS = np.linspace(.5, 4, 36)\n",
    "WS_SPEED_DIFFS = [10, 20, 30]\n",
    "WS_LINESTYLES = ['-', '--', ':']\n",
    "WS_COLORS = [(0, 0, 0), (.5, .5, .5)]\n",
    "WS_LINEWIDTHS = [3, 3]\n",
    "WS_FILENAME = os.path.join(\"data\", \"7_simulation_results\", \"ws_comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tolerance = 0.02\n",
    "driver = WSDriver()\n",
    "simulation = SimulationApproaching([driver], [ws_approaching_pars], tolerance=tolerance,\n",
    "                                   max_simulation=500)\n",
    "simulation.min_simulations = 20\n",
    "def ws_with_our_method(ttc: float, speed_diff: float):\n",
    "    return simulation.get_probability(dict(vego=speed_diff, ratio_vtar_vego=0, \n",
    "                                           init_position=ttc*speed_diff))\n",
    "    \n",
    "ws = WangStamatiadis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = WS_FILENAME + \"_tol{:.0f}.p\".format(100*tolerance)\n",
    "if os.path.exists(FILENAME):\n",
    "    with open(WS_FILENAME, \"rb\") as file:\n",
    "        result = pickle.load(file)\n",
    "if not os.path.exists(FILENAME) or OVERWRITE or \\\n",
    "        not result.shape == (len(WS_TTCS), len(WS_SPEED_DIFFS), 2):\n",
    "    result = np.zeros((len(WS_TTCS), len(WS_SPEED_DIFFS), 2))\n",
    "    np.random.seed(0)\n",
    "    for i, ttc in enumerate(WS_TTCS):\n",
    "        for j, speed_diff in enumerate(WS_SPEED_DIFFS):\n",
    "            result[i, j, 0] = ws.prob_collision(ttc, speed_diff)\n",
    "            result[i, j, 1] = ws_with_our_method(ttc, speed_diff)\n",
    "    with open(FILENAME, \"wb\") as file:\n",
    "        pickle.dump(result, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, speed_diff in enumerate(WS_SPEED_DIFFS):\n",
    "    plt.plot(WS_TTCS, result[:, i, 0], ls=WS_LINESTYLES[i], color=WS_COLORS[0], \n",
    "             lw=WS_LINEWIDTHS[0])\n",
    "    plt.plot(WS_TTCS, result[:, i, 1], ls=WS_LINESTYLES[i], color=WS_COLORS[1],\n",
    "             lw=WS_LINEWIDTHS[1])\n",
    "plt.xlabel(\"TTC [s]\")\n",
    "plt.ylabel(\"$P(C|x)$ according to the WS metric\")\n",
    "plt.xlim(WS_TTCS[0], WS_TTCS[-1])\n",
    "plt.ylim(0, 1)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply method on NGSIM data set to create a risk metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NGSIM_DATA = os.path.join(\"data\", \"8_interactions_v3\", \n",
    "                          \"dNGSIM_iLongitudinal_mFull_Reconstruction_e100_wi1_w1_hs32_bs2\",\n",
    "                          \"interactions.pkl\")\n",
    "NGSIM_KDE = os.path.join(\"data\", \"6_kde\", \"NGSIM.p\")\n",
    "NGSIM_PROB_COLLISION = os.path.join(\"data\", \"7_simulation_results\", \n",
    "                                    \"prob_collision_NGSIM.csv\")\n",
    "SCALING_GRID = [2, .5, 2, .25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data.\n",
    "with open(NGSIM_DATA, 'rb') as file:\n",
    "    all_interactions = pickle.load(file)\n",
    "locations = sorted(all_interactions.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for speed and acceleration\n",
    "def filter_signal(signal):\n",
    "    return scipy.signal.savgol_filter(signal, 15, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pars(vel_acc):\n",
    "    if len(vel_acc) < 15:\n",
    "        return np.zeros((0, 4))\n",
    "    if np.max(np.abs(np.diff(vel_acc['Velocity_X']))) > 1.5:\n",
    "        return np.zeros((0, 4))\n",
    "    \n",
    "    data = vel_acc.copy()\n",
    "    data['ax_savgol'] = filter_signal(data[\"Acceleration_X\"])\n",
    "    data['vx_savgol'] = filter_signal(data[\"Velocity_X\"])\n",
    "    i = data.index[scipy.signal.find_peaks(-data['vx_savgol'], prominence=1)[0]]\n",
    "    data['endspeed'] = np.nan\n",
    "    data['endtime'] = np.nan\n",
    "    data.loc[i, 'endspeed'] = data.loc[i, 'vx_savgol']\n",
    "    data.loc[i, 'endtime'] = i\n",
    "    data = data.fillna(method='backfill')\n",
    "    data = data.dropna()\n",
    "\n",
    "    data['duration'] = data['endtime'] - data.index\n",
    "    data['vdiff'] = data['endspeed'] - data['vx_savgol']\n",
    "    data['amean'] = data['vdiff'] / data['duration']\n",
    "    data = data.drop(i)\n",
    "    return data[['vx_savgol', 'ax_savgol', 'vdiff', 'amean']].values[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if OVERWRITE or not os.path.exists(NGSIM_KDE):\n",
    "    parameters = []\n",
    "    for location in locations:\n",
    "        parameters += [get_pars(interaction['leader']) for interaction in \n",
    "                       all_interactions[location].values()]\n",
    "    kde = KDE(np.concatenate(parameters), scaling=True)\n",
    "    kde.clustering(kde._maxdist()*5)\n",
    "    kde.compute_bandwidth()\n",
    "    print(\"Bandwidth: {:.4f}\".format(kde.get_bandwidth()))\n",
    "    kde.pickle(NGSIM_KDE)\n",
    "else:\n",
    "    kde = kde_from_file(NGSIM_KDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leader_parameters(**kwargs):\n",
    "    return LeaderInteractionParameters(init_position=kwargs[\"gap\"],\n",
    "                                       init_speed=kwargs[\"v0_lead\"],\n",
    "                                       init_acceleration=kwargs[\"a0_lead\"],\n",
    "                                       speed_difference=kwargs[\"dv\"],\n",
    "                                       duration=kwargs[\"duration\"])\n",
    "\n",
    "def follower_parameters(**kwargs):\n",
    "    return IDMParameters(amin=kwargs[\"amin\"],\n",
    "                         speed=kwargs[\"v0_host\"],\n",
    "                         n_reaction=int(kwargs[\"tr\"]*100),\n",
    "                         init_speed=kwargs[\"v0_host\"],\n",
    "                         init_position=0)\n",
    "\n",
    "def get_other_pars(**kwargs):\n",
    "    # Get the speed difference and the mean acceleration from the KDE.\n",
    "    while True:\n",
    "        (kwargs[\"dv\"], kwargs[\"amean\"]), = kde.conditional_sample([0, 1], [kwargs[\"v0_lead\"], \n",
    "                                                                           kwargs[\"a0_lead\"]])\n",
    "        if np.sign(kwargs[\"dv\"]) == np.sign(kwargs[\"amean\"]):\n",
    "            break\n",
    "    kwargs[\"duration\"] = kwargs[\"dv\"] / kwargs[\"amean\"]\n",
    "    \n",
    "    # Get reaction time from a lognormal distribution with mean=.92, std=0.28\n",
    "    if \"tr\" not in kwargs:\n",
    "        kwargs[\"tr\"] = np.random.lognormal(np.log(.92**2 / np.sqrt(.92**2 + .28**2)), \n",
    "                                           np.sqrt(np.log(1 + .28**2/.92**2)))\n",
    "    \n",
    "    # Get the braking capacity from a truncated normal distribution\n",
    "    if \"amin\" not in kwargs:\n",
    "        while True:\n",
    "            kwargs[\"amin\"] = np.random.normal(-8.45, 1.4)\n",
    "            if -12.68 < kwargs[\"amin\"] < -4.23:\n",
    "                break\n",
    "    \n",
    "    return kwargs\n",
    "\n",
    "simulation = SimulationLongitudinal(LeaderInteraction(), leader_parameters,\n",
    "                                    IDMPlus(), follower_parameters)\n",
    "simulation.min_simulation_time = 2\n",
    "\n",
    "def get_probability(**kwargs):\n",
    "    \"\"\"\n",
    "    Parameters to provide:\n",
    "    - v0_lead\n",
    "    - a0_lead\n",
    "    - v0_host\n",
    "    - gap\n",
    "    \"\"\"\n",
    "    # If the host speed is zero, always return 0.0\n",
    "    if \"v0_host\" in kwargs:\n",
    "        if kwargs[\"v0_host\"] <= 0.0:\n",
    "            return 0.0\n",
    "    \n",
    "    min_sim = 10\n",
    "    max_sim = 100\n",
    "    results = np.zeros(max_sim)\n",
    "    for i in range(max_sim):\n",
    "        parameters = get_other_pars(**kwargs)\n",
    "        results[i] = simulation.simulation(parameters)\n",
    "        \n",
    "        if i+1 >= min_sim:\n",
    "            # If results are all the same, return either 0.0 or 1.0\n",
    "            if np.std(results[:i+1]) < 1e-8:\n",
    "                if results[0] > 0.0:\n",
    "                    return 0.0\n",
    "                return 1.0\n",
    "            \n",
    "            kde_result = KDE(results[:i+1], scaling=True)\n",
    "            kde_result.compute_bandwidth()\n",
    "            cdf_zero = kde_result.cdf(np.array([0.0]))[0]\n",
    "            if np.sqrt(cdf_zero*(1-cdf_zero)/(i+1)) < 0.01:\n",
    "                break\n",
    "    \n",
    "    if np.isnan(cdf_zero):\n",
    "        asfdasdffd\n",
    "    return cdf_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid\n",
    "def grid_pars(interaction):\n",
    "    if len(interaction['leader']) < 15:\n",
    "        return np.zeros((0, 4))\n",
    "    interaction['leader']['ax_savgol'] = filter_signal(interaction['leader'][\"Acceleration_X\"])\n",
    "    interaction['leader']['vx_savgol'] = filter_signal(interaction['leader'][\"Velocity_X\"])\n",
    "    pars = pd.DataFrame(interaction[\"leader\"][[\"vx_savgol\", \"ax_savgol\"]].values,\n",
    "                        columns=[\"v0_lead\", \"a0_lead\"], index=interaction[\"leader\"].index)\n",
    "    interaction['follower']['vx_savgol'] = filter_signal(interaction['follower'][\"Velocity_X\"])\n",
    "    pars[\"v0_host\"] = interaction[\"follower\"][\"vx_savgol\"]\n",
    "    gap = (interaction[\"leader\"][\"Position_X\"] - interaction[\"follower\"][\"Position_X\"] - \n",
    "           interaction[\"leader\"][\"Length\"]/2 - interaction[\"follower\"][\"Length\"]/2)\n",
    "    gap[gap < 0] = np.exp(-5)  # Lower limit\n",
    "    pars[\"loggap\"] = np.log(gap)\n",
    "    return pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if OVERWRITE or not os.path.exists(NGSIM_PROB_COLLISION):\n",
    "    parameters = []\n",
    "    for location in locations:\n",
    "        parameters += [grid_pars(interaction) for interaction in \n",
    "                       all_interactions[location].values()]\n",
    "    parameters = np.concatenate(parameters)\n",
    "    \n",
    "    grid = parameters.copy()\n",
    "    grid[:, 0] = np.clip(grid[:, 0], 0, 100)\n",
    "    # grid[:, 1] = np.clip(grid[:, 1], -5, 5)\n",
    "    grid[:, 2] = np.clip(grid[:, 2], 0, 100)\n",
    "    grid[:, 3] = np.clip(grid[:, 3], -5, 5)\n",
    "    grid = np.round(grid / SCALING_GRID)\n",
    "    grid = np.unique(grid, axis=0)\n",
    "    grid = grid * SCALING_GRID\n",
    "else:\n",
    "    df = pd.read_csv(NGSIM_PROB_COLLISION, index_col=0)\n",
    "    grid = df[[\"v0_lead\", \"a0_lead\", \"v0_host\", \"loggap\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the collision probability for the grid\n",
    "def get_probability_grid_pars(row):\n",
    "    return get_probability(v0_lead=row[0], a0_lead=row[1],\n",
    "                           v0_host=row[2], gap=np.exp(row[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if OVERWRITE or not os.path.exists(NGSIM_PROB_COLLISION):\n",
    "    prob_collision = [get_probability_grid_pars(row) for row in tqdm(grid)]\n",
    "    df = pd.DataFrame(grid, columns=(\"v0_lead\", \"a0_lead\", \"v0_host\", \"loggap\"))\n",
    "    df[\"prob_collision\"] = prob_collision\n",
    "    df.to_csv(NGSIM_PROB_COLLISION)\n",
    "else:\n",
    "    prob_collision = df[\"prob_collision\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for the interpolation\n",
    "scaling = np.std(grid, axis=0)\n",
    "grid_scaled = grid / scaling\n",
    "def prob_ngsim(v0_lead, a0_lead, v0_host, gap):\n",
    "    tmp = np.array([[v0_lead, a0_lead, v0_host, np.log(gap)]]) / scaling\n",
    "    sq_distance = dist.cdist(grid_scaled, tmp, metric='sqeuclidean')\n",
    "    weights = np.exp(-sq_distance / 2 / (0.3**2))  # Bandwidth of .3\n",
    "    probability = np.dot(prob_collision, weights) / np.sum(weights, axis=0)\n",
    "    #if probability > 0.3:\n",
    "    #    print(tmp * scaling)\n",
    "    #    print(grid_scaled[np.argmax(weights)] * scaling)\n",
    "    #    aasffa\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method for adding data to grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_data_to_grid(pars):\n",
    "    \"\"\" \n",
    "    Use this function in the following manner:\n",
    "    \n",
    "    add_data_to_grid(<parameters>)\n",
    "    \"\"\"\n",
    "    global grid, scaling, grid_scaled, prob_collision, df\n",
    "    pars = np.round(pars / SCALING_GRID)\n",
    "    pars = np.unique(pars, axis=0)\n",
    "    pars = pars * SCALING_GRID\n",
    "    new = [not np.any((grid == pars[i, :]).all(axis=1)) for i in range(len(pars))]\n",
    "    if not np.any(new):\n",
    "        return grid, prob_collision\n",
    "    print(\"{:d}/{:d} values added\".format(np.sum(new), len(new)))\n",
    "    pars = pars[new, :]\n",
    "    df_new = pd.DataFrame(pars, columns=(\"v0_lead\", \"a0_lead\", \"v0_host\", \"loggap\"))\n",
    "    pcol = [get_probability_grid_pars(row) for row in pars]\n",
    "    df_new[\"prob_collision\"] = pcol\n",
    "    df = pd.concat((df, df_new), ignore_index=True)\n",
    "    df.to_csv(NGSIM_PROB_COLLISION)\n",
    "    grid = df[[\"v0_lead\", \"a0_lead\", \"v0_host\", \"loggap\"]].values\n",
    "    scaling = np.std(grid, axis=0)\n",
    "    grid_scaled = grid / scaling\n",
    "    prob_collision = df[\"prob_collision\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try method for scenario 1: No risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots(time, v_lead, a_lead, v_host, distance):    \n",
    "    # Calculate WS prob\n",
    "    prob_ws = np.zeros_like(time)\n",
    "    for i, (vh, vl, gap) in enumerate(zip(v_host, v_lead, distance)):\n",
    "        if vh > vl:\n",
    "            ttc = gap / (vh - vl)\n",
    "            prob_ws[i] = ws.prob_collision(ttc, vh-vl)\n",
    "            \n",
    "    # Calculate prob with new method\n",
    "    add_data_to_grid(np.array([v_lead, a_lead, v_host, np.log(distance)]).T)\n",
    "    prob_new = np.zeros_like(time)\n",
    "    for i, (vh, vl, al, gap) in enumerate(zip(v_host, v_lead, a_lead, distance)):\n",
    "        prob_new[i] = prob_ngsim(vl, al, vh, gap)\n",
    "        \n",
    "    _, ax1 = plt.subplots()\n",
    "    ax1.plot(time, v_host, c=WS_COLORS[0], lw=WS_LINEWIDTHS[0], ls=WS_LINESTYLES[0])\n",
    "    ax1.plot(time, v_lead, c=WS_COLORS[0], lw=WS_LINEWIDTHS[0], ls=WS_LINESTYLES[1])\n",
    "    ax1.set_xlabel(\"Time [s]\")\n",
    "    ax1.set_ylabel(\"Speed [m/s]\", color=WS_COLORS[0])\n",
    "    ax1.grid()\n",
    "    ax1.set_xlim(time[0], time[-1])\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(time, distance, c=WS_COLORS[1], lw=WS_LINEWIDTHS[0], ls=WS_LINESTYLES[2])\n",
    "    ax2.set_ylabel(\"Distance[m]\", color=WS_COLORS[1])\n",
    "    \n",
    "    ax1_ticks = ax1.get_yticks()[1:-1]\n",
    "    nticks = len(ax1_ticks)\n",
    "    n = 1\n",
    "    while int(np.max(distance)/n)+1 - int(np.min(distance/n)) >= nticks:\n",
    "        n += 1\n",
    "    ax2_ticks = (np.arange(nticks)+int(np.min(distance)/n))*n\n",
    "    ax2.set_yticks(ax2_ticks)\n",
    "    ax1_ylim = ax1.get_ylim()\n",
    "    aspect_ratio = (ax2_ticks[-1] - ax2_ticks[0]) / (ax1_ticks[-1] - ax1_ticks[0])\n",
    "    ax2.set_ylim(ax2_ticks[0] - aspect_ratio * (ax1_ticks[0] - ax1_ylim[0]),\n",
    "                 ax2_ticks[-1] + aspect_ratio * (ax1_ylim[1] - ax1_ticks[-1]))\n",
    "    \n",
    "    plt.subplots()\n",
    "    plt.plot(time, prob_ws, c=WS_COLORS[0], lw=WS_LINEWIDTHS[0])\n",
    "    plt.plot(time, prob_new, c=WS_COLORS[1], lw=WS_LINEWIDTHS[1])\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlim(time[0], time[-1])\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(\"Probability of collision\")\n",
    "    plt.grid()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V0_LEADER = 20\n",
    "DV_LEADER = 10\n",
    "A_LEADER = 3\n",
    "T_LEADER = 3\n",
    "\n",
    "V0_HOST = 24\n",
    "DV1_HOST = 16\n",
    "DV2_HOST = 2\n",
    "A1_HOST = 4\n",
    "A2_HOST = 0.5\n",
    "T_HOST = 2\n",
    "\n",
    "D_INIT = 40\n",
    "TMAX = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(0, TMAX+0.01, 0.01)\n",
    "\n",
    "v_lead = V0_LEADER * np.ones_like(time)\n",
    "a_lead = np.zeros_like(time)\n",
    "v_lead[time > DV_LEADER/A_LEADER+T_LEADER] = V0_LEADER - DV_LEADER\n",
    "i = np.logical_and(time > T_LEADER, time <= DV_LEADER/A_LEADER+T_LEADER)\n",
    "v_lead[i] = DV_LEADER/2*(np.cos(np.pi*(time[i]-T_LEADER)*A_LEADER/DV_LEADER)-1)+V0_LEADER\n",
    "a_lead[i] = -DV_LEADER/2*np.sin(np.pi*(time[i]-T_LEADER)*A_LEADER/DV_LEADER)*np.pi*A_LEADER/DV_LEADER\n",
    "\n",
    "v_host = V0_HOST * np.ones_like(time)\n",
    "a_host = np.zeros_like(time)\n",
    "t1 = DV1_HOST / A1_HOST + T_HOST\n",
    "i = np.logical_and(time > T_HOST, time <= t1)\n",
    "v_host[i] = DV1_HOST/2*(np.cos(np.pi*(time[i]-T_HOST)*A1_HOST/DV1_HOST)-1)+V0_HOST\n",
    "a_host[i] = -DV1_HOST/2*np.sin(np.pi*(time[i]-T_HOST)*A1_HOST/DV1_HOST)*np.pi*A1_HOST/DV1_HOST\n",
    "t2 = t1 + DV2_HOST / A2_HOST\n",
    "i = np.logical_and(time > t1, time <= t2)\n",
    "v_host[i] = -DV2_HOST/2*(np.cos(np.pi*(time[i]-t1)*A2_HOST/DV2_HOST)-1)+V0_HOST-DV1_HOST\n",
    "a_host[i] = DV2_HOST/2*np.sin(np.pi*(time[i]-t1)*A2_HOST/DV2_HOST)*np.pi*A2_HOST/DV2_HOST\n",
    "v_host[time > t2] = V0_HOST - DV1_HOST + DV2_HOST\n",
    "distance = D_INIT + np.cumsum(v_lead - v_host)*0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plots(time, v_lead, a_lead, v_host, distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try method for scenario 2: Risky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V0_LEADER = 20\n",
    "DV_LEADER = 10\n",
    "A_LEADER = 3\n",
    "T_LEADER = 3\n",
    "\n",
    "V0_HOST = 24\n",
    "DV1_HOST = 16\n",
    "DV2_HOST = 2\n",
    "A1_HOST = 4\n",
    "A2_HOST = 0.5\n",
    "T_HOST = 4\n",
    "\n",
    "D_INIT = 40\n",
    "TMAX = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(0, TMAX+0.01, 0.01)\n",
    "\n",
    "v_lead = V0_LEADER * np.ones_like(time)\n",
    "a_lead = np.zeros_like(time)\n",
    "v_lead[time > DV_LEADER/A_LEADER+T_LEADER] = V0_LEADER - DV_LEADER\n",
    "i = np.logical_and(time > T_LEADER, time <= DV_LEADER/A_LEADER+T_LEADER)\n",
    "v_lead[i] = DV_LEADER/2*(np.cos(np.pi*(time[i]-T_LEADER)*A_LEADER/DV_LEADER)-1)+V0_LEADER\n",
    "a_lead[i] = -DV_LEADER/2*np.sin(np.pi*(time[i]-T_LEADER)*A_LEADER/DV_LEADER)*np.pi*A_LEADER/DV_LEADER\n",
    "\n",
    "v_host = V0_HOST * np.ones_like(time)\n",
    "a_host = np.zeros_like(time)\n",
    "t1 = DV1_HOST / A1_HOST + T_HOST\n",
    "i = np.logical_and(time > T_HOST, time <= t1)\n",
    "v_host[i] = DV1_HOST/2*(np.cos(np.pi*(time[i]-T_HOST)*A1_HOST/DV1_HOST)-1)+V0_HOST\n",
    "a_host[i] = -DV1_HOST/2*np.sin(np.pi*(time[i]-T_HOST)*A1_HOST/DV1_HOST)*np.pi*A1_HOST/DV1_HOST\n",
    "t2 = t1 + DV2_HOST / A2_HOST\n",
    "i = np.logical_and(time > t1, time <= t2)\n",
    "v_host[i] = -DV2_HOST/2*(np.cos(np.pi*(time[i]-t1)*A2_HOST/DV2_HOST)-1)+V0_HOST-DV1_HOST\n",
    "a_host[i] = DV2_HOST/2*np.sin(np.pi*(time[i]-t1)*A2_HOST/DV2_HOST)*np.pi*A2_HOST/DV2_HOST\n",
    "v_host[time > t2] = V0_HOST - DV1_HOST + DV2_HOST\n",
    "distance = D_INIT + np.cumsum(v_lead - v_host)*0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plots(time, v_lead, a_lead, v_host, distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try method for scenario 3: Collision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V0_LEADER = 20\n",
    "DV_LEADER = 10\n",
    "A_LEADER = 3\n",
    "T_LEADER = 3\n",
    "\n",
    "V0_HOST = 25\n",
    "DV1_HOST = 16\n",
    "DV2_HOST = 2\n",
    "A1_HOST = 5\n",
    "A2_HOST = 0.5\n",
    "T_HOST = 4\n",
    "\n",
    "D_INIT = 34.933\n",
    "TMAX = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(0, TMAX+0.01, 0.01)\n",
    "\n",
    "v_lead = V0_LEADER * np.ones_like(time)\n",
    "a_lead = np.zeros_like(time)\n",
    "v_lead[time > DV_LEADER/A_LEADER+T_LEADER] = V0_LEADER - DV_LEADER\n",
    "i = np.logical_and(time > T_LEADER, time <= DV_LEADER/A_LEADER+T_LEADER)\n",
    "v_lead[i] = DV_LEADER/2*(np.cos(np.pi*(time[i]-T_LEADER)*A_LEADER/DV_LEADER)-1)+V0_LEADER\n",
    "a_lead[i] = -DV_LEADER/2*np.sin(np.pi*(time[i]-T_LEADER)*A_LEADER/DV_LEADER)*np.pi*A_LEADER/DV_LEADER\n",
    "\n",
    "v_host = V0_HOST * np.ones_like(time)\n",
    "a_host = np.zeros_like(time)\n",
    "t1 = DV1_HOST / A1_HOST + T_HOST\n",
    "i = np.logical_and(time > T_HOST, time <= t1)\n",
    "v_host[i] = DV1_HOST/2*(np.cos(np.pi*(time[i]-T_HOST)*A1_HOST/DV1_HOST)-1)+V0_HOST\n",
    "a_host[i] = -DV1_HOST/2*np.sin(np.pi*(time[i]-T_HOST)*A1_HOST/DV1_HOST)*np.pi*A1_HOST/DV1_HOST\n",
    "t2 = t1 + DV2_HOST / A2_HOST\n",
    "i = np.logical_and(time > t1, time <= t2)\n",
    "v_host[i] = -DV2_HOST/2*(np.cos(np.pi*(time[i]-t1)*A2_HOST/DV2_HOST)-1)+V0_HOST-DV1_HOST\n",
    "a_host[i] = DV2_HOST/2*np.sin(np.pi*(time[i]-t1)*A2_HOST/DV2_HOST)*np.pi*A2_HOST/DV2_HOST\n",
    "v_host[time > t2] = V0_HOST - DV1_HOST + DV2_HOST\n",
    "distance = D_INIT + np.cumsum(v_lead - v_host)*0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plots(time, v_lead, a_lead, v_host, distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate partial derivatives of our method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOLERANCE = 0.02\n",
    "MIN_SIMULATIONS = 100\n",
    "MAX_SIMULATIONS = 500\n",
    "FIXED_PARAMETERS = dict(a0_lead=0)\n",
    "VARIABLE_PARAMETERS = dict(v0_lead=(9.8, 10, 10.2),\n",
    "                           v0_host=(19.8, 20, 20.2),\n",
    "                           gap=(19.5, 20, 20.5),\n",
    "                           amin=(-4.8, -5, -5.2),\n",
    "                           tr=(.90, .95, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation.tolerance = TOLERANCE\n",
    "simulation.min_simulations = MIN_SIMULATIONS\n",
    "simulation.max_simulations = MAX_SIMULATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "parameters = FIXED_PARAMETERS.copy()\n",
    "for key, values in VARIABLE_PARAMETERS.items():\n",
    "    parameters[key] = values[1]\n",
    "print(\"Default simulation result: {:.3f}\".format(get_probability(**parameters)))\n",
    "for key, values in VARIABLE_PARAMETERS.items():\n",
    "    print()\n",
    "    results = [0, 0]\n",
    "    for i, value in enumerate([values[0], values[2]]):\n",
    "        parameters[key] = value\n",
    "        results[i] = get_probability(**parameters)\n",
    "        print(\"Change '{:s}' to {}, result: {:.3f}\".format(key, value, results[i]))\n",
    "    parameters[key] = values[1]  # Change back to default value\n",
    "    \n",
    "    print(\"Partial derivative for {:s}: {:.3f}\"\n",
    "          .format(key, (results[1]-results[0])/(values[2]-values[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[1] - results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, (results[1]-result[0])/(values[2]-values[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
