\section{Introduction}
\label{sec:introduction}

The amount of collected field data from driving studies is increasing rapidly. These data play an important role in the research, development, assessment, and evaluation of driving-related topics. For example, a naturalistic driving dataset is used to determine the driver crash risk factors by \textcite{dingus2016crashrisk}. In other studies, naturalistic driving data are used to determine the impact of the state of the driver, such as inattention \cite{klauer2006impact} and fatigue \cite{williamson2011link}. For simulation purposes, driver models have been developed using data-driven modeling \cite{sadigh2014data}. With regards to automated driving, the data of a test run of an automated vehicle are directly used to assess the system performance by \textcite{broggi2013extensive}. More indirectly, data are also used to create test cases for the assessment and evaluation of automated driving systems \cite{zofka2015datadrivetrafficscenarios, elrofai2018scenario, deGelder2017assessment, ploeg2018cetran, putz2017pegasus, krajewski2018highD}.

For any work that depends on data, it is important to know how complete the data are. Especially when deducing safety claims based on collected data, e.g., through testing scenarios based on collected data, we require knowledge about the degree of completeness of the dataset used \cite{geyer2014, stellet2015taxonomy, alvarez2017prospective}. Hence, questions like ``do we have enough data?'' are highly relevant when our work and conclusions depend on the data. Furthermore, since the collection of data is time-consuming and requires high investments and resources, we should ask are ourselves ``how much more data do we need?'' or ``how much more information can we gain when obtaining more data?'' To answer these questions, we propose a method for quantifying the completeness of a dataset. 

To quantify the completeness of a dataset, the data are interpreted as a sequence of different so-called scenarios that can be grouped into a finite set of scenario classes. Activities, such as ``braking'' and ``lane change'' form the building blocks of the scenarios \cite{elrofai2018scenario}. For every activity, we create a parametrization that encodes the information in the data of this activity. For each type of activity, we estimate a probability density function (pdf) of the associated parameters. Our proposed method approximates the degree of completeness of a dataset using the expected error of the estimated pdf. The smaller this error, the higher the degree of completeness.

To illustrate the proposed method, two different case studies are presented. The first case study involves artificial data of which the underlying distributions are known. Because the underlying distributions are known, we can show that the proposed method correctly quantifies the degree of completeness. Next, a case study with real-world data is performed to quantify the degree of completeness of the acquired data for which the underlying distributions are unknown. Additionally, we show how we can estimate the required amount of data in order to meet a certain requirement.

The paper is structured as follows. %First, a brief overview is presented of related works in \cref{sec:related}. 
In \cref{sec:problem}, we describe in more detail what the problem for which a solution is proposed in \cref{sec:method}. The two case studies are presented in \cref{sec:results}. After a discussion in \cref{sec:discussion}, this paper is concluded in \cref{sec:conclusion}.
