\section{Introduction}
\label{sec:introduction}

%The amount of collected field data from driving studies is increasing rapidly. These data play an important role in the research, development, assessment, and evaluation of driving-related topics. For example, a naturalistic driving dataset is used to determine the driver crash risk factors by \textcite{dingus2016crashrisk}. In other studies, naturalistic driving data are used to determine the impact of the state of the driver, such as inattention \cite{klauer2006impact} and fatigue \cite{williamson2011link}. For simulation purposes, driver models have been developed using data-driven modeling \cite{sadigh2014data}. With regards to automated driving, the data of a test run of an automated vehicle are directly used to assess the system performance by \textcite{broggi2013extensive}. More indirectly, data are also used to create test cases for the assessment and evaluation of automated driving systems \cite{zofka2015datadrivetrafficscenarios, elrofai2018scenario, deGelder2017assessment, ploeg2018cetran, putz2017pegasus, krajewski2018highD}.

%For any work that depends on data, it is important to know how complete the data are. Especially when deducing safety claims based on collected data, e.g., through testing scenarios based on collected data, we require knowledge about the degree of completeness of the dataset used \cite{geyer2014, stellet2015taxonomy, alvarez2017prospective}. Hence, questions like ``do we have enough data?'' are highly relevant when our work and conclusions depend on the data. Furthermore, since the collection of data is time-consuming and requires high investments and resources, we should ask ourselves ``how much more data do we need?'' or ``how much more information can we gain when obtaining more data?'' To answer these questions, we propose a method for quantifying the completeness of a dataset. 

The amount of collected field data from driving studies is increasing rapidly and these data are extensively used for the research, development, assessment, and evaluation of driving-related topics, e.g., see \textcite{dingus2016crashrisk, klauer2006impact, williamson2011link, sadigh2014data, broggi2013extensive, zofka2015datadrivetrafficscenarios, elrofai2018scenario, deGelder2017assessment, ploeg2018cetran, putz2017pegasus, krajewski2018highD}. For any work that depends on data, it is important to know how complete the data are. As mentioned by various authors \cite{geyer2014, stellet2015taxonomy, alvarez2017prospective}, especially when deducing safety claims based on collected data, e.g., through testing scenarios based on collected data, we require knowledge about the degree of completeness of the dataset used. Hence, questions like ``do we have enough data?'' are highly relevant when our work and conclusions depend on the data. Furthermore, since the collection of data is time-consuming and requires high investments and resources, we should ask ourselves ``how much more data do we need?'' or ``how much more information can we gain when obtaining more data?''

The aforementioned questions are already explored in other fields \cite{guest2006many, blair2004evolution, marks2018howmuch, yang2012estimating, wang2017much}, but the question of how much data are enough regarding traffic-related applications is less frequently answered. \textcite{wang2017much} appear to be the first in literature to point out and discuss issues concerning the amount of data needed to understand and model driver behaviors. They propose a statistical approach to determine how much naturalistic driving data are enough for understanding driving behaviors. 
For scenario-based assessments \cite{stellet2015taxonomy, alvarez2017prospective, elrofai2018scenario, ploeg2018cetran, geyer2014}, however, the approach of \textcite{wang2017much} might not be applicable, because they only consider the individual measurements at consecutive time instants instead of taking into account the whole driving scenario. Hence, there is a need for a quantitative measure for the completeness of a dataset that takes into account the different scenarios a vehicle encounters in real-world traffic.

We describe a method for quantifying the completeness of a dataset. The data are interpreted as a sequence of different scenarios that can be grouped into a finite set of scenario classes. Activities, such as ``braking'' and ``lane change'' form the building blocks of the scenarios \cite{elrofai2018scenario}. For every activity, we create a parametrization that encodes the information in the data of this activity. For each type of activity, we estimate a probability density function (pdf) of the associated parameters. Our proposed method approximates the degree of completeness of a dataset using the expected error of the estimated pdf. The smaller this error, the higher the degree of completeness.

To illustrate the proposed method, two different case studies are presented. The first case study involves artificial data of which the underlying distributions are known. Because the underlying distributions are known, we can show that the proposed method correctly quantifies the degree of completeness. Next, a case study with real-world data is performed to quantify the degree of completeness of the acquired data for which the underlying distributions are unknown. Additionally, we show how we can estimate the required amount of data to meet a certain requirement.

The paper is structured as follows. %First, a brief overview is presented of related works in \cref{sec:related}. 
In \cref{sec:problem}, we describe in more detail what the problem for which a solution is proposed in \cref{sec:method}. The two case studies are presented in \cref{sec:results}. After a discussion in \cref{sec:discussion}, this paper is concluded in \cref{sec:conclusion}.
