\section{Method}
\label{sec:method}

% Introduce f(x) and fhat(x;n)
In this section, we present how to approach the the second subproblem, i.e., how to quantify the completeness regarding all scenarios that fall into a scenario class. As explained in \cref{sec:problem}, all scenarios that fall into a specific scenario class are parametrized similarly. Let $n$ denote the number of scenarios that fall into a specific scenario class. As a result, we have $n$ parameter vectors, denoted by $X_i \in \mathbb{R}^d$ with $i\in \{1,\ldots,n\}$ and $d$ denoting the number of parameters for one scenario, that describe these scenarios. We will estimate the underlying distribution of $X_i$. Let $f(x)$ denote the true probability density function (pdf) and let $\hat{f}(x;n)$ denote the estimated pdf using $n$ parameter vectors.

% Introduce MISE
To quantify the completeness of the $n$ scenarios, use is made of the estimated pdf $\hat{f}(x;n)$. For example, suppose that $\hat{f}(x;n)$ equals $f(x)$ for all $x \in \mathbb{R}^d$. In this case, it would be reasonable to say that the $n$ scenarios give a complete view of the variety and the distribution of the different scenarios that fall into the specific scenario class. On the other hand, when $\hat{f}(x;n)$ is very different from $f(x)$, it would be reasonable to say that the opposite is the case, i.e., the $n$ scenarios do not give a complete view. One common measure for comparing the estimated pdf with the true pdf is the Mean Integrated Squared Error (MISE):
\begin{equation}
	\label{eq:mise}
	\mise{n} = \expectation{\int \left( f(x) - \hat{f}(x;n) \right)^2 \ud x}.
\end{equation}
Here and in the future, the integral is to be taken over $\mathbb{R}^d$.

A low MISE indicates a complete set whereas a high MISE indicates a low degree of completeness, because the expected integrated squared error is high. Therefore MISE might be used to quantify the completeness of set of scenarios that fall into a specific scenario class. The problem, however, with \cref{eq:mise} is that it depends on the true pdf $f(x)$ which is unknown. So the MISE of \cref{eq:mise} cannot be evaluated.

In the remainder of this section, we will explain how the MISE of \cref{eq:mise} can be estimated when Kernel Density Estimation (KDE) is employed for estimated the pdf $f(x)$. First, KDE will be explained. Next, in \cref{sec:mise dependent}, a method is presented for estimating the MISE when assuming that the $d$ parameters are correlated. \Cref{sec:mise independent} shows how the MISE can be approximated when some of the $d$ parameters are independent from each other.

% Explain everything about KDE
\subsection{Estimating the distribution using Kernel Density Estimation}
\label{sec:kde}

The shape of the probability densities is unknown beforehand and might change as more scenarios are acquired. Assuming a functional form of the pdf and fitting the parameters of the pdf to the data may therefore lead to inaccurate fits unless a lot of hand-tuning is applied. We employ a non-parametric approach using Kernel Density Estimation (KDE) \cite{rosenblatt1956remarks, parzen1962estimation} because the shape is automatically computed and KDE is highly flexible regarding the shape of the pdf.

In KDE, the estimated pdf is given by
\begin{equation}
	\label{eq:kde}
	\hat{f}(x;n) = \frac{1}{nh^d} \sum_{i=1}^n K\left(\frac{x - X_i}{h}\right).
\end{equation}
Here, $K(\cdot)$ is an appropriate kernel function and $h$ denotes the bandwidth. The choice of the kernel $K(\cdot)$ is not as important as the choice of the bandwidth $h$ \cite{turlach1993bandwidthselection}. We use a Gaussian kernel because it will simplify some of our calculations. The Gaussian kernel is given by
\begin{equation}
	\label{eq:gaussian kernel}
	K(u) = \frac{1}{\left( 2\pi \right)^{d/2}} \exp \left\{ -\frac{1}{2} \|u\|^2 \right\},
\end{equation}
where $\|u\|^2$ denotes the squared 2-norm of $u$, i.e., $u^T u$.

The bandwidth $h$ controls the amount of smoothing. For our chosen kernel of \cref{eq:gaussian kernel}, the same amount of smoothing is applied in every direction, although our method can easily be exended to a multi-dimentionsal bandwidth, see, e.g., \textcite{chen2017tutorial}. There are many different ways of estimating the bandwidth, ranging from simple reference rules like for example Scott's rule of thumb \cite{scott1992multivariate} or Silverman's rule of thumb \cite{silverman1986density} to more elaborate methods. See \textcite{turlach1993bandwidthselection, bashtannyk2001bandwidth, jones1996brief, chiu1996comparative} for reviews of different bandwidth selection methods. We use one-leave-out cross validation to compute the bandwidth $h$ (see also \textcite{duin1976parzen}) because this minimizes the Kullback-Leibler divergence between the real pdf $f(x)$ and the estimated pdf $\hat{f}(x;n)$ \cite{turlach1993bandwidthselection,zambom2013review}.

% Explain how MISE is computed
\subsection{Estimating the Mean Integrated Squared Error for dependent parameters}
\label{sec:mise dependent}

As an approximation of the MISE of \cref{eq:mise}, the asymptotic mean integrated squared error (AMISE) is often used. With the KDE of \cref{eq:kde} employed, the AMISE is as follows \cite{marron1992exact}:
\begin{equation}
	\label{eq:amise}
	\amise{n} = \frac{h^4}{4} \sigma_K^4 \int \left( \nabla^2 f(x) \right)^2 \ud x + \frac{\mu_K}{nh^d}.
\end{equation}
Here, $\sigma_K$ and $\mu_K$ are constants that depend on the choice of the kernel $K(\cdot)$:
\begin{align}
	\sigma_K &= \int u^2 K(u) \ud u, \\
	\mu_K &= \int K(u)^2 \ud u.
\end{align}
Because we use the Gaussian kernel of \cref{eq:gaussian kernel}, we have $\sigma_K=1$ and $\mu_K=(2\sqrt{\pi})^{-d}$. In \cref{eq:amise}, $\nabla^2 f(x)$ denotes the Laplacian of $f(x)$, i.e., 
\begin{equation}
	\nabla^2 f(x) = \sum_{i=1}^d \frac{\partial^2 f(x)}{\partial x_i^2}.
\end{equation}
Note that the Laplacian equals the trace of the Hessian. Assuming that $h \rightarrow 0$ and $nh^d \rightarrow \infty$ as $n \rightarrow \infty$, the AMISE will be only differ from the MISE by higher order terms \cite{silverman1986density}.

The influence of the bandwidth $h$ is demonstrated in a nice way by the AMISE of \cref{eq:amise}. The first term of the AMISE of \cref{eq:amise} corresponds to the asymptotic bias introduced by smoothing the pdf. Therefore, this term approaches zero when $h \rightarrow 0$. However, when $h \rightarrow 0$, the variance goes to infinity, as can be seen by the second term of the AMISE which corresponds to the asymptotic variance. 

As with the MISE, we cannot evaluate the AMISE because it depends on the true pdf $f(x)$. As suggested by \cite{chen2017tutorial}, we can estimate the quantity $\nabla^2 f(x)$ by $\nabla^2 \tilde{f}(x;n)$, where $\tilde{f}(x;n)$ is similar to \cref{eq:kde} but with different bandwidth, i.e., 
\begin{equation}
	\tilde{f}(x;n) = \frac{1}{nb^d} \sum_{i=1}^n K\left(\frac{x - X_i}{b}\right),
\end{equation}
where $b$ denotes the bandwidth. Here, the bandwidth needs to be larger than the optimal bandwidth to obtain a consistent estimator of $\nabla^2 f(x)$ \cite{chen2017tutorial}.

% Explain how MISE can be estimated with independent data
\subsection{Estimating the Mean Integrated Squared Error for independent parameters}
\label{sec:mise independent}

