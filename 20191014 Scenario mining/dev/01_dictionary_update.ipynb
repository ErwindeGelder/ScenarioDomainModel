{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRO\n",
    "- here we try to combine the dictionary extraction task + visualisation with jeroen's new data\n",
    "- we extract the dictionary of possible timestamp configurations and we render them. this should be something that goes on forever, so to enrich an existing dictionary etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports.general_settings import *\n",
    "from imports.general_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RENDERING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_EGO_IMG_cell(i, ego_lateral, ego_longitudinal, debug=False) :\n",
    "    ego_img = np.zeros((EGO_IMG_H, EGO_IMG_W, 3))\n",
    "    has_issue_longitudinal = False\n",
    "    has_issue_lateral = False\n",
    "    \n",
    "    if debug :\n",
    "        print(i, ego_lateral, ego_longitudinal)\n",
    "        \n",
    "    # processing longitutinal information\n",
    "    if ego_longitudinal == 'a' :\n",
    "        # accelerate\n",
    "        ego_img += EGO_ACCELERATING_COLOUR\n",
    "    elif ego_longitudinal == 'd' :\n",
    "        ego_img += EGO_DECELERATING_COLOUR\n",
    "    elif ego_longitudinal == 'c' :\n",
    "        ego_img += EGO_CRUISING_COLOUR\n",
    "    else :\n",
    "        ego_img += EGO_ISSUE\n",
    "        has_issue_longitudinal = True\n",
    "        \n",
    "    # processing lateral information\n",
    "    if ego_lateral == 'r' :\n",
    "        # we place the blinker at the front right\n",
    "        x0 = EGO_IMG_W - BLINKER_W\n",
    "        y0 = EGO_IMG_H - BLINKER_H\n",
    "        ego_img[y0:y0+BLINKER_H, x0:x0+BLINKER_W] = EGO_BLINKER_COLOUR\n",
    "    elif ego_lateral == 'l' :\n",
    "        # we place the blinker at the front left\n",
    "        x0 = EGO_IMG_W - BLINKER_W\n",
    "        y0 = 0\n",
    "        ego_img[y0:y0+BLINKER_H, x0:x0+BLINKER_W] = EGO_BLINKER_COLOUR\n",
    "    elif ego_lateral == 'fl' :\n",
    "        # lane following => no blinker\n",
    "        pass\n",
    "    else :\n",
    "        ego_img += EGO_ISSUE\n",
    "        has_issue_lateral = True\n",
    "        \n",
    "    cell_img = np.ones((CELL_IMG_H, CELL_IMG_W, 3))\n",
    "    cell_img += BG_COLOUR\n",
    "    \n",
    "    \n",
    "    # positioning ego in cell\n",
    "    egoX = int((CELL_IMG_W - EGO_IMG_W) / 2)\n",
    "    egoY = int((CELL_IMG_H - EGO_IMG_H) / 2)\n",
    "    cell_img[egoY : egoY+EGO_IMG_H, egoX:egoX+EGO_IMG_W] = ego_img\n",
    "    \n",
    "    if debug :\n",
    "        return cell_img, has_issue_lateral, has_issue_longitudinal\n",
    "    else :\n",
    "        return cell_img, has_issue_lateral or has_issue_longitudinal\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_target_img_cell(i, target_idx, target_lateral, target_longitudinal, target_velocity, debug=False) :\n",
    "    if debug :\n",
    "        print(i, target_idx, target_lateral, target_longitudinal, target_pos_lateral, target_pos_longitudinal, target_velocity)\n",
    "      \n",
    "    cell_img = np.ones((CELL_IMG_H, CELL_IMG_W, 3))\n",
    "    cell_img += BG_COLOUR\n",
    "    \n",
    "    # is there a target at all?\n",
    "    if np.sum(np.array([target_lateral, target_longitudinal, target_velocity]) == '') == 3 :\n",
    "        # all five features are '' => no target => return empty cell\n",
    "        return False, cell_img, False\n",
    "    \n",
    "    # we have an object!\n",
    "    target_img = np.zeros((TARGET_IMG_H, TARGET_IMG_W, 3))\n",
    "    has_issue_longitudinal = False\n",
    "    has_issue_lateral = False\n",
    "    has_issue_velocity = False\n",
    "   \n",
    "    # processing longitudinal information\n",
    "    if target_longitudinal == 'a' :\n",
    "        target_img += TARGET_ACCELERATING_COLOUR\n",
    "    elif target_longitudinal == 'd' :\n",
    "        target_img += TARGET_DECELERATING_COLOUR\n",
    "    elif target_longitudinal == 'c' :\n",
    "        target_img += TARGET_CRUISING_COLOUR\n",
    "    else :\n",
    "        target_img += TARGET_ISSUE\n",
    "        has_issue_longitudinal = True\n",
    "        \n",
    "    # processing lateral information\n",
    "    if target_lateral in ['ro', 'ri'] :\n",
    "        # we place the blinker at the front right\n",
    "        x0 = TARGET_IMG_W - BLINKER_W\n",
    "        y0 = TARGET_IMG_H - BLINKER_H\n",
    "        target_img[y0:y0+BLINKER_H, x0:x0+BLINKER_W] = TARGET_BLINKER_COLOUR\n",
    "    elif target_lateral in ['lo', 'li'] :\n",
    "        # we place the blinker at the front left\n",
    "        x0 = TARGET_IMG_W - BLINKER_W\n",
    "        y0 = 0\n",
    "        target_img[y0:y0+BLINKER_H, x0:x0+BLINKER_W] = TARGET_BLINKER_COLOUR\n",
    "    elif target_lateral == 'fl' :\n",
    "        # lane following => no blinker\n",
    "        pass\n",
    "    else :\n",
    "        target_img += TARGET_ISSUE\n",
    "        has_issue_lateral = True\n",
    "        \n",
    "    # processing velocity information\n",
    "    targetX = None\n",
    "    targetY = int((CELL_IMG_H - TARGET_IMG_H) / 2)\n",
    "    if target_velocity == 'equal' :\n",
    "        # same speed => centred\n",
    "        targetX = int((CELL_IMG_W - TARGET_IMG_W) / 2)\n",
    "    elif target_velocity == 'slower' :\n",
    "        # draw the \"slower than\" lines\n",
    "        # draw \"skidmarks\" at the very right\n",
    "        targetX = 2\n",
    "        for x in range(CELL_IMG_W - TARGET_IMG_W - 2 + 1, CELL_IMG_W - 2 + 1, 2) :\n",
    "            for y in range(targetY, targetY + TARGET_IMG_H, 2) :\n",
    "                cell_img[y:y+1, x:x+1] = TARGET_REL_SPEED_COLOUR   \n",
    "    elif target_velocity == 'faster' :\n",
    "        # at the very left\n",
    "        targetX = CELL_IMG_W - TARGET_IMG_W - 2\n",
    "        # draw the \"faster than\" lines\n",
    "        for x in range(2, CELL_IMG_W - TARGET_IMG_W) :\n",
    "            for y in range(targetY, targetY + TARGET_IMG_H, 2) :\n",
    "                cell_img[y:y+1, x:x+1] = TARGET_REL_SPEED_COLOUR\n",
    "    else :\n",
    "        # unknown: centre image + issue\n",
    "        targetX = int((CELL_IMG_W - TARGET_IMG_W) / 2)\n",
    "        has_issue_velocity = True\n",
    "        \n",
    "    # pasting target in cell\n",
    "    cell_img[targetY : targetY + TARGET_IMG_H, targetX : targetX + TARGET_IMG_W] = target_img\n",
    "    \n",
    "    if debug :\n",
    "        return True, cell_img, has_issue_lateral, has_issue_longitudinal, has_issue_velocity\n",
    "    else :\n",
    "        return True, cell_img, has_issue_lateral or has_issue_longitudinal or has_issue_velocity\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_macro_cell_EGO(i, ego_img) :\n",
    "    # this one is simple\n",
    "    macro_cell_img = np.zeros((MACRO_CELL_H, MACRO_CELL_W, 3))\n",
    "    macro_cell_img += BG_COLOUR\n",
    "    \n",
    "    egoX = int((MACRO_CELL_W - CELL_IMG_W) / 2)\n",
    "    egoY = int((MACRO_CELL_H - CELL_IMG_H) / 2)\n",
    "    \n",
    "    macro_cell_img[egoY:egoY+CELL_IMG_H, egoX:egoX+CELL_IMG_W] = ego_img\n",
    "    \n",
    "    return macro_cell_img    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_macro_cell_target(i, lateral_position, longitudinal_position, target_img_list, target_position) :\n",
    "    \n",
    "    macro_cell_img = np.zeros((MACRO_CELL_H, MACRO_CELL_W, 3))\n",
    "    macro_cell_img += BG_COLOUR \n",
    "    \n",
    "    for t in range(nTargets) :\n",
    "        target_img = target_img_list[t]\n",
    "        target_pos = target_position[t]\n",
    "        \n",
    "        if target_pos['lateral'] == lateral_position and target_pos['longitudinal'] == longitudinal_position :\n",
    "            # this target can be added to the macro cell\n",
    "            #print(t)\n",
    "            targetX = int(int(t / 4) * MACRO_CELL_W / 2)\n",
    "            targetY = int(t % 4 * MACRO_CELL_H / 4)\n",
    "            macro_cell_img[targetY : targetY + CELL_IMG_H, targetX : targetX + CELL_IMG_W] = target_img\n",
    "        \n",
    "    return macro_cell_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_full_img(i, ego_img, target_img_list, target_rel_pos) :\n",
    "    \n",
    "    # initialising full image\n",
    "    n_rows = len(valid_relative_positions['lateral']) - 1 # -1 because 'lateral' also contains ''\n",
    "    n_cols = len(valid_relative_positions['longitudinal']) # so basically all longitudinal + EGO CELL which it is always at centre\n",
    "    full_img = np.zeros((n_rows * MACRO_CELL_H + (n_rows - 1) * H_LANE_H, \n",
    "                         n_cols * MACRO_CELL_W + (n_cols - 1) * V_LANE_W, 3))\n",
    "    full_img += BG_COLOUR\n",
    "    \n",
    "    #print(n_rows, n_cols)\n",
    "    \n",
    "    # adding horizontal lanes\n",
    "    for i in range(1, n_rows) :\n",
    "        y0 = MACRO_CELL_H * i + (i-1) * H_LANE_H\n",
    "        for x in range(0, full_img.shape[1], 2 * H_LANE_W) :\n",
    "            full_img[y0 : y0 + H_LANE_H, x : x + H_LANE_W] = H_LANE_COLOUR\n",
    "            \n",
    "    # adding vertical lanes\n",
    "    for j in range(1, n_cols) :\n",
    "        x0 = MACRO_CELL_W * j + (j-1) * V_LANE_W\n",
    "        for y in range(0, full_img.shape[0], 2 * V_LANE_H) :\n",
    "            full_img[y : y + V_LANE_H, x0 : x0 + V_LANE_W] = V_LANE_COLOUR\n",
    "            \n",
    "    # ego img positioning: always in the centre\n",
    "    ego_col = int(n_cols / 2)\n",
    "    x0 = ego_col * MACRO_CELL_W + int((n_cols - 1) / 2) * V_LANE_W\n",
    "    y0 = int(n_rows / 2) * MACRO_CELL_H + int((n_rows - 1) / 2) * H_LANE_H\n",
    "    macro_cell_ego = make_macro_cell_EGO(i, ego_img)\n",
    "    full_img[y0 : y0 + MACRO_CELL_H, x0 : x0 + MACRO_CELL_W] = macro_cell_ego\n",
    "    \n",
    "    for lat_i in range(len(valid_relative_positions['lateral'])) :\n",
    "        lat = valid_relative_positions['lateral'][lat_i]\n",
    "        if lat == '' :\n",
    "            continue\n",
    "        y0 = MACRO_CELL_H * lat_i\n",
    "        if lat_i > 0 :\n",
    "            y0 += lat_i * H_LANE_H\n",
    "        \n",
    "        x0 = None\n",
    "        for lon_i in range(len(valid_relative_positions['longitudinal'])) :\n",
    "            lon = valid_relative_positions['longitudinal'][lon_i]\n",
    "            if lon == '' :\n",
    "                continue\n",
    "            x0 = lon_i * MACRO_CELL_W\n",
    "            if lon_i > 0 :\n",
    "                x0 += lon_i * V_LANE_W\n",
    "            if lon_i >= ego_col :\n",
    "                x0 += MACRO_CELL_W + V_LANE_W\n",
    "\n",
    "            macro_cell_target = make_macro_cell_target(i, lat, lon, target_img_list, target_position)\n",
    "            full_img[y0 : y0 + MACRO_CELL_H, x0 : x0 + MACRO_CELL_W] = macro_cell_target\n",
    "\n",
    "    return full_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERAL SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_valid_relative_positions(valid_relative_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseFolder = os.path.join('..', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFolder = \"00_raw_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputFolder = \"01_activity_dictionary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_outputSubFolder = \"img_{:d}x{:d}\".format(len(valid_relative_positions['lateral'])-1,\n",
    "                                             len(valid_relative_positions['longitudinal'])-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionaryFilename = \"activityDictionary_{:d}x{:d}.csv\".format(len(valid_relative_positions['lateral'])-1,\n",
    "                                                               len(valid_relative_positions['longitudinal'])-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionaryFilename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPath = os.path.join(baseFolder, inputFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPath_dictionary = os.path.join(baseFolder, outputFolder)\n",
    "outputPath_dictionary = os.path.join(baseFolder, outputFolder)\n",
    "outputPath_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputPath_dictionary_img = os.path.join(outputPath_dictionary, img_outputSubFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputPath_dictionary_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if outputFolder not in os.listdir(baseFolder) :\n",
    "    print(\"creating\", outputPath_dictionary)\n",
    "    os.mkdir(outputPath_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if img_outputSubFolder not in os.listdir(outputPath_dictionary) :\n",
    "    print(\"creating\", outputPath_dictionary_img)\n",
    "    os.mkdir(outputPath_dictionary_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD TAGGED DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileList = os.listdir(inputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fileList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFile = \"20170529_PP_03_Run_1.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPath + inputFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.HDFStore(inputPath + inputFile)\n",
    "tagged_dataset = s.get('df')\n",
    "s.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_dataset.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuesPerCol = {}\n",
    "colsWithRawValues = []\n",
    "lastTargetID = 0\n",
    "for c in tagged_dataset.columns :\n",
    "    if tagged_dataset[c].dtype == float :\n",
    "        colsWithRawValues.append(c)\n",
    "        continue\n",
    "    cName = c\n",
    "    if 'host' in c[:len('host')] :\n",
    "        if c not in valuesPerCol :\n",
    "            valuesPerCol[c] = []\n",
    "    elif 'target' in c[:len('target')] :\n",
    "        targetId = int(c.split('_')[1])\n",
    "        if targetId > lastTargetID :\n",
    "            lastTargetID = targetId\n",
    "        last = '_'.join(c.split('_')[2:])\n",
    "        cName = 'target_' + last\n",
    "        if cName not in valuesPerCol :\n",
    "            valuesPerCol[cName] = []\n",
    "    uniq = list(tagged_dataset[c].drop_duplicates())\n",
    "    valuesPerCol[cName] = list(set(valuesPerCol[cName] + uniq))\n",
    "print(\"categorical columns and values:\")\n",
    "for k in valuesPerCol :\n",
    "    print(\"\\t\", k, valuesPerCol[k])\n",
    "print(\"\\ncontinuous columns:\")\n",
    "for k in colsWithRawValues :\n",
    "    print(\"\\t\", k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTargets = lastTargetID + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTargets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INITIALISE DICTIONARY\n",
    "either load existing one or create an empty one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = None\n",
    "if dictionaryFilename in os.listdir(inputPath_dictionary) :\n",
    "    print(\"loading\", outputPath_dictionary + dictionaryFilename)\n",
    "    dictionary = pd.read_pickle(outputPath_dictionary + dictionaryFilename)\n",
    "else :\n",
    "    dictionary = pd.DataFrame(columns=dictionary_columns)  #['index', 'host_lateral', 'host_longitudinal', 'target_0_lateral', 'target_0_longitudinal', 'target_0_relative_position_longitudinal', 'target_0_relative_position_lateral', 'target_0_velocity', 'target_1_lateral', 'target_1_longitudinal', 'target_1_relative_position_longitudinal', 'target_1_relative_position_lateral', 'target_1_velocity', 'target_2_lateral', 'target_2_longitudinal', 'target_2_relative_position_longitudinal', 'target_2_relative_position_lateral', 'target_2_velocity', 'target_3_lateral', 'target_3_longitudinal', 'target_3_relative_position_longitudinal', 'target_3_relative_position_lateral', 'target_3_velocity', 'target_4_lateral', 'target_4_longitudinal', 'target_4_relative_position_longitudinal', 'target_4_relative_position_lateral', 'target_4_velocity', 'target_5_lateral', 'target_5_longitudinal', 'target_5_relative_position_longitudinal', 'target_5_relative_position_lateral', 'target_5_velocity', 'target_6_lateral', 'target_6_longitudinal', 'target_6_relative_position_longitudinal', 'target_6_relative_position_lateral', 'target_6_velocity', 'target_7_lateral', 'target_7_longitudinal', 'target_7_relative_position_longitudinal', 'target_7_relative_position_lateral', 'target_7_velocity', 'n_objects',  'ego_img',  'target_0_img',  'target_1_img',  'target_2_img',  'target_3_img',  'target_4_img',  'target_5_img', 'target_6_img',  'target_7_img',  'full_img',  'ego_issue', 'target_0_issue', 'target_1_issue', 'target_2_issue', 'target_3_issue', 'target_4_issue', 'target_5_issue', 'target_6_issue', 'target_7_issue' ])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.columns == dictionary_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAGGED DATAFRAME CORRECTION BASED ON VALID RELATIVE POSITIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_dataset = tagged_dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dictionary.shape, len(core_dictionary_columns), len(img_dictionary_columns))\n",
    "print(tagged_dataset[core_dictionary_columns].shape)\n",
    "print(tagged_dataset[core_dictionary_columns].drop_duplicates().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(nTargets) :\n",
    "    reduced_dataset.loc[(~reduced_dataset['target_' + str(t) + '_relative_position_longitudinal'].isin(valid_relative_positions['longitudinal'])) |\n",
    "              (~reduced_dataset['target_' + str(t) + '_relative_position_lateral'].isin(valid_relative_positions['lateral'])),\n",
    "                        ['target_' + str(t) + '_lateral', \n",
    "                         'target_' + str(t) + '_longitudinal',\n",
    "                         'target_' + str(t) + '_relative_position_longitudinal', \n",
    "                         'target_' + str(t) + '_relative_position_lateral',\n",
    "                         'target_' + str(t) + '_velocity']] = ''\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(8) :\n",
    "    print(t, list(reduced_dataset['target_' + str(t) + '_relative_position_lateral'].drop_duplicates()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DICTIONARY CONSTRUCTION OF THE CORRECTED DATAFRAME\n",
    "so basically we check which entries are new wrt the existing dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reduced_dataset[core_dictionary_columns].drop_duplicates().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_entries = reduced_dataset[core_dictionary_columns].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_entries.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_entries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in unique_entries.columns :\n",
    "    if c not in dictionary.columns :\n",
    "        print(c)\n",
    "print('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for c in dictionary.columns :\n",
    "    if c not in unique_entries.columns :\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_add = 0\n",
    "n_skip = 0\n",
    "\n",
    "for i in range(len(unique_entries)) :\n",
    "    print(i, len(unique_entries), 10*' ', end='\\r')\n",
    "    \n",
    "    # is the entry already present in the dictionary?\n",
    "    entry = unique_entries.iloc[i]\n",
    "    \n",
    "    add_entry = False\n",
    "    if len(dictionary) == 0 :\n",
    "        add_entry = True\n",
    "    elif np.max(np.sum(dictionary[entry.index] == entry, axis=1)) < len(entry) :\n",
    "        # the highest number of common features is less than the lenght of the entry => new feature values => add!\n",
    "        add_entry = True\n",
    "        \n",
    "    if add_entry :        \n",
    "        # we can add this entry\n",
    "        entry['index'] = len(dictionary)\n",
    "        entry['n_objects'] = sum([entry['target_' + str(t) + \"_lateral\"] != '' for t in range(nTargets)])\n",
    "        entry['ego_img'], entry['ego_issue'] = make_EGO_IMG_cell(i, entry['host_lateral'], entry['host_longitudinal'])\n",
    "        \n",
    "        n_targets = []\n",
    "        target_position = []\n",
    "        \n",
    "        for t in range(nTargets) :\n",
    "            target_lateral = entry['target_' + str(t) + '_lateral']\n",
    "            target_longitudinal = entry['target_' + str(t) + '_longitudinal']\n",
    "            target_velocity = entry['target_' + str(t) + '_velocity']\n",
    "            target_exists, entry['target_' + str(t) + '_img'], entry['target_' + str(t) + '_issue'] = make_target_img_cell(i, t, target_lateral, target_longitudinal, target_velocity)\n",
    "            n_targets.append(target_exists)\n",
    "            target_position.append({'lateral' : entry['target_' + str(t) + '_relative_position_lateral'],\n",
    "                                   'longitudinal' : entry['target_' + str(t) + '_relative_position_longitudinal']})\n",
    "            #break\n",
    "        \n",
    "        # time to merge the EGO/target images into a macro image\n",
    "        entry['full_img'] = make_full_img(i, entry['ego_img'], [entry['target_' + str(x) + '_img'] for x in range(nTargets)], target_position)\n",
    "        \n",
    "        # sanity check: do we have all entries to add to the dictionarY?\n",
    "        all_good = sum([c in dictionary.columns for c in entry.index]) == len(dictionary.columns)\n",
    "        if all_good :\n",
    "            #print(\"all good to add!\")\n",
    "            n_add += 1\n",
    "            dictionary = dictionary.append(entry, ignore_index=True)\n",
    "            \n",
    "    else :\n",
    "        #print(\"already present\")\n",
    "        n_skip += 1\n",
    "    \n",
    "print('\\n.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render(entry['target_7_img'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"dataset processed, new entries =\", n_add, \"existing entries =\", n_skip)\n",
    "print(\"updated dictionary shape=\", dictionary.shape)\n",
    "print(\"issues status:\")\n",
    "for c in dictionary.columns :\n",
    "    if 'issue' in c :\n",
    "        print(c, sum(dictionary[c]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DICTIONARY FINALISATION\n",
    "i.e. saving the dictionary and its images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.to_pickle(outputPath_dictionary + dictionaryFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dictionary)) :\n",
    "    print(i, len(dictionary), 10*' ', end='\\r')\n",
    "    render(dictionary.iloc[i]['full_img'], saveFig=True, title=str(i), outPath=outputPath_dictionary_img)\n",
    "print('\\n.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
