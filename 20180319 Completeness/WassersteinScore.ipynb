{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import NamedTuple\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ot\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from scipy.spatial import distance\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.model_selection import train_test_split\n",
    "from stats import KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"pickles\", \"df.p\"), \"rb\") as file:\n",
    "    dfs, scaling = pickle.load(file)\n",
    "scaling = scaling.T   # [time vstart vend]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50\n",
    "profiles = np.zeros((len(dfs), n))\n",
    "for i, df in enumerate(dfs):\n",
    "    profiles[i] = np.interp(np.linspace(0, 1, n), df[\"time\"], df[\"vel\"])\n",
    "profiles_scaled = np.zeros_like(profiles)\n",
    "for i in range(n):\n",
    "    profiles_scaled[:, i] = profiles[:, i]*(scaling[:, 1] - scaling[:, 2]) + scaling[:, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexa, indexb = train_test_split(np.arange(len(profiles)), test_size=.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalinga, scalingb = scaling[indexa, :], scaling[indexb, :]\n",
    "profilesa, profilesb = profiles[indexa, :], profiles[indexb, :]\n",
    "pa, pb = profiles_scaled[indexa, :], profiles_scaled[indexb, :]\n",
    "ta, tb = scalinga[:, 0], scalingb[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approach0(profilesa):\n",
    "    return profilesa\n",
    "\n",
    "def approach1(profilesa):\n",
    "    return profilesa[np.random.choice(np.arange(len(profilesa)), len(profilesa)), :]\n",
    "\n",
    "def approach2(profilesa):\n",
    "    return np.array([np.linspace(1, 0, profilesa.shape[1]) for _ in range(profilesa.shape[0])])\n",
    "\n",
    "def approach3(profilesa):\n",
    "    profiles = np.zeros_like(profilesa)\n",
    "    x = np.linspace(0, 1, n)\n",
    "    for i in range(len(profilesa)):\n",
    "        b = -np.random.rand()*2\n",
    "        a = -1-b\n",
    "        profiles[i] = a*x**2 + b*x + 1\n",
    "    return profiles\n",
    "\n",
    "def approach4(profilesa, q=3):\n",
    "    profiles = np.zeros_like(profilesa)\n",
    "    mean = np.mean(profilesa, axis=0)\n",
    "    u,s,v = np.linalg.svd(profilesa-mean, full_matrices=False)\n",
    "    for i in range(len(profilesa)):\n",
    "        profiles[i] = np.dot(np.random.randn(q)*s[:q]/np.sqrt(profilesa.shape[0]), v[:q]) + mean\n",
    "    return profiles\n",
    "\n",
    "def approach5(profilesa):\n",
    "    profiles = approach1(profilesa)\n",
    "    x = np.linspace(0, 1, n)\n",
    "    for i in range(len(profilesa)):\n",
    "        b = (2*np.random.rand() - 1)*.1\n",
    "        a = -b\n",
    "        profiles[i] += a*x**2 + b*x\n",
    "    return profiles\n",
    "\n",
    "def approach6(profilesa, q=3):\n",
    "    profiles = np.zeros_like(profilesa)\n",
    "    mean = np.mean(profilesa, axis=0)\n",
    "    u,s,v = np.linalg.svd(profilesa-mean, full_matrices=False)\n",
    "    for i in range(len(profilesa)):\n",
    "        profiles[i] = np.dot(np.random.randn(q)*s[:q]/np.sqrt(profilesa.shape[0]), v[:q]) + mean\n",
    "    profiles[profiles > 1] = 1\n",
    "    profiles[profiles < 0] = 0\n",
    "    return profiles\n",
    "\n",
    "def approach7(profilesa, q=2):\n",
    "    profiles = np.zeros_like(profilesa)\n",
    "    mean = np.mean(profilesa, axis=0)\n",
    "    u,s,v = np.linalg.svd(profilesa-mean, full_matrices=False)\n",
    "    k = KDE(u[:, :q], scaling=True)\n",
    "    k.compute_bandwidth()\n",
    "    profiles = np.dot(k.sample(len(k.data)) * s[:q], v[:q]) + mean\n",
    "    profiles[profiles > 1] = 1\n",
    "    profiles[profiles < 0] = 0\n",
    "    return profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(approach, test):\n",
    "    return ot.emd2([], [], distance.cdist(test, approach))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_without_scaling(alpha, seed=0, overwrite=False):\n",
    "    filename = os.path.join(\"pickles\", \n",
    "                            \"test_without_scaling_seed{:d}.p\".format(seed))\n",
    "    if os.path.exists(filename) and not overwrite:\n",
    "        with open(filename, \"rb\") as file:\n",
    "            scores1, scores2 = pickle.load(file)\n",
    "    else:\n",
    "        approaches = [approach0, approach1, approach2, approach3, \n",
    "                      approach4, approach5, approach6, approach7]\n",
    "        scores1 = np.zeros(len(approaches))\n",
    "        scores2 = np.zeros_like(scores1)\n",
    "        for i, method in enumerate(approaches):\n",
    "            profiles = method(profilesa)\n",
    "            scores1[i] = score(profiles, profilesb)\n",
    "            scores2[i] = score(profiles, profilesa)\n",
    "        with open(filename, \"wb\") as file:\n",
    "            pickle.dump((scores1, scores2), file)\n",
    "    \n",
    "    for i in range(len(scores1)):\n",
    "        print(\"Method {:d}: {:.4f} {:.4f} {:.4f}\".format(i, scores1[i], scores2[i], \n",
    "                                                         (1+alpha)*scores1[i]-alpha*scores2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_without_scaling(alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_without_scaling(alpha=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_approach_without_scaling(approach, qmax, alpha=1, seed=0, overwrite=False):\n",
    "    filename = os.path.join(\"pickles\", \n",
    "                            \"test_without_scaling_{:s}_qmax{:d}_seed{:d}.p\"\n",
    "                            .format(approach.__name__, qmax, seed))\n",
    "    if os.path.exists(filename) and not overwrite:\n",
    "        with open(filename, \"rb\") as file:\n",
    "            scores1, scores2 = pickle.load(file)\n",
    "    else:\n",
    "        scores1 = np.zeros(qmax+1)\n",
    "        scores2 = np.zeros_like(scores1)\n",
    "        for i in range(qmax+1):\n",
    "            profiles = approach(profilesa, q=i)\n",
    "            scores1[i] = score(profiles, profilesb)\n",
    "            scores2[i] = score(profiles, profilesa)\n",
    "        with open(filename, \"wb\") as file:\n",
    "            pickle.dump((scores1, scores2), file)\n",
    "    \n",
    "    combined_score = (1+alpha)*scores1-alpha*scores2\n",
    "    for i in range(len(scores1)):\n",
    "        print(\"q={:2d}: {:.4f} {:.4f} {:.4f}\".format(i, scores1[i], scores2[i], combined_score[i]),\n",
    "              end=\"\")\n",
    "        if combined_score[i] == np.min(combined_score):\n",
    "            print(\"  *\")\n",
    "        else:\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_approach_without_scaling(approach4, qmax=30, alpha=.25, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_approach_without_scaling(approach7, qmax=10, alpha=.25, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(p1, p2, t1, t2):\n",
    "    a = 25\n",
    "    s1 = np.hstack((np.log(t1[:, np.newaxis])*a, p1))\n",
    "    s2 = np.hstack((np.log(t2[:, np.newaxis])*a, p2))\n",
    "    return ot.emd2([], [], distance.cdist(s1, s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approach0(pa, tt):\n",
    "    return pa, ta\n",
    "\n",
    "def approach1(pa, ta, n=None):\n",
    "    i = np.random.choice(np.arange(len(pa)), len(pa) if n is None else n)\n",
    "    return pa[i, :], ta[i]\n",
    "\n",
    "def approach2(pa, ta):\n",
    "    data = np.array([pa[:, 0], pa[:, -1], np.log(ta)]).T\n",
    "    k = KDE(data, scaling=True)\n",
    "    k.compute_bandwidth()\n",
    "    p = np.zeros_like(pa)\n",
    "    t = np.zeros_like(ta)\n",
    "    for i in range(len(pa)):\n",
    "        pars = k.sample()[0]\n",
    "        pars[1] = max(pars[1], 0)\n",
    "        while pars[1] >= pars[0]:\n",
    "            pars = k.sample()[0]\n",
    "            pars[1] = max(pars[1], 0)\n",
    "        p[i] = np.linspace(pars[0], pars[1], pa.shape[1])\n",
    "        t[i] = np.exp(pars[2])\n",
    "    return p, t\n",
    "\n",
    "def approach3(pa, ta, q=2, n=None):\n",
    "    if n is None:\n",
    "        n = len(pa)\n",
    "    p = np.zeros((n, pa.shape[1]))\n",
    "    t = np.zeros(n)\n",
    "    mean = np.mean(pa, axis=0)\n",
    "    u,s,v = np.linalg.svd(pa-mean, full_matrices=False)\n",
    "    k = KDE(np.hstack((np.log(ta)[:, np.newaxis], u[:, :q])), scaling=True)\n",
    "    k.compute_bandwidth(max_bw=k.silverman())\n",
    "    for i in range(n):\n",
    "        pars = k.sample()[0]\n",
    "        p[i] = np.dot(pars[1:]*s[:q], v[:q]) + mean\n",
    "        t[i] = np.exp(pars[0])\n",
    "    return p, t\n",
    "\n",
    "def approach4(pa, ta, q=2):\n",
    "    data = np.array([pa[:, 0], pa[:, -1], np.log(ta)]).T\n",
    "    k = KDE(data, scaling=True)\n",
    "    k.compute_bandwidth()\n",
    "    p = np.zeros_like(pa)\n",
    "    t = np.zeros_like(ta)\n",
    "    psvd = pa.copy()\n",
    "    for i in range(len(pa)):\n",
    "        psvd[i] = (psvd[i] - psvd[i, -1]) / (psvd[i, 0] - psvd[i, -1])\n",
    "    mean = np.mean(psvd, axis=0)\n",
    "    u,s,v = np.linalg.svd(psvd-mean, full_matrices=False)\n",
    "    for i in range(len(pa)):\n",
    "        pars = k.sample()[0]\n",
    "        pars[1] = max(pars[1], 0)\n",
    "        while pars[1] > pars[0] or pars[1] < 0:\n",
    "            pars = k.sample()[0]\n",
    "            pars[1] = max(pars[1], 0)\n",
    "        p[i] = np.dot(np.random.randn(q)*s[:q]/np.sqrt(pa.shape[0]), v[:q]) + mean\n",
    "        p[i] = p[i] * (pars[0] - pars[1]) + pars[1]\n",
    "        t[i] = np.exp(pars[2])\n",
    "    return p, t\n",
    "\n",
    "def approach5(pa, ta, q=3, a=25, n=None):\n",
    "    if n is None:\n",
    "        n = len(pa)\n",
    "    p = np.zeros((n, pa.shape[1]))\n",
    "    t = np.zeros(n)\n",
    "    svd = np.hstack((a*np.log(ta[:, np.newaxis]), pa))\n",
    "    mean = np.mean(svd, axis=0)\n",
    "    u,s,v = np.linalg.svd(svd-mean, full_matrices=False)\n",
    "    k = KDE(u[:, :q], scaling=True)\n",
    "    k.compute_bandwidth(max_bw=k.silverman())\n",
    "    for i in range(n):\n",
    "        pars = k.sample()[0]\n",
    "        tmp = np.dot(pars*s[:q], v[:q]) + mean\n",
    "        p[i] = tmp[1:]\n",
    "        t[i] = np.exp(tmp[0]/a)\n",
    "    return p, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_scaling(alpha, seed=0, overwrite=False):\n",
    "    filename = os.path.join(\"pickles\", \n",
    "                            \"test_with_scaling_seed{:d}.p\".format(seed))\n",
    "    if os.path.exists(filename) and not overwrite:\n",
    "        with open(filename, \"rb\") as file:\n",
    "            scores1, scores2 = pickle.load(file)\n",
    "    else:\n",
    "        approaches = [approach0, approach1, approach2, approach3, approach4, approach5]\n",
    "        scores1 = np.zeros(len(approaches))\n",
    "        scores2 = np.zeros_like(scores1)\n",
    "        for i, method in enumerate(approaches):\n",
    "            p, t = method(pa, ta)\n",
    "            scores1[i] = score(p, pb, t, tb)\n",
    "            scores2[i] = score(p, pa, t, ta)\n",
    "        with open(filename, \"wb\") as file:\n",
    "            pickle.dump((scores1, scores2), file)\n",
    "    \n",
    "    for i in range(len(scores1)):\n",
    "        print(\"Method {:d}: {:.4f} {:.4f} {:.4f}\".format(i, scores1[i], scores2[i], \n",
    "                                                         (1+alpha)*scores1[i]-alpha*scores2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_with_scaling(alpha=.25, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_approach_with_scaling(approach, qmax, alpha=1, seed=0, overwrite=False):\n",
    "    filename = os.path.join(\"pickles\", \n",
    "                            \"test_with_scaling_{:s}_qmax{:d}_seed{:d}.p\"\n",
    "                            .format(approach.__name__, qmax, seed))\n",
    "    if os.path.exists(filename) and not overwrite:\n",
    "        with open(filename, \"rb\") as file:\n",
    "            scores1, scores2 = pickle.load(file)\n",
    "    else:\n",
    "        scores1 = np.zeros(qmax+1)\n",
    "        scores2 = np.zeros_like(scores1)\n",
    "        for i in range(qmax+1):\n",
    "            p, t = approach(pa, ta, q=i)\n",
    "            scores1[i] = score(p, pb, t, tb)\n",
    "            scores2[i] = score(p, pa, t, ta)\n",
    "        with open(filename, \"wb\") as file:\n",
    "            pickle.dump((scores1, scores2), file)\n",
    "    \n",
    "    combined_score = (1+alpha)*scores1-alpha*scores2\n",
    "    for i in range(len(scores1)):\n",
    "        print(\"q={:2d}: {:7.4f} {:7.4f} {:7.4f}\".format(i, scores1[i], scores2[i], combined_score[i]),\n",
    "              end=\"\")\n",
    "        if combined_score[i] == np.min(combined_score):\n",
    "            print(\"  *\")\n",
    "        else:\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_approach_with_scaling(approach5, qmax=8, alpha=.3, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform comparison multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_multiple_times(approach, qmax, overwrite=False):\n",
    "    filename = os.path.join(\"pickles\", \n",
    "                            \"test_multiple_times_{:s}_qmax{:d}\".format(approach.__name__, qmax))\n",
    "    if os.path.exists(filename) and not overwrite:\n",
    "        with open(filename, \"rb\") as file:\n",
    "            return pickle.load(file)\n",
    "        \n",
    "    nrepeat = 50\n",
    "    np.random.seed(0)\n",
    "    scores1 = np.zeros((nrepeat, qmax+1))\n",
    "    scores2 = np.zeros_like(scores1)\n",
    "    for i in tqdm(range(nrepeat)):\n",
    "        indexa, indexb = train_test_split(np.arange(len(dfs)), test_size=.5, random_state=i)\n",
    "        scalinga, scalingb = scaling[indexa, :], scaling[indexb, :]\n",
    "        pa, pb = profiles_scaled[indexa, :], profiles_scaled[indexb, :]\n",
    "        ta, tb = scalinga[:, 0], scalingb[:, 0]\n",
    "\n",
    "        # Using the default.\n",
    "        scores1[i, 0] = score(pa, pb, ta, tb)\n",
    "\n",
    "        # Using approach with different q values.\n",
    "        for q in range(1, qmax+1):\n",
    "            p, t = approach(pa, ta, q=q)\n",
    "            scores1[i, q] = score(p, pb, t, tb)\n",
    "            scores2[i, q] = score(p, pa, t, ta)\n",
    "    \n",
    "    with open(filename, \"wb\") as file:\n",
    "        pickle.dump((scores1, scores2), file)\n",
    "    \n",
    "    return scores1, scores2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplots(scores):\n",
    "    plt.boxplot(scores)\n",
    "    plt.xticks(np.arange(1, qmax+2), \n",
    "               [\"Training set\\n{:.1f}\".format(np.median(scores[:, 0]))] +\n",
    "               [\"d={:d}\\n{:.1f}\".format(q, np.median(scores[:, q])) for q in range(1, qmax+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qmax = 6\n",
    "s1, s2 = test_multiple_times(approach5, qmax)\n",
    "alpha = .5\n",
    "scores = s1 + alpha*(s1-s2)\n",
    "boxplots(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_difference = scores[:, 1:].copy()\n",
    "for q in range(qmax+1):\n",
    "    score_difference[:, q] = score_difference[:, q] - scores[:, 0]\n",
    "plt.boxplot(score_difference)\n",
    "_ = plt.xticks(np.arange(1, qmax+2), [\"d={:d}\".format(q) for q in range(qmax+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation of scoring measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_scoring(approach, qreal, nmin=100, overwrite=False):\n",
    "    filename = os.path.join(\"pickles\", \"test_validation_{:s}_qreal{:d}_nmin{:d}.p\"\n",
    "                            .format(approach.__name__, qreal, nmin))\n",
    "    if os.path.exists(filename) and not overwrite:\n",
    "        with open(filename, \"rb\") as file:\n",
    "            return pickle.load(file)\n",
    "    \n",
    "    nmax = 5000\n",
    "    nrepeat = 10\n",
    "    qmax = 4\n",
    "    np.random.seed(0)\n",
    "    old_few = np.zeros((nrepeat, qmax+1))\n",
    "    old_many = np.zeros_like(old_few)\n",
    "    self_few = np.zeros_like(old_few)\n",
    "    self_many = np.zeros_like(old_few)\n",
    "    for i in tqdm(range(nrepeat)):\n",
    "        Y1, Y2 = approach(pa, ta, n=nmin, q=qreal)\n",
    "        Z1, Z2 = approach(pa, ta, n=nmax, q=qreal)\n",
    "\n",
    "        # Using the default.\n",
    "        X1, X2 = approach1(Y1, Y2, n=nmax)\n",
    "        old_few[i, 0] = score(X1, Z1[:nmin], X2, Z2[:nmin])\n",
    "        old_many[i, 0] = score(X1, Z1, X2, Z2)\n",
    "        self_few[i, 0] = score(X1, Y1, X2, Y2)\n",
    "        self_many[i, 0] = score(X1, Y1, X2, Y2)\n",
    "\n",
    "        # Using approach 3 with different q values.\n",
    "        for q in range(1, qmax+1):\n",
    "            X1, X2 = approach(Y1, Y2, q=q, n=nmax)\n",
    "            old_few[i, q] = score(X1[:nmin], Z1, X2[:nmin], Z2)\n",
    "            old_many[i, q] = score(X1, Z1, X2, Z2)\n",
    "            self_few[i, q] = score(X1[:nmin], Y1, X2[:nmin], Y2)\n",
    "            self_many[i, q] = score(X1, Y1, X2, Y2)\n",
    "            \n",
    "    with open(filename, \"wb\") as file:\n",
    "        pickle.dump((old_few, old_many, self_few, self_many), file)\n",
    "    \n",
    "    return old_few, old_many, self_few, self_many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qreal = 3\n",
    "old_few, old_many, self_few, self_many = validation_scoring(approach3, qreal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot(old_few)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot(old_many)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = np.linspace(0, 1, 101)\n",
    "beta = np.zeros_like(alpha)\n",
    "old_few2 = old_few[:, 2]\n",
    "self_few2 = self_few[:, 2]\n",
    "old_many2 = old_many[:, 2]\n",
    "for i in range(len(alpha)):\n",
    "    beta[i] = np.corrcoef(old_few2 + alpha[i]*(old_few2-self_few2), \n",
    "                          old_many2)[0][1]\n",
    "    \n",
    "plt.plot(alpha, beta)\n",
    "plt.xlabel(r\"$\\alpha$\")\n",
    "plt.ylabel(\"Correlation\")\n",
    "plt.title(r\"Max correlation: {:.3f} at $\\alpha$= {:.2f}\".format(np.max(beta), alpha[np.argmax(beta)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Y\n",
    "Test Z (klein)\n",
    "Test Z' (groot) -> benadering van originele distributie\n",
    "Generation X\n",
    "\n",
    "Wat we willen: X komt uit zelfde distributie als Y\n",
    "Lijkt X op Z? -- probleem: je kunt het beste gewoon X=Y nemen\n",
    "\n",
    "ideal(X) = W(X,Z')\n",
    "\n",
    "oud(X) = W(X,Z)\n",
    "adhoc(X;a) = W(X,Z) - a*(W(X,Z) - W(X,Y))\n",
    "\n",
    "W(X,Z') = f(X,Y,Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try alternative way: create large number of test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmin, nmax = 100, 5000\n",
    "nrepeat = 10\n",
    "qmax = 4\n",
    "np.random.seed(0)\n",
    "old_scores_few = np.zeros((nrepeat, qmax+2))\n",
    "old_scores_many = np.zeros_like(old_scores_few)\n",
    "new_scores_few = np.zeros_like(old_scores_few)\n",
    "new_scores_many = np.zeros_like(old_scores_few)\n",
    "for i in tqdm(range(nrepeat)):\n",
    "    Y1, Y2 = approach5(pa, ta, n=nmin)\n",
    "    Z1, Z2 = approach5(pa, ta, n=nmin)\n",
    "    \n",
    "    # Using the default.\n",
    "    X1, X2 = approach1(Y1, Y2, n=nmax)\n",
    "    old_scores_few[i, 0] = score(X1[:nmin], Z1, X2[:nmin], Z2)\n",
    "    old_scores_many[i, 0] = score(X1, Z1, X2, Z2)\n",
    "    new_scores_few[i, 0] = 2*old_scores_few[i, 0] - score(X1[:nmin], Y1, X2[:nmin], Y2)\n",
    "    new_scores_many[i, 0] = 2*old_scores_many[i, 0] - score(X1, Y1, X2, Y2)\n",
    "    \n",
    "    # Using approach 3 with different q values.\n",
    "    for q in range(0, qmax+1):\n",
    "        X1, X2 = approach3(Y1, Y2, q=q, n=nmax)\n",
    "        old_scores_few[i, q+1] = score(X1[:nmin], Z1, X2[:nmin], Z2)\n",
    "        old_scores_many[i, q+1] = score(X1, Z1, X2, Z2)\n",
    "        new_scores_few[i, q+1] = 2*old_scores_few[i, q+1] - score(X1[:nmin], Y1, X2[:nmin], Y2)\n",
    "        new_scores_many[i, q+1] = 2*old_scores_many[i, q+1] - score(X1, Y1, X2, Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot(old_scores_few)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot(old_scores_many)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try with uniform distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive(x, n=None):\n",
    "    i = np.random.choice(np.arange(len(x)), len(x) if n is None else n)\n",
    "    return x[i, :]\n",
    "\n",
    "def generate_new(x, n=None, h=.1):\n",
    "    k = KDE(x)\n",
    "    k.set_bandwidth(h)\n",
    "    return k.sample(len(x) if n is None else n)\n",
    "\n",
    "def s(a, b):\n",
    "    return ot.emd2([], [], distance.cdist(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "nmin, nmax = 5, 100\n",
    "nrepeat = 500\n",
    "hh = np.array([.01, 0.02, .04, .06, .08, .1, .15, .2, .3, .4])*2.5\n",
    "real_numbers = np.atleast_2d(np.linspace(0, 1, 100, endpoint=False) + .5/100).T\n",
    "real_numbers = np.atleast_2d(np.random.randn(1, 200)).T\n",
    "\n",
    "test_scores = np.zeros((nrepeat, len(hh)+1))\n",
    "self_scores = np.zeros_like(test_scores)\n",
    "real_scores = np.zeros_like(test_scores)\n",
    "\n",
    "for i in tqdm(range(nrepeat)):\n",
    "    y = np.random.randn(1, nmin).T\n",
    "    z = np.random.randn(1, nmin).T\n",
    "    \n",
    "    x = naive(y, n=nmax)\n",
    "    test_scores[i, 0] = s(x, z)\n",
    "    self_scores[i, 0] = s(x, y)\n",
    "    real_scores[i, 0] = s(x, real_numbers)\n",
    "    for j, h in enumerate(hh):\n",
    "        x = generate_new(y, n=nmax, h=h)\n",
    "        test_scores[i, j+1] = s(x, z)\n",
    "        self_scores[i, j+1] = s(x, y)\n",
    "        real_scores[i, j+1] = s(x, real_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot(s):\n",
    "    plt.subplots(1, 1, figsize=(12, 4))\n",
    "    plt.boxplot(s)\n",
    "    _ = plt.xticks(np.arange(1, len(hh)+2), \n",
    "                   [\"Training set\\n{:.3f}\".format(np.mean(s[:, 0]))]+\n",
    "                   [\"h={:.3f}\\n{:.3f}\".format(h, np.mean(s[:, i+1])) \n",
    "                    for i, h in enumerate(hh)])\n",
    "boxplot(real_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot(test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot(test_scores + 0.31*(test_scores - self_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.mean(test_scores, axis=0)\n",
    "b = np.mean(self_scores, axis=0)\n",
    "c = np.mean(real_scores, axis=0)\n",
    "alpha = np.linspace(0, 1, 101)\n",
    "beta = np.zeros_like(alpha)\n",
    "for i in range(len(alpha)):\n",
    "    beta[i] = np.corrcoef(a + alpha[i]*(a-b), c)[0][1]\n",
    "plt.plot(alpha, beta)\n",
    "plt.xlabel(r\"$\\alpha$\")\n",
    "plt.ylabel(\"Correlation *true metric* and *ad-hoc method*\")\n",
    "alpha[np.argmax(beta)], np.max(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.31\n",
    "plt.plot(a+alpha*(a-b), c, '.')\n",
    "plt.xlabel(\"Ad-hoc metric\")\n",
    "plt.ylabel(\"True metric\")\n",
    "plt.title(r\"$\\alpha^*={:.2f}$, Correlation: {:.4f}\".format(alpha, np.max(beta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g1(n):  # Uniform\n",
    "    return np.random.rand(n, 1)\n",
    "def g2(n):  # Normal, 1D\n",
    "    return np.random.randn(n, 1)\n",
    "def g3(n):  # Normal, 2D\n",
    "    return np.random.randn(n, 2)\n",
    "gkde = KDE([-1, .2, 1], bandwidth=.2)\n",
    "def g4(n):  # KDE\n",
    "    return gkde.sample(n)\n",
    "def g5(n):  # Normal, 3D\n",
    "    return np.random.randn(n, 3)\n",
    "def g6(n):  # Normal, 4D\n",
    "    return np.random.randn(n, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(g4(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestResult = NamedTuple(\"TestResult\", [(\"alpha\", float),\n",
    "                                       (\"correlation\", float),\n",
    "                                       (\"old_correlation\", float),\n",
    "                                       (\"test_scores\", np.ndarray),\n",
    "                                       (\"self_scores\", np.ndarray),\n",
    "                                       (\"real_scores\", np.ndarray)])                                       \n",
    "hh = np.array([.01, 0.02, .04, .06, .08, .1, .15, .2, .3, .4])*3\n",
    "def find_alpha(generator, nyz, nx=100, nreal=500, nrepeat=500, seed=0, overwrite=False):\n",
    "    filename = os.path.join('pickles', \n",
    "                            'result_{:s}_nx{:d}_ny{:d}_nreal{:d}_nrepeat{:d}_seed{:d}.p'\n",
    "                            .format(generator.__name__, nx, nyz, nreal, nrepeat, seed))\n",
    "    if not overwrite and os.path.exists(filename):\n",
    "        with open(filename, 'rb') as file:\n",
    "            result = pickle.load(file)\n",
    "        return result    \n",
    "    \n",
    "    np.random.rand(seed)\n",
    "    real_numbers = generator(nreal)\n",
    "    test_scores = np.zeros((nrepeat, len(hh)+1))\n",
    "    self_scores = np.zeros_like(test_scores)\n",
    "    real_scores = np.zeros_like(test_scores)\n",
    "\n",
    "    for i in tqdm(range(nrepeat), leave=False):\n",
    "        y = generator(nyz)\n",
    "        z = generator(nyz)\n",
    "\n",
    "        x = naive(y, n=nx)\n",
    "        test_scores[i, 0] = s(x, z)\n",
    "        self_scores[i, 0] = s(x, y)\n",
    "        real_scores[i, 0] = s(x, real_numbers)\n",
    "        for j, h in enumerate(hh):\n",
    "            x = generate_new(y, n=nx, h=h)\n",
    "            test_scores[i, j+1] = s(x, z)\n",
    "            self_scores[i, j+1] = s(x, y)\n",
    "            real_scores[i, j+1] = s(x, real_numbers)\n",
    "            \n",
    "    a = np.mean(test_scores, axis=0)\n",
    "    b = np.mean(self_scores, axis=0)\n",
    "    c = np.mean(real_scores, axis=0)\n",
    "    alpha = np.linspace(0, 1, 101)\n",
    "    beta = np.zeros_like(alpha)\n",
    "    for i in range(len(alpha)):\n",
    "        beta[i] = np.corrcoef(a + alpha[i]*(a-b), c)[0][1]\n",
    "    result = TestResult(alpha=alpha[np.argmax(beta)], \n",
    "                        correlation=np.max(beta), \n",
    "                        old_correlation=beta[0],\n",
    "                        test_scores=test_scores, self_scores=self_scores, real_scores=real_scores)\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(result, file)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, g in enumerate([g1, g2, g3, g4], start=1):\n",
    "    for n in [2, 5, 20]:\n",
    "        r = find_alpha(g, n)\n",
    "        print(\"Generator {:d}, n={:2d}, alpha={:.4f},\".format(i, n, r.alpha),\n",
    "              \"corr={:.4f}, corr at a={:.4f}\".format(r.correlation, r.old_correlation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, g in enumerate([g1, g2, g3, g4], start=1):\n",
    "    for n in [2, 5, 20]:\n",
    "        r = find_alpha(g, n, seed=1)\n",
    "        print(\"Generator {:d}, n={:2d}, alpha={:.4f},\".format(i, n, r.alpha),\n",
    "              \"corr={:.4f}, corr at a={:.4f}\".format(r.correlation, r.old_correlation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = find_alpha(g5, 100, nx=1000, nrepeat=100, nreal=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplots(result):\n",
    "    boxplot(result.real_scores)\n",
    "    plt.title(\"True metric\")\n",
    "    boxplot(result.test_scores)\n",
    "    plt.title(\"Old score (correlation={:.4f})\".format(result.old_correlation))\n",
    "    boxplot(result.test_scores + result.alpha*(result.test_scores - result.self_scores))\n",
    "    plt.title(r\"Ad-hoc metric ($\\alpha$={:.2f}, correlation={:.4f})\".format(result.alpha, \n",
    "                                                                            result.correlation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplots(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = find_alpha(g6, 100, nx=1000, nrepeat=100, nreal=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot(res.real_scores)\n",
    "plt.title(\"True metric\")\n",
    "boxplot(res.test_scores)\n",
    "plt.title(\"Old score (correlation={:.4f})\".format(res.old_correlation))\n",
    "boxplot(res.test_scores + res.alpha*(res.test_scores - res.self_scores))\n",
    "plt.title(r\"Ad-hoc metric ($\\alpha$={:.2f}, correlation={:.4f})\".format(res.alpha, res.correlation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
