{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special\n",
    "import scipy.spatial.distance as dist\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import pickle\n",
    "from stats import Copula, CopulaPairs, CopulaOptions, KDE, GaussianMixture\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters.\n",
    "SEED = 0\n",
    "NDATA = 1000\n",
    "MUS = np.array([[0.5, 0.5], [-0.5, -1]])\n",
    "SIGMAS = np.array([[[0.5, -0.1], [-0.1, 0.25]],\n",
    "                   [[0.5, 0.3], [0.3, 0.4]]])\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the data and obtain the PDF.\n",
    "MIXTURE = GaussianMixture(MUS, SIGMAS)\n",
    "SAMPLES = MIXTURE.generate_samples(NDATA)\n",
    "(X1PDF, X2PDF), YPDF = MIXTURE.pdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show the data and the true PDF.\n",
    "HIST2D = plt.hist2d(SAMPLES[:, 0], SAMPLES[:, 1], bins=10, cmap=plt.cm.get_cmap('BuGn_r'))\n",
    "plt.contour(X1PDF, X2PDF, YPDF)\n",
    "plt.xlim([np.min(HIST2D[1]), np.max(HIST2D[1])])\n",
    "plt.ylim([np.min(HIST2D[2]), np.max(HIST2D[2])])\n",
    "plt.title(\"Histogram of data with contour plot of real PDF\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map data to uniformly distributed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the Kernel Density Estimations.\n",
    "KDES = [KDE(SAMPLES[:, i]) for i in range(SAMPLES.shape[1])]\n",
    "for kde in KDES:\n",
    "    kde.compute_bandwidth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the uniform data using the CDF of the KDE.\n",
    "USAMPLES = np.zeros_like(SAMPLES)\n",
    "for i, kde in enumerate(KDES):\n",
    "    USAMPLES[:, i] = kde.cdf(SAMPLES[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIST2D = plt.hist2d(USAMPLES[:, 0], USAMPLES[:, 1], bins=10, cmap=plt.cm.get_cmap('BuGn_r'),\n",
    "                    range=((0, 1), (0, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the copula density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, convert the data, such that each marginal is normally distributed.\n",
    "NSAMPLES = scipy.special.erfinv(USAMPLES*2-1)*np.sqrt(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct KDE the \"normally\" distributed data.\n",
    "CKDE = KDE(NSAMPLES)\n",
    "CKDE.compute_bandwidth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compute the likelihood of all data.\n",
    "SCORE_COPULA = (np.sum(np.log(CKDE.score_samples(NSAMPLES))) + \n",
    "                NDATA*np.log(2*np.pi) + 1/2*np.sum(NSAMPLES**2))\n",
    "SCORE_MARGINALS = np.sum([np.sum(np.log(kde.score_samples(SAMPLES[:, i]))) \n",
    "                          for i, kde in enumerate(KDES)])\n",
    "SCORE = SCORE_COPULA + SCORE_MARGINALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the score if we would directly use the KDE.\n",
    "KDE_DATA = KDE(SAMPLES)\n",
    "KDE_DATA.compute_bandwidth()\n",
    "SCORE_KDE = np.sum(np.log(KDE_DATA.score_samples(SAMPLES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Score with copula: {:.2f}\".format(SCORE))\n",
    "print(\"Score with KDE:    {:.2f}\".format(SCORE_KDE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show that same result is obtained when using the Copula class.\n",
    "COPULA = Copula(SAMPLES)\n",
    "np.sum(np.log(COPULA.pdf(SAMPLES)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute likelihood of newly generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the score if we would directly use the KDE.\n",
    "NDATA = 1000\n",
    "np.random.seed(SEED+1)\n",
    "SAMPLES = MIXTURE.generate_samples(NDATA)\n",
    "SCORE_KDE = np.sum(np.log(KDE_DATA.score_samples(SAMPLES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the score when using the copula.\n",
    "USAMPLES = np.zeros_like(SAMPLES)\n",
    "for i, kde in enumerate(KDES):\n",
    "    USAMPLES[:, i] = kde.cdf(SAMPLES[:, i])\n",
    "NSAMPLES = scipy.special.erfinv(USAMPLES*2-1)*np.sqrt(2)\n",
    "SCORE_COPULA = (np.sum(np.log(CKDE.score_samples(NSAMPLES))) + \n",
    "                NDATA*np.log(2*np.pi) + 1/2*np.sum(NSAMPLES**2))\n",
    "SCORE_MARGINALS = np.sum([np.sum(np.log(kde.score_samples(SAMPLES[:, i]))) \n",
    "                          for i, kde in enumerate(KDES)])\n",
    "SCORE = SCORE_COPULA + SCORE_MARGINALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Score with copula: {:.2f}\".format(SCORE))\n",
    "print(\"Score with KDE:    {:.2f}\".format(SCORE_KDE))\n",
    "print(\"Score with COPULA: {:.2f}\".format(np.sum(np.log(COPULA.pdf(SAMPLES)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test copula on three dimensional data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first two columns of the data comes from the same distribution as for the 2-dimensional data. The third column contains data that is normally distributed with a mean of $\\mu$ and a standard deviation of $\\sigma$, where\n",
    "\n",
    "$$\\mu = (y+1)^2,$$\n",
    "$$\\sigma = \\frac{1}{\\sqrt{|y|}+1},$$\n",
    "\n",
    "where $y$ corresponds to the second column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDATA = 200\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def dependent_data(data_in):\n",
    "    data_out = np.random.randn(len(data_in))\n",
    "    data_out /= (np.sqrt(np.abs(data_in))+1)\n",
    "    data_out += (data_in + 1)**2\n",
    "    return data_out\n",
    "\n",
    "def get_data(ndata):\n",
    "    samples = MIXTURE.generate_samples(ndata)\n",
    "    third = dependent_data(samples[:, 1])\n",
    "    samples = np.concatenate((samples, third[:, np.newaxis]), axis=1)\n",
    "    return samples\n",
    "SAMPLES = get_data(NDATA)\n",
    "TEST = get_data(NDATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_copula(samples, test, pairs):\n",
    "    # Use KDE and compute the scores.\n",
    "    normal_kde = KDE(samples)\n",
    "    normal_kde.compute_bandwidth()\n",
    "    print(\"Score of regular KDE:       {:.2f}\"\n",
    "          .format(np.sum(np.log(normal_kde.score_samples(test)))))\n",
    "    \n",
    "    # Compute score if it is assumed that the data is independent.\n",
    "    kdes = [KDE(samples[:, i]) for i in range(3)]\n",
    "    score_ind = 0\n",
    "    for i, kde in enumerate(kdes):\n",
    "        kde.compute_bandwidth()\n",
    "        score_ind += np.sum(np.log(kde.score_samples(test[:, i])))\n",
    "    print(\"Score assuming independent: {:.2f}\".format(score_ind))\n",
    "        \n",
    "    # Create big copula.\n",
    "    copula = Copula(samples, CopulaOptions())\n",
    "    print(\"Score 3D copula:            {:.2f}\".format(np.sum(np.log(copula.pdf(test)))))\n",
    "    \n",
    "    # Create copulas pairs and show the copula pairs.\n",
    "    copula_pairs = CopulaPairs(samples, pairs)\n",
    "    print(\"Score for pairs:            {:.2f}\".format(np.sum(np.log(copula_pairs.pdf(test)))))\n",
    "    height = np.min((4, 16/len(copula_pairs.parms.copulas)))\n",
    "    _, axes = plt.subplots(1, len(copula_pairs.parms.copulas),\n",
    "                           figsize=(height*len(copula_pairs.parms.copulas), height))\n",
    "    x = np.linspace(0, 1, 51)\n",
    "    xx, yy = np.meshgrid(x, x)\n",
    "    xxyy = np.transpose(np.array([xx, yy]), [1, 2, 0])\n",
    "    for c, ax in zip(copula_pairs.parms.copulas, axes):\n",
    "        ax.contourf(x, x, c.copula(xxyy))\n",
    "        \n",
    "    return normal_kde, kdes, copula, copula_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "k, i, c, p = test_copula(SAMPLES, TEST, [(0, 1), (1, 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = KDE(SAMPLES[:, :2])\n",
    "k2 = KDE(SAMPLES[:, 1:])\n",
    "#k1.set_bandwidth(k.bandwidth)\n",
    "#k2.set_bandwidth(k.bandwidth)\n",
    "k1.compute_bandwidth()\n",
    "k2.compute_bandwidth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb1 = k1.cdf(np.array([[1000, x] for x in TEST[:, 1]]))\n",
    "pb2 = k2.cdf(np.array([[x, 1000] for x in TEST[:, 1]]))\n",
    "score = k1.score_samples(TEST[:, :2]) * k2.score_samples(TEST[:, 1:]) / pb2\n",
    "np.sum(np.log(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.log(k.score_samples(TEST)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score / k.score_samples(TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROBLEM: The above works well with `NDATA = 500`. However, for other values (e.g., `50` or `1000`), it does not work well for the copulas. I think this is due to the fact that, by accident, there is one test sample that is far off from the original samples, hence resulting in a very low probability when calculating its marginal probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test copula on three dimensional data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first three columns are generated in the same way as for the previous dataset. The fourth column is generated like the third column of the previous dataset, but now the dependence is on the first column instead of the second column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDATA = 500\n",
    "np.random.seed(SEED+4)\n",
    "\n",
    "def get_data4(ndata):\n",
    "    samples = get_data(ndata)\n",
    "    fourth = dependent_data(samples[:, 0])\n",
    "    samples = np.concatenate((samples, fourth[:, np.newaxis]), axis=1)\n",
    "    return samples\n",
    "SAMPLES = get_data4(NDATA)\n",
    "TEST = get_data4(NDATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = test_copula(SAMPLES, TEST, [(0, 1), (1, 2), (0, 3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try it for data that is strongly correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_samples(s):\n",
    "    n = s.copy()\n",
    "    n[:, 0] *= -1\n",
    "    n[:, 1] *= 2\n",
    "    n[:, 2] *= 0.5\n",
    "    n[:, 3] *= -2\n",
    "    n += np.random.randn(*s.shape)*0.1\n",
    "    return n\n",
    "SAMPLES2 = np.concatenate((SAMPLES, new_samples(SAMPLES)), axis=1)\n",
    "TEST2 = np.concatenate((TEST, new_samples(TEST)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_copula(SAMPLES2, TEST2, [(0, 1), (1, 2), (0, 3), (0, 4), (1, 5), (2, 6), (3, 7)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try the copulas for the real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the dataset\n",
    "with open(os.path.join('pickles', 'df.p'), 'rb') as f:\n",
    "    dfs, scaling = pickle.load(f)\n",
    "scaling = scaling.T  # [time vstart vend]\n",
    "scaling = scaling[scaling[:, 2] > 0, :]  # Remove full stops\n",
    "scaling[:, 1] = scaling[:, 1] - scaling[:, 2]  # Now it becomes: [time deltav vend] (less correlation)\n",
    "scaling[:, 0] = scaling[:, 1] / scaling[:, 0]  # Now it becomes: [deceleration deltav vend] (better behaved)\n",
    "std_scaling = np.std(scaling, axis=0)\n",
    "mean_scaling = np.mean(scaling, axis=0)\n",
    "scaling = (scaling - mean_scaling) / std_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, test = train_test_split(scaling, test_size=0.1, random_state=0)\n",
    "test_copula(samples, test, [(0, 1), (1, 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_copula(samples, test, [(0, 1), (0, 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_copula(samples, test, [(0, 2), (1, 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = SAMPLES[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=KDE(x)\n",
    "k.compute_bandwidth()\n",
    "kold = deepcopy(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(np.log(k.score_samples(x))))\n",
    "print(np.sum(np.log(k.score_samples(TEST[:, 0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = -np.percentile(k.data_helpers.mindists, 95, axis=0)\n",
    "k.set_bandwidth(tmp / np.mean(tmp) * kold.bandwidth)\n",
    "h = k.bandwidth.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k2 = deepcopy(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k2.compute_bandwidth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-3, 3, 100)\n",
    "plt.plot(x, kold.score_samples(x), label=\"Fixed bandwidth\")\n",
    "plt.plot(x, k2.score_samples(x), label=\"Variable bandwidth\")\n",
    "plt.legend()\n",
    "plt.xlim(np.min(x), np.max(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.zeros((31, 2))\n",
    "t = k.bandwidth.copy()\n",
    "ss = np.logspace(-1, 1, 31)\n",
    "for i, s in enumerate(ss):\n",
    "    k.set_bandwidth(s*t)\n",
    "    score[i, 0] = np.sum(np.log(k.score_samples(x)))\n",
    "    score[i, 1] = np.sum(np.log(k.score_samples(TEST[:, 0])))\n",
    "k.set_bandwidth(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.semilogx(ss, score[:, 0], 'b', label=\"Sampel data\")\n",
    "plt.semilogx(ss, score[:, 1], 'g', label=\"Test data\")\n",
    "plt.legend()\n",
    "print(\"Max test score {:.2f} at {:.3f}\".format(np.max(score[:, 1]), ss[np.argmax(score[:, 1])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(TEST[:, 0], np.log(kold.score_samples(TEST[:, 0])), 'b.')\n",
    "plt.plot(TEST[:, 0], np.log(k.score_samples(TEST[:, 0])), 'g.')\n",
    "plt.plot(TEST[:, 0], np.log(k.score_samples(TEST[:, 0]))-np.log(kold.score_samples(TEST[:, 0])), 'r.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(TEST[:, 0], '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpdf = np.linspace(-3, 3, 100)\n",
    "y1 = k.score_samples(xpdf)\n",
    "y2 = kold.score_samples(xpdf)\n",
    "plt.plot(xpdf, y2, 'b', label=\"old\")\n",
    "plt.plot(xpdf, y1, 'g', label=\"new\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test old\", np.sum(np.log(kold.score_samples(TEST[:, 0]))))\n",
    "print(\"Test new\", np.sum(np.log(k.score_samples(TEST[:, 0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = KDE(x[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.constants.variable_bandwidth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.score_leave_one_out(include_const=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = k.bandwidth.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scores = np.zeros(len(x))\n",
    "for i in range(len(x)):\n",
    "    xtmp = x.copy()\n",
    "    xtmp = np.delete(xtmp, i)\n",
    "    h = k.bandwidth.copy()\n",
    "    h = np.delete(h, i)\n",
    "    ktmp = KDE(xtmp)\n",
    "    ktmp.set_bandwidth(h)\n",
    "    scores[i] = ktmp.score_samples(np.array([x[i]]))\n",
    "print(np.sum(np.log(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = np.logspace(-1, 1, 100)\n",
    "scores = np.zeros(len(ss))\n",
    "for i, s in enumerate(ss):\n",
    "    k.set_bandwidth(s*h)\n",
    "    scores[i] = k.score_leave_one_out(include_const=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(ss, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.sum(np.log(np.sum(np.exp(mindists / k.bandwidth**2) / k.bandwidth, axis=1) - 1/k.bandwidth)) +\n",
    " k.constants.const_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.score_leave_one_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.sum(np.log((np.sum(np.exp(mindists / k.bandwidth**2), axis=0) - 1))) -\n",
    " 200/2*np.log(2*np.pi) - 200*np.log(k.bandwidth) - 200*np.log(199))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.constants.const_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-200/2*np.log(2*np.pi) - 200*np.log(199)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(-200*1/2*np.log(2*np.pi) - 200*np.log(199))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.set_n(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ones((4, 4)) / np.array([1, 2, 3, 4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
