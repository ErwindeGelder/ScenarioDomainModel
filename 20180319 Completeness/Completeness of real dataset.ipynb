{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from fastkde import KDE\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import h5py\n",
    "import scipy.special\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply method for approximating the MISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the dataset\n",
    "with open(os.path.join('pickles', 'df.p'), 'rb') as f:\n",
    "    dfs, scaling = pickle.load(f)\n",
    "scaling = scaling.T  # [time vstart vend]\n",
    "scaling = scaling[scaling[:, 2] > 0, :]  # Remove full stops\n",
    "scaling[:, 1] = scaling[:, 1] - scaling[:, 2]  # Now it becomes: [time deltav vend] (less correlation)\n",
    "scaling[:, 0] = scaling[:, 1] / scaling[:, 0]  # Now it becomes: [deceleration deltav vend] (better behaved)\n",
    "std_scaling = np.std(scaling, axis=0)\n",
    "mean_scaling = np.mean(scaling, axis=0)\n",
    "scaling = (scaling - mean_scaling) / std_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(scaling.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "nmin = 600\n",
    "nstep = 300\n",
    "xmax = 3\n",
    "nx = 61\n",
    "nrepeat = 10\n",
    "seed = 0\n",
    "d = scaling.shape[1]\n",
    "overwrite = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = np.arange(nmin, scaling.shape[0], nstep)\n",
    "bw = np.zeros((nrepeat, len(nn)))\n",
    "pdfs = np.zeros(np.concatenate(([nrepeat, len(nn)], np.ones(d, dtype=np.int)*nx)))\n",
    "x = np.linspace(-xmax, xmax, nx)\n",
    "dx = np.mean(np.gradient(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize the KDE\n",
    "np.random.seed(seed)\n",
    "data = scaling.copy()\n",
    "filename = os.path.join('hdf5', 'pdfs_real_dataset.hdf5')\n",
    "if overwrite or not os.path.exists(filename):\n",
    "    for repeat in tqdm(range(nrepeat)):\n",
    "        np.random.shuffle(data)\n",
    "        kde = KDE(data=data)\n",
    "\n",
    "        # Evaluate MISE for different values of n\n",
    "        for i, n in enumerate(nn):\n",
    "            # Compute the bandwidth\n",
    "            kde.set_n(n)\n",
    "            kde.compute_bw()\n",
    "            bw[repeat, i] = kde.bw\n",
    "\n",
    "            # Compute the pdf\n",
    "            xx = np.array(np.meshgrid(*[x for _ in range(d)])).reshape((d, nx**d)).T\n",
    "            pdf = kde.score_samples(xx).reshape(tuple([nx for _ in range(d)]))\n",
    "            pdfs[repeat, i] = pdf\n",
    "            \n",
    "    # Write data to file\n",
    "    with h5py.File(filename, \"w\") as f:\n",
    "        f.create_dataset(\"pdfs\", data=pdfs)\n",
    "        f.create_dataset(\"bw\", data=bw)\n",
    "else:\n",
    "     with h5py.File(filename, \"r\") as f:\n",
    "        pdfs = f[\"pdfs\"][:]\n",
    "        bw = f[\"bw\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mise_var = np.zeros_like(bw)\n",
    "mise_bias = np.zeros_like(bw)\n",
    "mise = np.zeros_like(bw)\n",
    "kde = KDE(data=scaling)  # Just to get kde.muk\n",
    "\n",
    "# Evaluate MISE for different values of n\n",
    "for repeat in tqdm(range(nrepeat)):\n",
    "    for i, n in enumerate(nn):\n",
    "        # Compute integral of Laplacianxx = np.reshape(xx, (d, nx**d)).T\n",
    "        pdf = pdfs[repeat, i]\n",
    "        laplacian = np.sum(np.array([np.gradient(np.gradient(pdf, axis=i), axis=i) / dx**2 for i in range(d)]), axis=0)\n",
    "        integral = laplacian**2\n",
    "        for _ in range(d):\n",
    "            integral = np.trapz(integral, x)\n",
    "\n",
    "        # Estimate MISE\n",
    "        mise_var[repeat, i] = kde.muk / (n * bw[repeat, i]**d)\n",
    "        mise_bias[repeat, i] = bw[repeat, i]**4 / 4 * integral\n",
    "        mise[repeat, i] = mise_var[repeat, i] + mise_bias[repeat, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for m in mise:\n",
    "    plt.loglog(nn, m, color=[.5, .5, 1])\n",
    "plt.loglog(nn, np.mean(mise, axis=0), 'r-', lw=3, label=\"Mean\")\n",
    "plt.xlabel(\"Number of samples\")\n",
    "plt.ylabel(\"MISE\")\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "ax.loglog(nn, mise[0], lw=5)\n",
    "ax.set_xlabel(\"Number of samples\")\n",
    "ax.set_ylabel(\"MISE\")\n",
    "ax.set_xlim([nn[0], nn[-1]])\n",
    "ax.grid(True)\n",
    "print(\"Power for estimated MISE: {:.2f}\".format(np.polyfit(np.log(nn), np.log(mise[0]), 1)[0]))\n",
    "mise_normal = mise  # Save MISE for later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First map the input data\n",
    "\n",
    "The data is mapped, such that each marginal distribution is closer to a normal distribution. The idea is that the estimation of the MISE should be more consistent. For example, when looking at the plot above, it shows that the approximation of the MISE can be significantly different when the data is reshuffled. It is expected that this is less when the data is closer to a well-behaved Gaussian distribution. Still, the data will not be Gaussian, as only the marginal distributions will be, but it is nevertheless expected that this improve things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "nmin = 600\n",
    "nstep = 300\n",
    "xmax = 3\n",
    "nx = 61\n",
    "xmax_transform = np.max(np.abs(scaling)) + 3\n",
    "nx_transform = 500\n",
    "seed = 0\n",
    "nrepeat = 10\n",
    "d = scaling.shape[1]\n",
    "overwrite = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scaling.copy()\n",
    "kdes = [KDE(data=scaling[:, i], bw=0.25) for i in range(d)]  # 0.25 is approximately similar to Silverman's rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpdf_transform = np.linspace(-xmax_transform, xmax_transform, nx_transform)\n",
    "dx_transform = np.mean(np.gradient(xpdf_transform))\n",
    "f, axs = plt.subplots(1, 3, figsize=(14, 4))\n",
    "ypdf_transform = np.zeros((d, nx_transform))\n",
    "ycdf_transform = np.zeros_like(ypdf_transform)\n",
    "for i, (kde, ax) in enumerate(zip(kdes, axs)):\n",
    "    ax.hist(scaling[:, i], density=True)\n",
    "    ypdf_transform[i] = kde.score_samples(xpdf_transform)\n",
    "    ypdf_transform[i] /= np.trapz(ypdf_transform[i], xpdf_transform)\n",
    "    ycdf_transform[i] = np.cumsum(ypdf_transform[i]) * dx_transform\n",
    "    ycdf_transform[i] /= ycdf_transform[i, -1]\n",
    "    xlim = ax.get_xlim()\n",
    "    ax.plot(xpdf_transform, ypdf_transform[i], 'r-')\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_xlabel('original value')\n",
    "    ax.set_ylabel('pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1, 3, figsize=(14, 4))\n",
    "for i, ax in enumerate(axs):\n",
    "    new = np.interp(scaling[:, i], xpdf_transform, ycdf_transform[i]) * 2 - 1\n",
    "    data[:, i] = scipy.special.erfinv(new)\n",
    "    ax.hist(data[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = np.arange(nmin, scaling.shape[0], nstep)\n",
    "bw = np.zeros((nrepeat, len(nn)))\n",
    "pdfs = np.zeros(np.concatenate(([nrepeat, len(nn)], np.ones(d, dtype=np.int)*nx)))\n",
    "x = np.linspace(-xmax, xmax, nx)\n",
    "dx = np.mean(np.gradient(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compute the pdfs\n",
    "np.random.seed(seed)\n",
    "filename = os.path.join('hdf5', 'pdfs_real_dataset_transformed.hdf5')\n",
    "if overwrite or not os.path.exists(filename):\n",
    "    for repeat in tqdm(range(nrepeat)):\n",
    "        np.random.shuffle(data)\n",
    "        kde = KDE(data=data)\n",
    "\n",
    "        # Evaluate MISE for different values of n\n",
    "        for i, n in enumerate(nn):\n",
    "            # Compute the bandwidth\n",
    "            kde.set_n(n)\n",
    "            kde.compute_bw()\n",
    "            bw[repeat, i] = kde.bw\n",
    "\n",
    "            # Compute the pdf\n",
    "            xx = np.array(np.meshgrid(*[x for _ in range(d)])).reshape((d, nx**d)).T\n",
    "            pdf = kde.score_samples(xx).reshape(tuple([nx for _ in range(d)]))\n",
    "            pdfs[repeat, i] = pdf\n",
    "            \n",
    "    # Write data to file\n",
    "    with h5py.File(filename, \"w\") as f:\n",
    "        f.create_dataset(\"pdfs\", data=pdfs)\n",
    "        f.create_dataset(\"bw\", data=bw)\n",
    "else:\n",
    "     with h5py.File(filename, \"r\") as f:\n",
    "        pdfs = f[\"pdfs\"][:]\n",
    "        bw = f[\"bw\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mise_var = np.zeros_like(bw)\n",
    "mise_bias = np.zeros_like(bw)\n",
    "mise = np.zeros_like(bw)\n",
    "\n",
    "# Evaluate MISE for different values of n\n",
    "for repeat in tqdm(range(nrepeat)):\n",
    "    for i, n in enumerate(nn):\n",
    "        # Compute integral of Laplacianxx = np.reshape(xx, (d, nx**d)).T\n",
    "        pdf = pdfs[repeat, i]\n",
    "        laplacian = np.sum(np.array([np.gradient(np.gradient(pdf, axis=i), axis=i) / dx**2 for i in range(d)]), axis=0)\n",
    "        integral = laplacian**2\n",
    "        for _ in range(d):\n",
    "            integral = np.trapz(integral, x)\n",
    "\n",
    "        # Estimate MISE\n",
    "        mise_var[repeat, i] = kde.muk / (n * bw[repeat, i]**d)\n",
    "        mise_bias[repeat, i] = bw[repeat, i]**4 / 4 * integral\n",
    "        mise[repeat, i] = mise_var[repeat, i] + mise_bias[repeat, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in mise:\n",
    "    plt.loglog(nn, m, color=[.5, .5, 1])\n",
    "plt.loglog(nn, np.mean(mise, axis=0), 'r-', lw=3, label=\"Mean\")\n",
    "plt.xlabel(\"Number of samples\")\n",
    "plt.ylabel(\"MISE\")\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute KDE for first feature seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "seed = 0\n",
    "nrepeat = 10\n",
    "overwrite = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = np.arange(nmin, scaling.shape[0], nstep)\n",
    "bw = np.zeros((nrepeat, len(nn), 2))\n",
    "pdfs1 = np.zeros((nrepeat, len(nn), nx))\n",
    "pdfs2 = np.zeros(np.concatenate(([nrepeat, len(nn)], np.ones(d-1, dtype=np.int)*nx)))\n",
    "laplacian1 = np.zeros_like(pdfs1)\n",
    "laplacian2 = np.zeros_like(pdfs2)\n",
    "x = np.linspace(-xmax, xmax, nx)\n",
    "dx = np.mean(np.gradient(x))\n",
    "data = scaling.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the KDE\n",
    "np.random.seed(seed)\n",
    "filename = os.path.join('hdf5', 'pdfs_split_notebook.hdf5')\n",
    "if overwrite or not os.path.exists(filename):\n",
    "    for repeat in tqdm(range(nrepeat)):\n",
    "        np.random.shuffle(data)\n",
    "        kde1 = KDE(data=data[:, 0])\n",
    "        kde2 = KDE(data=data[:, 1:])\n",
    "        kde1.set_score_samples(x)\n",
    "        xx = np.array(np.meshgrid(*[x for _ in range(d-1)])).reshape((d-1, nx**(d-1))).T\n",
    "        kde2.set_score_samples(xx)\n",
    "\n",
    "        # Evaluate MISE for different values of n\n",
    "        for i, n in enumerate(tqdm(nn, leave=False)):\n",
    "            # Compute the bandwidth\n",
    "            for j, kde in enumerate([kde1, kde2]):\n",
    "                kde.set_n(n)\n",
    "                kde.compute_bw()\n",
    "                bw[repeat, i, j] = kde.bw\n",
    "\n",
    "            # Compute the pdf\n",
    "            pdfs1[repeat, i] = kde1.score_samples()\n",
    "            laplacian1[repeat, i] = kde1.laplacian()\n",
    "            pdf = kde2.score_samples().reshape(tuple([nx for _ in range(d-1)]))\n",
    "            pdfs2[repeat, i] = pdf\n",
    "            laplacian = kde2.laplacian().reshape(tuple([nx for _ in range(d-1)]))\n",
    "            laplacian2[repeat, i] = laplacian\n",
    "            \n",
    "    # Write data to file\n",
    "    with h5py.File(filename, \"w\") as f:\n",
    "        f.create_dataset(\"pdfs1\", data=pdfs1)\n",
    "        f.create_dataset(\"pdfs2\", data=pdfs2)\n",
    "        f.create_dataset(\"bw\", data=bw)\n",
    "else:\n",
    "     with h5py.File(filename, \"r\") as f:\n",
    "        pdfs1 = f[\"pdfs1\"][:]\n",
    "        pdfs2 = f[\"pdfs2\"][:]\n",
    "        bw = f[\"bw\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mise = np.zeros((nrepeat, len(nn)))\n",
    "mise1 = np.zeros_like(mise)\n",
    "mise2 = np.zeros_like(mise)\n",
    "kde1 = KDE(data=scaling[:, 0])  # Just to get kde.muk\n",
    "kde2 = KDE(data=scaling[:, 1:])  # Just to get kde.muk\n",
    "\n",
    "# Evaluate MISE for different values of n\n",
    "for repeat in tqdm(range(nrepeat)):\n",
    "    for i, n in enumerate(nn):\n",
    "        # Compute the MISE of the first part\n",
    "        pdf = pdfs1[repeat, i]\n",
    "        laplacian = np.gradient(np.gradient(pdf)) / dx**2\n",
    "        laplacian = laplacian1[repeat, i]\n",
    "        integral = np.trapz(laplacian**2, x)\n",
    "        mise1[repeat, i] = kde1.muk / (n * bw[repeat, i, 0]) + bw[repeat, i, 0]**4 / 4 * integral\n",
    "        \n",
    "        # Compute MISE of the second part\n",
    "        pdf = pdfs2[repeat, i]\n",
    "        laplacian = np.sum(np.array([np.gradient(np.gradient(pdf, axis=i), axis=i) / dx**2 for i in range(d-1)]), axis=0)\n",
    "        laplacian = laplacian2[repeat, i]\n",
    "        integral = laplacian**2\n",
    "        for _ in range(d-1):\n",
    "            integral = np.trapz(integral, x)\n",
    "        mise2[repeat, i] = kde2.muk / (n * bw[repeat, i, 1]**(d-1)) + bw[repeat, i, 1]**4 / 4 * integral\n",
    "        \n",
    "        # Compute the integrals of the squared probabilities\n",
    "        integral1 = np.trapz(pdfs1[repeat, i]**2, x)\n",
    "        integral2 = pdfs2[repeat, i]**2\n",
    "        for _ in range(d-1):\n",
    "            integral2 = np.trapz(integral2, x)\n",
    "            \n",
    "        # Compute the total MISE\n",
    "        mise = integral1 * mise2 + integral2 * mise1 + mise1 * mise2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in mise:\n",
    "    plt.loglog(nn, m, color=[.5, .5, 1])\n",
    "plt.loglog(nn, np.mean(mise, axis=0), 'r-', lw=3, label=\"Mean\")\n",
    "plt.xlabel(\"Number of samples\")\n",
    "plt.ylabel(\"MISE\")\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in mise:\n",
    "    plt.loglog(nn, m, color=[.5, .5, 1])\n",
    "plt.loglog(nn, np.mean(mise, axis=0), 'r-', lw=3, label=\"Mean\")\n",
    "plt.xlabel(\"Number of samples\")\n",
    "plt.ylabel(\"MISE\")\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "ax.loglog(nn, mise_normal[0], lw=5, label=\"Normal\")\n",
    "ax.loglog(nn, mise[0], lw=5, label=\"Acceleration independent\")\n",
    "ax.set_xlabel(\"Number of samples\")\n",
    "ax.set_ylabel(\"MISE\")\n",
    "ax.set_xlim([nn[0], nn[-1]])\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "print(\"Power for estimated MISE: {:.2f}\".format(np.polyfit(np.log(nn), np.log(mise[0]), 1)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(nn, bw[0, :, 0])\n",
    "plt.semilogx(nn, bw[0, :, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map the data, such that one feature is independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scaling / np.std(scaling, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde = KDE(data=data)\n",
    "kde.compute_bandwidth()\n",
    "score_kde = kde.score_leave_one_out()\n",
    "print(\"Total score:       {:.4f}\".format(score_kde))\n",
    "\n",
    "kde1 = KDE(data=data[:, 0])\n",
    "kde1.compute_bandwidth()\n",
    "score_kde1 = kde1.score_leave_one_out()\n",
    "print(\"Score feature 0:   {:.4f}\".format(score_kde1))\n",
    "\n",
    "kde2 = KDE(data=data[:, [1, 2]])\n",
    "kde2.compute_bandwidth()\n",
    "score_kde2 = kde2.score_leave_one_out()\n",
    "print(\"Score feature 1&2: {:.4f}\".format(score_kde2))\n",
    "print(\"Sum scores 0, 1&2: {:.4f}\".format(score_kde1+score_kde2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scaling / np.std(scaling, axis=0)\n",
    "A = np.array([np.ones(len(data)), data[:, 1], data[:, 2]]).T\n",
    "theta = np.linalg.lstsq(A, data[:, 0], rcond=None)[0]\n",
    "print(theta)\n",
    "data[:, 0] -= np.dot(A, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde = KDE(data=data)\n",
    "kde.compute_bandwidth()\n",
    "score_kde = kde.score_leave_one_out()\n",
    "print(\"Total score:       {:.4f}\".format(score_kde))\n",
    "\n",
    "kde1 = KDE(data=data[:, 0])\n",
    "kde1.compute_bandwidth()\n",
    "score_kde1 = kde1.score_leave_one_out()\n",
    "print(\"Score feature 0:   {:.4f}\".format(score_kde1))\n",
    "\n",
    "kde2 = KDE(data=data[:, [1, 2]])\n",
    "kde2.compute_bandwidth()\n",
    "score_kde2 = kde2.score_leave_one_out()\n",
    "print(\"Score feature 1&2: {:.4f}\".format(score_kde2))\n",
    "print(\"Sum scores 0, 1&2: {:.4f}\".format(score_kde1+score_kde2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scaling / np.std(scaling, axis=0)\n",
    "A = np.array([np.ones(len(data)), data[:, 0], data[:, 2]]).T\n",
    "theta = np.linalg.lstsq(A, data[:, 1], rcond=None)[0]\n",
    "print(theta)\n",
    "data[:, 1] -= np.dot(A, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde = KDE(data=data)\n",
    "kde.compute_bandwidth()\n",
    "score_kde = kde.score_leave_one_out()\n",
    "print(\"Total score:       {:.4f}\".format(score_kde))\n",
    "\n",
    "kde1 = KDE(data=data[:, 1])\n",
    "kde1.compute_bandwidth()\n",
    "score_kde1 = kde1.score_leave_one_out()\n",
    "print(\"Score feature 1:   {:.4f}\".format(score_kde1))\n",
    "\n",
    "kde2 = KDE(data=data[:, [0, 2]])\n",
    "kde2.compute_bandwidth()\n",
    "score_kde2 = kde2.score_leave_one_out()\n",
    "print(\"Score feature 1&2: {:.4f}\".format(score_kde2))\n",
    "print(\"Sum scores 0, 1&2: {:.4f}\".format(score_kde1+score_kde2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scaling / np.std(scaling, axis=0)\n",
    "A = np.array([np.ones(len(data)), data[:, 0], data[:, 1]]).T\n",
    "theta = np.linalg.lstsq(A, data[:, 2], rcond=None)[0]\n",
    "print(theta)\n",
    "data[:, 2] -= np.dot(A, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde = KDE(data=data)\n",
    "kde.compute_bandwidth()\n",
    "score_kde = kde.score_leave_one_out()\n",
    "print(\"Total score:       {:.4f}\".format(score_kde))\n",
    "\n",
    "kde1 = KDE(data=data[:, 2])\n",
    "kde1.compute_bandwidth()\n",
    "score_kde1 = kde1.score_leave_one_out()\n",
    "print(\"Score feature 1:   {:.4f}\".format(score_kde1))\n",
    "\n",
    "kde2 = KDE(data=data[:, [0, 1]])\n",
    "kde2.compute_bandwidth()\n",
    "score_kde2 = kde2.score_leave_one_out()\n",
    "print(\"Score feature 1&2: {:.4f}\".format(score_kde2))\n",
    "print(\"Sum scores 0, 1&2: {:.4f}\".format(score_kde1+score_kde2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde = KDE(data=data[:, 0])\n",
    "kde.compute_bandwidth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-3, 7, 10000)\n",
    "kde.set_score_samples(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = kde.score_samples()\n",
    "plt.plot(x, pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian = np.gradient(np.gradient(pdf)) / np.mean(np.diff(x))**2\n",
    "plt.plot(x, laplacian**2)\n",
    "plt.plot(x, kde.laplacian()**2)\n",
    "plt.plot(x, laplacian**2 - kde.laplacian()**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
