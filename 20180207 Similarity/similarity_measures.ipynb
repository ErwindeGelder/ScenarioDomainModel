{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario similarity measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "rc('text', usetex=True)\n",
    "from matplotlib2tikz import save as tikz_save\n",
    "import os\n",
    "import scipy\n",
    "from scipy import linalg\n",
    "from scipy import interpolate\n",
    "from DynamicTimeWarping import DynamicTimeWarping\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tikz_path = 'figures'\n",
    "def tikz(name, extras=None):\n",
    "    # Convert to tikz\n",
    "    tikz_save(os.path.join(tikz_path, '{:s}.tikz'.format(name)),\n",
    "              figureheight='\\\\figureheight', figurewidth='\\\\figurewidth',\n",
    "              extra_axis_parameters=extras, show_info=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define function for quickly making tables\n",
    "table_folder = 'tabular'\n",
    "tex_folder = 'tex'\n",
    "\n",
    "def write(f, text):\n",
    "    f.write(text)\n",
    "    print(text, end=\"\")\n",
    "def str_e(x, decimals=1):\n",
    "    if x >= 1 and x < 10:\n",
    "        return '{:.{decimals}f}'.format(x, decimals=decimals)\n",
    "    else:\n",
    "        exp = np.floor(np.log10(x)).astype(np.int)\n",
    "        return '{:.{decimals}f} \\\\cdot 10^{{{:d}}}'.format(x / 10.**exp, exp, decimals=decimals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define method for looping through set of profiles and print score\n",
    "def table_distance(V, func, **kwargs):\n",
    "    nv = len(V)\n",
    "    print(\"  \", end=\"\")\n",
    "    for i in range(nv):\n",
    "        print(\" {:7d}\".format(i+1), end=\"\")\n",
    "    print(\"\")\n",
    "    for i in range(nv):\n",
    "        print(\"{:2d}\".format(i+1), end=\"\")\n",
    "        for j in range(nv):\n",
    "            if i == j:\n",
    "                print(\" {:7s}\".format(\"\"), end=\"\")\n",
    "            else:\n",
    "                print(\" {:7.1e}\".format(func(V[i], V[j], **kwargs)), end=\"\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create two example figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('..', '20171126 Parametrization', 'df.p'), 'rb') as f:\n",
    "    (dfs, scaling) = pickle.load(f)\n",
    "# Only use first n profiles\n",
    "n = len(dfs)\n",
    "dfs = dfs[:n].copy()\n",
    "scaling = scaling.T[:n].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show a profile\n",
    "# 322: hardest braking\n",
    "# 292: Looks most at 322 when only looking at start and end velocity\n",
    "# 143: Looks very similar to 292\n",
    "# 381: Acceleratin similar to 292, but much shorter\n",
    "ii = [322, 143, 292, 381]\n",
    "ts = 0.1\n",
    "V = []\n",
    "A = []\n",
    "for j, i in enumerate(ii):\n",
    "    t = dfs[i]['time']*scaling[i, 0]\n",
    "    v = (dfs[i]['vel']*(scaling[i, 1] - scaling[i, 2]) + scaling[i, 2])\n",
    "    tnew = np.arange(t.values[0], np.ceil(t.values[-1] / ts)+1) * ts\n",
    "    vnew = np.interp(tnew, t, v)\n",
    "    V.append(vnew)\n",
    "    A.append(np.gradient(vnew) / ts)\n",
    "    plt.plot(tnew, vnew, '.', label=r\"$\\textbf{{v}}_{:d}$\".format(j+1), ms=1)\n",
    "    print(\"Average deceleration: {:.2f} m/s^2\".format((scaling[i, 1] - scaling[i, 2]) / scaling[i, 0]))\n",
    "plt.grid('on')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Velocity [km/h]')\n",
    "plt.legend()\n",
    "tikz('velocity_profile_example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We will resample all profiles, as we have to use them\n",
    "dfs_resampled = []\n",
    "for i, df in enumerate(dfs):\n",
    "    t = df['time']*scaling[i, 0]\n",
    "    v = (df['vel']*(scaling[i, 1] - scaling[i, 2]) + scaling[i, 2])\n",
    "    tnew = np.arange(t.values[0], np.ceil(t.values[-1] / ts)+1) * ts\n",
    "    vnew = np.interp(tnew, t, v)\n",
    "    dfs_resampled.append(pd.DataFrame(np.array([tnew, vnew]).T, columns=['time', 'vel']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lp(xx, yy, p):\n",
    "    # Sample yy to have the same number of elements\n",
    "    yy = np.interp(np.linspace(0, len(yy), len(xx)), np.arange(0, len(yy)), yy)\n",
    "    \n",
    "    # Compute the norm\n",
    "    return np.sum(np.abs(xx - yy)**p) ** (1/p)\n",
    "\n",
    "def euclidean(xx, yy):\n",
    "    return lp(xx, yy, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = len(V)\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        if not i == j:\n",
    "            print(\"Deuclidean({:d},{:d}) = {:.1f}\".format(i+1, j+1, euclidean(V[i], V[j])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, j in zip([1, 1, 0], [0, 2, 2]):\n",
    "    f, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "    ax.plot(V[i], '.', label='Profile {:d}'.format(i+1), ms=1)\n",
    "    ax.plot(np.interp(np.linspace(0, len(V[j]), len(V[i])), np.arange(0, len(V[j])), V[j]), '.', \n",
    "            label='Profile {:d}'.format(j+1), ms=1)\n",
    "    ax.set_xlabel('Sample')\n",
    "    ax.set_ylabel('Velocity [m/s]')\n",
    "    ax.grid('on')\n",
    "    tikz('velocity_profiles_resampled{:d}{:d}'.format(i+1, j+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Feature-based\n",
    "\n",
    "### Fourier coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fft(x):\n",
    "    X = np.fft.rfft(x)\n",
    "    f = np.arange(np.floor(len(x)/2)+1) / (len(x) * ts)\n",
    "    return f, X\n",
    "def fft_at_freq(x, freqs):\n",
    "    f, X = fft(x)\n",
    "    return np.interp(freqs, f, X)\n",
    "def fourier_based_distance(x, y, w=None):\n",
    "    xhat = fft_at_freq(x, freq) / len(x)\n",
    "    yhat = fft_at_freq(y, freq) / len(y)\n",
    "    if w is None:  # Use default weights in this case\n",
    "        w = [1/100, 1, 1, 1]\n",
    "    return np.sqrt(np.sum(w*np.abs(xhat - yhat)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3))\n",
    "for v in V:\n",
    "    f, X = fft(v)\n",
    "    ax1.semilogy(f, np.abs(X)/len(v), '.')\n",
    "    ax2.plot(f, np.angle(X)/np.pi*180, '.')\n",
    "ax1.grid('on')\n",
    "ax2.grid('on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute fourier coefficients for all profiles\n",
    "freq = [0, 0.5, 1, 1.5]\n",
    "FCs = np.array([fft_at_freq(df['vel'], freq)/len(df['vel']) for df in dfs_resampled])\n",
    "FCweights = 1 / np.std(FCs, axis=0) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write weights to tex file\n",
    "with open(os.path.join(tex_folder, 'FC_weights.tex'), 'w') as f:\n",
    "    for i, w in enumerate(FCweights):\n",
    "        if i == len(FCweights)-1:\n",
    "            write(f, 'and ')\n",
    "        write(f, '$w_{{{:d}}}=\\\\unit[{:s}]{{s^2/m^2}}'.format(i, str_e(w)))\n",
    "        write(f, '$')\n",
    "        if i < len(FCweights)-1:\n",
    "            write(f, ', ')\n",
    "    write(f, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "table_distance(V, fourier_based_distance, w=FCweights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(table_folder, 'fourier_coefficients.tex'), 'w') as f:\n",
    "    write(f, '\\\\begin{tabular}{crrrr}\\n')\n",
    "    write(f, '    \\\\toprule\\n')\n",
    "    write(f, '    Time    & \\\\multicolumn{3}{c}{Fourier coefficients} \\\\\\\\\\n')\n",
    "    write(f, '    series ')\n",
    "    for fr in freq:\n",
    "        write(f, ' & $\\\\unit[{:.1f}]{{Hz}}$'.format(fr))\n",
    "    write(f, ' \\\\\\\\\\\\otoprule\\n')\n",
    "    for i, v in enumerate(V):\n",
    "        F = fft_at_freq(v, freq) / len(v)\n",
    "        f_real = np.real(F)\n",
    "        f_imag = np.imag(F)\n",
    "        write(f, '    $\\\\profile{{{:d}}}$'.format(i+1))\n",
    "        for real, imag in zip(f_real, f_imag):\n",
    "            write(f, ' & ${:.2f}{:s}{:.2f}\\\\imagi$'.format(real, '+' if imag >= 0 else '-', np.abs(imag)))\n",
    "        write(f, ' \\\\\\\\\\n')\n",
    "    write(f, '    \\\\bottomrule\\n')\n",
    "    write(f, '\\\\end{tabular}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Determine parameters for all time series\n",
    "par_all = np.array([[df['vel'][0], \n",
    "                     df['vel'].values[-1], \n",
    "                     df['vel'][0] - df['vel'].values[-1], \n",
    "                     df['time'].values[-1]] for df in dfs_resampled])\n",
    "w = 1 / np.std(par_all, axis=0)**2\n",
    "par_weights = [w[3], w[2], w[1]]  # Only take weights for time difference, velocity difference, and velocity reduction\n",
    "par_w_units = ['s^{-2}', 's^2/m^2', 's^2/m^2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write weights to tex file\n",
    "with open(os.path.join(tex_folder, 'custom_par_weights.tex'), 'w') as f:\n",
    "    for i, (w, u) in enumerate(zip(par_weights, par_w_units)):\n",
    "        if i == len(par_weights)-1:\n",
    "            write(f, 'and ')\n",
    "        write(f, '$w_{{{:d}}}=\\\\unit[{:s}]{{{:s}}}'.format(i, str_e(w), u))\n",
    "        write(f, '$')\n",
    "        write(f, ', ')\n",
    "    write(f, 'respectively.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Time duration, velocity difference, end velocity\n",
    "def parameter_based_distance(x, y, w=None):\n",
    "    x_dt = (len(x) - 1) * ts\n",
    "    y_dt = (len(y) - 1) * ts\n",
    "    x_dv = np.max(x) - np.min(x)\n",
    "    y_dv = np.max(y) - np.min(y)\n",
    "    x_ve = x[-1]\n",
    "    y_ve = y[-1]\n",
    "    \n",
    "    if w is None:\n",
    "        w_dt = 1\n",
    "        w_dv = 0.2\n",
    "        w_ve = 0.2\n",
    "    else:\n",
    "        w_dt, w_dv, w_ve = w\n",
    "    \n",
    "    return np.sqrt(w_dt*(x_dt-y_dt)**2 + w_dv*(x_dv-y_dv)**2 + w_ve*(x_ve-y_ve)**2)\n",
    "table_distance(V, parameter_based_distance, w=par_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a table with the parameters\n",
    "with open(os.path.join(table_folder, 'scenario_parameters.tex'), 'w') as f:\n",
    "    write(f, '\\\\begin{tabular}{crrrr}\\n')\n",
    "    write(f, '    \\\\toprule\\n')\n",
    "    write(f, '    Time & \\\\multicolumn{4}{c}{Parameters} \\\\\\\\\\n')\n",
    "    write(f, '    series & $\\\\parvstart\\,[\\\\unit{m/s}]$ & $\\\\parvend\\,[\\\\unit{m/s}]$')\n",
    "    write(f, ' & $\\\\pardv\\,[\\\\unit{m/s}]$ & $\\\\pardt\\,[\\\\unit{s}]$ \\\\\\\\\\\\otoprule\\n')\n",
    "    for i, v in enumerate(V):\n",
    "        write(f, '    $\\\\profile{{{:d}}}$ & {:.1f} & {:.1f}'.format(i+1, v[0], v[-1]))\n",
    "        write(f, ' & {:.1f} & {:.1f} \\\\\\\\\\n'.format(v[0]-v[-1], (len(v)-1)*ts))\n",
    "    write(f, '    \\\\bottomrule\\n')\n",
    "    write(f, '\\\\end{tabular}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Note, time has no influence\n",
    "def spl_coef(x, k=1):  # k=number of interior knots\n",
    "    t = np.arange(len(x))*ts\n",
    "    knots = np.linspace(0, t[-1], k+2)[1:-1]\n",
    "    t, c, d = interpolate.splrep(t, x, t=knots)\n",
    "    nr_coefficients = k + 4\n",
    "    return c[:nr_coefficients]\n",
    "def spl_distance(x, y, k=1, w=None):\n",
    "    cx = spl_coef(x, k=k)\n",
    "    tx = (len(x) - 1)*ts\n",
    "    par_x = np.concatenate(([tx], cx))\n",
    "    cy = spl_coef(y, k=k)\n",
    "    ty = (len(x) - 1)*ts\n",
    "    par_y = np.concatenate(([ty], cy))\n",
    "    if w is None:\n",
    "        w = np.ones(len(par_x))\n",
    "    return np.sum(w * (par_x - par_y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute spline coefficients for all time series\n",
    "spl_coefs = np.array([spl_coef(df['vel']) for df in dfs_resampled])\n",
    "tduration = np.array([df['time'].values[-1] for df in dfs_resampled])  # Compute tduration, because we will add this as parameter\n",
    "spl_weights = 1 / np.concatenate(([np.std(tduration)], np.std(spl_coefs, axis=0)))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print weights to tex file\n",
    "with open(os.path.join(tex_folder, 'spl_weights.tex'), 'w') as f:\n",
    "    write(f, 'The associated weight for the length of the time series is $w_0=\\\\unit[{:s}]{{s^{{-2}}}}$.\\n'.format(str_e(spl_weights[0])))\n",
    "    write(f, 'For the spline coefficients $c_1$ through $c_{{{:d}}}$, the weights are '.format(len(spl_weights)-1))\n",
    "    for i, w in enumerate(spl_weights[1:]):\n",
    "        if i == len(spl_weights)-2:\n",
    "            write(f, 'and ')\n",
    "        write(f, '$w_{{{:d}}}=\\\\unit[{:s}]{{s^2/m^2}}$, '.format(i+1, str_e(w)))\n",
    "    write(f, 'respectively.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a table with the parameters\n",
    "with open(os.path.join(table_folder, 'spline_parameters.tex'), 'w') as f:\n",
    "    write(f, '\\\\begin{tabular}{crrrrrr}\\n')\n",
    "    write(f, '    \\\\toprule\\n')\n",
    "    write(f, '    Time & $\\\\pardt\\,[\\\\unit{s}]$ & \\\\multicolumn{5}{c}{Spline parameters} \\\\\\\\\\n')\n",
    "    write(f, '    series &')\n",
    "    for i in range(5):  # 5 spline parameters\n",
    "        write(f, ' & $c_{{{:d}}}\\,[\\\\unit{{m/s}}]$'.format(i+1))\n",
    "    write(f, ' \\\\\\\\\\\\otoprule\\n')\n",
    "    for i, v in enumerate(V):\n",
    "        write(f, '    $\\\\profile{{{:d}}}$ & {:.1f}'.format(i+1, (len(v)-1)*ts))\n",
    "        for c in spl_coef(v):\n",
    "            write(f, ' & {:.1f}'.format(c))\n",
    "        write(f, ' \\\\\\\\\\n')\n",
    "    write(f, '    \\\\bottomrule\\n')\n",
    "    write(f, '\\\\end{tabular}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table_distance(V, spl_distance, w=spl_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto-regressive models\n",
    "\n",
    "Problem that duration is not taken into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ar(x, n=3):\n",
    "    A = np.zeros((len(x)-n+1, n))\n",
    "    A[:, 0] = 1\n",
    "    for i in range(1, n):\n",
    "        A[:, i] = x[n-i-1:-i]\n",
    "    b = x[n-1:]\n",
    "    return np.linalg.lstsq(A, b)[0]\n",
    "def ar_distance(x, y, n=3, w=None):\n",
    "    xhat = ar(x, n=n)\n",
    "    yhat = ar(y, n=n)\n",
    "    if w is None:\n",
    "        w = np.ones(n)\n",
    "    return np.sqrt(np.sum(w * (xhat - yhat)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Alternative method using Yule-Walker method\n",
    "class YW(object):\n",
    "    \"\"\"A class to fit AR model using Yule-Walker method\"\"\"\n",
    "\n",
    "    def __init__(self, X):\n",
    "        self.X = X - np.mean(X)\n",
    "        \n",
    "    def autocorr(self, lag=3):\n",
    "        c = np.correlate(self.X, self.X, 'full')\n",
    "        mid = len(c)//2\n",
    "        acov = c[mid:mid+lag]\n",
    "        acor = acov/acov[0]\n",
    "        return acor\n",
    "    \n",
    "    def fit(self, p=3):\n",
    "        ac = self.autocorr(p+1)\n",
    "        R = linalg.toeplitz(ac[:p])\n",
    "        r = ac[1:p+1]\n",
    "        self.phi = np.linalg.solve(R, r)\n",
    "yw = YW(V[0])\n",
    "print(yw.autocorr())\n",
    "yw.fit()\n",
    "yw.phi  # What does this mean? It is completely different from the previous method..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1, len(V), figsize=(5*len(V), 4))\n",
    "n_ar = 3\n",
    "A = []\n",
    "for j, (v, ax) in enumerate(zip(V, axs)):\n",
    "    a = ar(v/3.6, n=n_ar)\n",
    "    A.append(a)\n",
    "    y = np.zeros_like(v)\n",
    "    y[:n_ar-1] = v[:n_ar-1] / 3.6\n",
    "    for i in range(n_ar-1, len(y)):\n",
    "        y[i] = a[0] + np.sum(np.flipud(a[1:]) * y[i-n_ar+1:i])\n",
    "    y *= 3.6\n",
    "    ax.plot(v, '.', label='Original')\n",
    "    ax.plot(y, '.', label='Auto-regression fit')\n",
    "    ax.set_xlabel('Sample')\n",
    "    ax.set_ylabel('Velocity [km/h]')\n",
    "    ax.set_title('Time series {:d}'.format(j+1))\n",
    "    ax.grid('on')\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(table_folder, 'ar_coefficients.tex'), 'w') as f:\n",
    "    write(f, '\\\\begin{tabular}{crrr}\\n')\n",
    "    write(f, '    \\\\toprule\\n')\n",
    "    write(f, '    Time    & \\\\multicolumn{3}{c}{Auto-regression coefficients} \\\\\\\\\\n')\n",
    "    write(f, '    series & $a_0\\,[\\\\unit{m/s}]$ & $a_1$ & $a_2$ \\\\\\\\ \\\\otoprule\\n')\n",
    "    for i, aa in enumerate(A):\n",
    "        write(f, '    $\\\\profile{{{:d}}}$'.format(i+1))\n",
    "        for a in aa:\n",
    "            write(f, ' & {:.2f}'.format(a))\n",
    "        write(f, ' \\\\\\\\\\n')\n",
    "    write(f, '    \\\\bottomrule\\n')\n",
    "    write(f, '\\\\end{tabular}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ar_coefficients = np.array([ar(df['vel'], n=n_ar) for df in dfs_resampled])\n",
    "ar_weights = 1 / np.std(ar_coefficients, axis=0)**2\n",
    "with open(os.path.join(tex_folder, 'ar_weights.tex'), 'w') as f:\n",
    "    write(f, '$w_{{0}}=\\\\unit[{:s}]{{s^2/m^2}}$, '.format(str_e(ar_weights[0])))\n",
    "    for i, w in enumerate(ar_weights[1:]):\n",
    "        if i == len(ar_weights)-2:\n",
    "            write(f, 'and ')\n",
    "        write(f, '$w_{{{:d}}}={:s}$, '.format(i+1, str_e(w)))\n",
    "    write(f, 'respectively.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "table_distance(V, ar_distance, n=n_ar, w=ar_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Time Warping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = DynamicTimeWarping(scale_score=True)\n",
    "table_distance(V, d.dtw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show warping path between v1 and v3\n",
    "d.dtw(V[0], V[2])\n",
    "wx, wy = d.compute_warpings()\n",
    "plt.plot(V[0][wx], '.', label=r'$\\textbf{v}_1$', ms=1)\n",
    "plt.plot(V[2][wy], '.', label=r'$\\textbf{v}_3$', ms=1)\n",
    "plt.xlabel('$k$')\n",
    "plt.ylabel('Speed [km/h]')\n",
    "plt.grid('on')\n",
    "plt.legend()\n",
    "tikz('dtw_warped_series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# With sakoeband\n",
    "d = DynamicTimeWarping(scale_score=True, sakoeband=20)\n",
    "table_distance(V, d.dtw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# With Itakura parallelogram\n",
    "d = DynamicTimeWarping(scale_score=True, ikaturaband=3)\n",
    "table_distance(V, d.dtw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Include acceleration\n",
    "V2 = [np.array([v, np.gradient(v)/ts]).T for v in V]\n",
    "cost = lambda x, y: (x[0] - y[0])**2 + 3*(x[1] - y[1])**2\n",
    "d = DynamicTimeWarping(scale_score=True, cost=cost)\n",
    "table_distance(V2, d.dtw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize normal dtw for comparison\n",
    "dtw = DynamicTimeWarping(scale_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare all feature-based methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(table_folder, 'feature_based.tex'), 'w') as f:\n",
    "    write(f, '\\\\begin{tabular}{ccccccl}\\n')\n",
    "    write(f, '    \\\\toprule\\n')\n",
    "    write(f, '    \\\\multicolumn{2}{c}{Time series} & \\\\multicolumn{2}{c}{Features based}')\n",
    "    write(f, ' & \\\\multicolumn{2}{c}{Model based} & Dynamic \\\\\\\\\\n')\n",
    "    write(f, '    \\\\textbf{x} & \\\\textbf{y} & Fourier & Custom & Auto & Splines & time \\\\\\\\\\n')\n",
    "    write(f, '    & & coefficients & features & regression & warping \\\\\\\\\\n')\n",
    "    write(f, ' \\\\otoprule\\n')\n",
    "    for i, x in enumerate(V):\n",
    "        for j, y in enumerate(V):\n",
    "            if j > i:\n",
    "                write(f, '    $\\\\profile{{{:d}}}$ & $\\\\profile{{{:d}}}$'.format(i+1, j+1))\n",
    "                write(f, ' & ${:.2f}$'.format(fourier_based_distance(x, y, w=FCweights)))\n",
    "                write(f, ' & ${:.2f}$'.format(parameter_based_distance(x, y, w=par_weights)))\n",
    "                write(f, ' & ${:.2f}$'.format(ar_distance(x, y, w=ar_weights)))\n",
    "                write(f, ' & ${:.2f}$'.format(spl_distance(x, y, w=spl_weights)))\n",
    "                write(f, ' & ${:s}$ \\\\\\\\\\n'.format(str_e(dtw.dtw(x, y), decimals=2)))\n",
    "    write(f, '    \\\\bottomrule\\n')\n",
    "    write(f, '\\\\end{tabular}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
